I0113 13:58:51.729882 28435 caffe.cpp:185] Using GPUs 0
I0113 13:58:52.299134 28435 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1430
test_interval: 1000
base_lr: 0.001
display: 200
max_iter: 70000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 10000
snapshot_prefix: "krnet_full"
solver_mode: GPU
device_id: 0
net: "krnet_full_train_test.prototxt"
snapshot_format: HDF5
I0113 13:58:52.299290 28435 solver.cpp:91] Creating training net from net file: krnet_full_train_test.prototxt
I0113 13:58:52.299841 28435 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0113 13:58:52.299860 28435 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0113 13:58:52.300087 28435 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "train_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 13:58:52.300210 28435 layer_factory.hpp:77] Creating layer cifar
I0113 13:58:52.301312 28435 net.cpp:106] Creating Layer cifar
I0113 13:58:52.301336 28435 net.cpp:411] cifar -> data
I0113 13:58:52.301357 28435 net.cpp:411] cifar -> label
I0113 13:58:52.301369 28435 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 13:58:52.301919 28439 db_lmdb.cpp:38] Opened lmdb train_lmdb
I0113 13:58:52.381531 28435 data_layer.cpp:41] output data size: 100,3,100,100
I0113 13:58:52.401767 28435 net.cpp:150] Setting up cifar
I0113 13:58:52.401826 28435 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 13:58:52.401849 28435 net.cpp:157] Top shape: 100 (100)
I0113 13:58:52.401854 28435 net.cpp:165] Memory required for data: 12000400
I0113 13:58:52.401875 28435 layer_factory.hpp:77] Creating layer conv1
I0113 13:58:52.401914 28435 net.cpp:106] Creating Layer conv1
I0113 13:58:52.401924 28435 net.cpp:454] conv1 <- data
I0113 13:58:52.401948 28435 net.cpp:411] conv1 -> conv1
I0113 13:58:52.406008 28435 net.cpp:150] Setting up conv1
I0113 13:58:52.406046 28435 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 13:58:52.406052 28435 net.cpp:165] Memory required for data: 140000400
I0113 13:58:52.406082 28435 layer_factory.hpp:77] Creating layer pool1
I0113 13:58:52.406105 28435 net.cpp:106] Creating Layer pool1
I0113 13:58:52.406113 28435 net.cpp:454] pool1 <- conv1
I0113 13:58:52.406126 28435 net.cpp:411] pool1 -> pool1
I0113 13:58:52.406178 28435 net.cpp:150] Setting up pool1
I0113 13:58:52.406188 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.406191 28435 net.cpp:165] Memory required for data: 172000400
I0113 13:58:52.406196 28435 layer_factory.hpp:77] Creating layer relu1
I0113 13:58:52.406206 28435 net.cpp:106] Creating Layer relu1
I0113 13:58:52.406211 28435 net.cpp:454] relu1 <- pool1
I0113 13:58:52.406224 28435 net.cpp:397] relu1 -> pool1 (in-place)
I0113 13:58:52.406236 28435 net.cpp:150] Setting up relu1
I0113 13:58:52.406244 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.406246 28435 net.cpp:165] Memory required for data: 204000400
I0113 13:58:52.406251 28435 layer_factory.hpp:77] Creating layer norm1
I0113 13:58:52.406265 28435 net.cpp:106] Creating Layer norm1
I0113 13:58:52.406268 28435 net.cpp:454] norm1 <- pool1
I0113 13:58:52.406277 28435 net.cpp:411] norm1 -> norm1
I0113 13:58:52.406388 28435 net.cpp:150] Setting up norm1
I0113 13:58:52.406399 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.406402 28435 net.cpp:165] Memory required for data: 236000400
I0113 13:58:52.406407 28435 layer_factory.hpp:77] Creating layer conv2
I0113 13:58:52.406426 28435 net.cpp:106] Creating Layer conv2
I0113 13:58:52.406432 28435 net.cpp:454] conv2 <- norm1
I0113 13:58:52.406445 28435 net.cpp:411] conv2 -> conv2
I0113 13:58:52.411113 28435 net.cpp:150] Setting up conv2
I0113 13:58:52.411136 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.411141 28435 net.cpp:165] Memory required for data: 268000400
I0113 13:58:52.411157 28435 layer_factory.hpp:77] Creating layer relu2
I0113 13:58:52.411168 28435 net.cpp:106] Creating Layer relu2
I0113 13:58:52.411175 28435 net.cpp:454] relu2 <- conv2
I0113 13:58:52.411183 28435 net.cpp:397] relu2 -> conv2 (in-place)
I0113 13:58:52.411192 28435 net.cpp:150] Setting up relu2
I0113 13:58:52.411198 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.411202 28435 net.cpp:165] Memory required for data: 300000400
I0113 13:58:52.411206 28435 layer_factory.hpp:77] Creating layer pool2
I0113 13:58:52.411216 28435 net.cpp:106] Creating Layer pool2
I0113 13:58:52.411226 28435 net.cpp:454] pool2 <- conv2
I0113 13:58:52.411237 28435 net.cpp:411] pool2 -> pool2
I0113 13:58:52.411262 28435 net.cpp:150] Setting up pool2
I0113 13:58:52.411270 28435 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 13:58:52.411274 28435 net.cpp:165] Memory required for data: 308000400
I0113 13:58:52.411278 28435 layer_factory.hpp:77] Creating layer norm2
I0113 13:58:52.411301 28435 net.cpp:106] Creating Layer norm2
I0113 13:58:52.411306 28435 net.cpp:454] norm2 <- pool2
I0113 13:58:52.411316 28435 net.cpp:411] norm2 -> norm2
I0113 13:58:52.411418 28435 net.cpp:150] Setting up norm2
I0113 13:58:52.411427 28435 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 13:58:52.411432 28435 net.cpp:165] Memory required for data: 316000400
I0113 13:58:52.411437 28435 layer_factory.hpp:77] Creating layer conv3
I0113 13:58:52.411450 28435 net.cpp:106] Creating Layer conv3
I0113 13:58:52.411455 28435 net.cpp:454] conv3 <- norm2
I0113 13:58:52.411466 28435 net.cpp:411] conv3 -> conv3
I0113 13:58:52.421535 28435 net.cpp:150] Setting up conv3
I0113 13:58:52.421586 28435 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 13:58:52.421591 28435 net.cpp:165] Memory required for data: 332000400
I0113 13:58:52.421615 28435 layer_factory.hpp:77] Creating layer relu3
I0113 13:58:52.421633 28435 net.cpp:106] Creating Layer relu3
I0113 13:58:52.421639 28435 net.cpp:454] relu3 <- conv3
I0113 13:58:52.421651 28435 net.cpp:397] relu3 -> conv3 (in-place)
I0113 13:58:52.421663 28435 net.cpp:150] Setting up relu3
I0113 13:58:52.421669 28435 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 13:58:52.421674 28435 net.cpp:165] Memory required for data: 348000400
I0113 13:58:52.421677 28435 layer_factory.hpp:77] Creating layer pool3
I0113 13:58:52.421687 28435 net.cpp:106] Creating Layer pool3
I0113 13:58:52.421691 28435 net.cpp:454] pool3 <- conv3
I0113 13:58:52.421701 28435 net.cpp:411] pool3 -> pool3
I0113 13:58:52.421731 28435 net.cpp:150] Setting up pool3
I0113 13:58:52.421739 28435 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 13:58:52.421743 28435 net.cpp:165] Memory required for data: 351686800
I0113 13:58:52.421747 28435 layer_factory.hpp:77] Creating layer ip1
I0113 13:58:52.421762 28435 net.cpp:106] Creating Layer ip1
I0113 13:58:52.421767 28435 net.cpp:454] ip1 <- pool3
I0113 13:58:52.421778 28435 net.cpp:411] ip1 -> ip1
I0113 13:58:52.428053 28435 net.cpp:150] Setting up ip1
I0113 13:58:52.428067 28435 net.cpp:157] Top shape: 100 4 (400)
I0113 13:58:52.428071 28435 net.cpp:165] Memory required for data: 351688400
I0113 13:58:52.428081 28435 layer_factory.hpp:77] Creating layer loss
I0113 13:58:52.428092 28435 net.cpp:106] Creating Layer loss
I0113 13:58:52.428097 28435 net.cpp:454] loss <- ip1
I0113 13:58:52.428105 28435 net.cpp:454] loss <- label
I0113 13:58:52.428112 28435 net.cpp:411] loss -> loss
I0113 13:58:52.428125 28435 layer_factory.hpp:77] Creating layer loss
I0113 13:58:52.428210 28435 net.cpp:150] Setting up loss
I0113 13:58:52.428231 28435 net.cpp:157] Top shape: (1)
I0113 13:58:52.428237 28435 net.cpp:160]     with loss weight 1
I0113 13:58:52.428280 28435 net.cpp:165] Memory required for data: 351688404
I0113 13:58:52.428285 28435 net.cpp:226] loss needs backward computation.
I0113 13:58:52.428292 28435 net.cpp:226] ip1 needs backward computation.
I0113 13:58:52.428295 28435 net.cpp:226] pool3 needs backward computation.
I0113 13:58:52.428299 28435 net.cpp:226] relu3 needs backward computation.
I0113 13:58:52.428303 28435 net.cpp:226] conv3 needs backward computation.
I0113 13:58:52.428308 28435 net.cpp:226] norm2 needs backward computation.
I0113 13:58:52.428313 28435 net.cpp:226] pool2 needs backward computation.
I0113 13:58:52.428318 28435 net.cpp:226] relu2 needs backward computation.
I0113 13:58:52.428321 28435 net.cpp:226] conv2 needs backward computation.
I0113 13:58:52.428326 28435 net.cpp:226] norm1 needs backward computation.
I0113 13:58:52.428330 28435 net.cpp:226] relu1 needs backward computation.
I0113 13:58:52.428335 28435 net.cpp:226] pool1 needs backward computation.
I0113 13:58:52.428339 28435 net.cpp:226] conv1 needs backward computation.
I0113 13:58:52.428344 28435 net.cpp:228] cifar does not need backward computation.
I0113 13:58:52.428349 28435 net.cpp:270] This network produces output loss
I0113 13:58:52.428369 28435 net.cpp:283] Network initialization done.
I0113 13:58:52.429080 28435 solver.cpp:181] Creating test net (#0) specified by net file: krnet_full_train_test.prototxt
I0113 13:58:52.429141 28435 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0113 13:58:52.429756 28435 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "test_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 13:58:52.429934 28435 layer_factory.hpp:77] Creating layer cifar
I0113 13:58:52.430972 28435 net.cpp:106] Creating Layer cifar
I0113 13:58:52.430986 28435 net.cpp:411] cifar -> data
I0113 13:58:52.431002 28435 net.cpp:411] cifar -> label
I0113 13:58:52.431013 28435 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 13:58:52.431566 28441 db_lmdb.cpp:38] Opened lmdb test_lmdb
I0113 13:58:52.432521 28435 data_layer.cpp:41] output data size: 100,3,100,100
I0113 13:58:52.452801 28435 net.cpp:150] Setting up cifar
I0113 13:58:52.452850 28435 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 13:58:52.452858 28435 net.cpp:157] Top shape: 100 (100)
I0113 13:58:52.452862 28435 net.cpp:165] Memory required for data: 12000400
I0113 13:58:52.452874 28435 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0113 13:58:52.452898 28435 net.cpp:106] Creating Layer label_cifar_1_split
I0113 13:58:52.452906 28435 net.cpp:454] label_cifar_1_split <- label
I0113 13:58:52.452922 28435 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_0
I0113 13:58:52.452939 28435 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_1
I0113 13:58:52.452994 28435 net.cpp:150] Setting up label_cifar_1_split
I0113 13:58:52.453004 28435 net.cpp:157] Top shape: 100 (100)
I0113 13:58:52.453011 28435 net.cpp:157] Top shape: 100 (100)
I0113 13:58:52.453014 28435 net.cpp:165] Memory required for data: 12001200
I0113 13:58:52.453018 28435 layer_factory.hpp:77] Creating layer conv1
I0113 13:58:52.453042 28435 net.cpp:106] Creating Layer conv1
I0113 13:58:52.453047 28435 net.cpp:454] conv1 <- data
I0113 13:58:52.453059 28435 net.cpp:411] conv1 -> conv1
I0113 13:58:52.456116 28435 net.cpp:150] Setting up conv1
I0113 13:58:52.456177 28435 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 13:58:52.456182 28435 net.cpp:165] Memory required for data: 140001200
I0113 13:58:52.456213 28435 layer_factory.hpp:77] Creating layer pool1
I0113 13:58:52.456241 28435 net.cpp:106] Creating Layer pool1
I0113 13:58:52.456249 28435 net.cpp:454] pool1 <- conv1
I0113 13:58:52.456262 28435 net.cpp:411] pool1 -> pool1
I0113 13:58:52.456310 28435 net.cpp:150] Setting up pool1
I0113 13:58:52.456320 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.456323 28435 net.cpp:165] Memory required for data: 172001200
I0113 13:58:52.456328 28435 layer_factory.hpp:77] Creating layer relu1
I0113 13:58:52.456341 28435 net.cpp:106] Creating Layer relu1
I0113 13:58:52.456346 28435 net.cpp:454] relu1 <- pool1
I0113 13:58:52.456356 28435 net.cpp:397] relu1 -> pool1 (in-place)
I0113 13:58:52.456365 28435 net.cpp:150] Setting up relu1
I0113 13:58:52.456372 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.456374 28435 net.cpp:165] Memory required for data: 204001200
I0113 13:58:52.456379 28435 layer_factory.hpp:77] Creating layer norm1
I0113 13:58:52.456390 28435 net.cpp:106] Creating Layer norm1
I0113 13:58:52.456395 28435 net.cpp:454] norm1 <- pool1
I0113 13:58:52.456403 28435 net.cpp:411] norm1 -> norm1
I0113 13:58:52.456506 28435 net.cpp:150] Setting up norm1
I0113 13:58:52.456516 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.456519 28435 net.cpp:165] Memory required for data: 236001200
I0113 13:58:52.456524 28435 layer_factory.hpp:77] Creating layer conv2
I0113 13:58:52.456544 28435 net.cpp:106] Creating Layer conv2
I0113 13:58:52.456549 28435 net.cpp:454] conv2 <- norm1
I0113 13:58:52.456562 28435 net.cpp:411] conv2 -> conv2
I0113 13:58:52.461302 28435 net.cpp:150] Setting up conv2
I0113 13:58:52.461344 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.461349 28435 net.cpp:165] Memory required for data: 268001200
I0113 13:58:52.461375 28435 layer_factory.hpp:77] Creating layer relu2
I0113 13:58:52.461392 28435 net.cpp:106] Creating Layer relu2
I0113 13:58:52.461401 28435 net.cpp:454] relu2 <- conv2
I0113 13:58:52.461413 28435 net.cpp:397] relu2 -> conv2 (in-place)
I0113 13:58:52.461427 28435 net.cpp:150] Setting up relu2
I0113 13:58:52.461433 28435 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 13:58:52.461436 28435 net.cpp:165] Memory required for data: 300001200
I0113 13:58:52.461441 28435 layer_factory.hpp:77] Creating layer pool2
I0113 13:58:52.461455 28435 net.cpp:106] Creating Layer pool2
I0113 13:58:52.461460 28435 net.cpp:454] pool2 <- conv2
I0113 13:58:52.461470 28435 net.cpp:411] pool2 -> pool2
I0113 13:58:52.461503 28435 net.cpp:150] Setting up pool2
I0113 13:58:52.461513 28435 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 13:58:52.461516 28435 net.cpp:165] Memory required for data: 308001200
I0113 13:58:52.461521 28435 layer_factory.hpp:77] Creating layer norm2
I0113 13:58:52.461534 28435 net.cpp:106] Creating Layer norm2
I0113 13:58:52.461539 28435 net.cpp:454] norm2 <- pool2
I0113 13:58:52.461549 28435 net.cpp:411] norm2 -> norm2
I0113 13:58:52.461649 28435 net.cpp:150] Setting up norm2
I0113 13:58:52.461659 28435 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 13:58:52.461663 28435 net.cpp:165] Memory required for data: 316001200
I0113 13:58:52.461668 28435 layer_factory.hpp:77] Creating layer conv3
I0113 13:58:52.461684 28435 net.cpp:106] Creating Layer conv3
I0113 13:58:52.461689 28435 net.cpp:454] conv3 <- norm2
I0113 13:58:52.461701 28435 net.cpp:411] conv3 -> conv3
I0113 13:58:52.470721 28435 net.cpp:150] Setting up conv3
I0113 13:58:52.470767 28435 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 13:58:52.470772 28435 net.cpp:165] Memory required for data: 332001200
I0113 13:58:52.470799 28435 layer_factory.hpp:77] Creating layer relu3
I0113 13:58:52.470818 28435 net.cpp:106] Creating Layer relu3
I0113 13:58:52.470826 28435 net.cpp:454] relu3 <- conv3
I0113 13:58:52.470854 28435 net.cpp:397] relu3 -> conv3 (in-place)
I0113 13:58:52.470877 28435 net.cpp:150] Setting up relu3
I0113 13:58:52.470885 28435 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 13:58:52.470888 28435 net.cpp:165] Memory required for data: 348001200
I0113 13:58:52.470893 28435 layer_factory.hpp:77] Creating layer pool3
I0113 13:58:52.470906 28435 net.cpp:106] Creating Layer pool3
I0113 13:58:52.470909 28435 net.cpp:454] pool3 <- conv3
I0113 13:58:52.470919 28435 net.cpp:411] pool3 -> pool3
I0113 13:58:52.470949 28435 net.cpp:150] Setting up pool3
I0113 13:58:52.470957 28435 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 13:58:52.470962 28435 net.cpp:165] Memory required for data: 351687600
I0113 13:58:52.470965 28435 layer_factory.hpp:77] Creating layer ip1
I0113 13:58:52.470979 28435 net.cpp:106] Creating Layer ip1
I0113 13:58:52.470984 28435 net.cpp:454] ip1 <- pool3
I0113 13:58:52.470994 28435 net.cpp:411] ip1 -> ip1
I0113 13:58:52.477460 28435 net.cpp:150] Setting up ip1
I0113 13:58:52.477510 28435 net.cpp:157] Top shape: 100 4 (400)
I0113 13:58:52.477515 28435 net.cpp:165] Memory required for data: 351689200
I0113 13:58:52.477532 28435 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0113 13:58:52.477551 28435 net.cpp:106] Creating Layer ip1_ip1_0_split
I0113 13:58:52.477561 28435 net.cpp:454] ip1_ip1_0_split <- ip1
I0113 13:58:52.477576 28435 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0113 13:58:52.477591 28435 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0113 13:58:52.477633 28435 net.cpp:150] Setting up ip1_ip1_0_split
I0113 13:58:52.477643 28435 net.cpp:157] Top shape: 100 4 (400)
I0113 13:58:52.477648 28435 net.cpp:157] Top shape: 100 4 (400)
I0113 13:58:52.477653 28435 net.cpp:165] Memory required for data: 351692400
I0113 13:58:52.477658 28435 layer_factory.hpp:77] Creating layer accuracy
I0113 13:58:52.477674 28435 net.cpp:106] Creating Layer accuracy
I0113 13:58:52.477679 28435 net.cpp:454] accuracy <- ip1_ip1_0_split_0
I0113 13:58:52.477687 28435 net.cpp:454] accuracy <- label_cifar_1_split_0
I0113 13:58:52.477696 28435 net.cpp:411] accuracy -> accuracy
I0113 13:58:52.477710 28435 net.cpp:150] Setting up accuracy
I0113 13:58:52.477717 28435 net.cpp:157] Top shape: (1)
I0113 13:58:52.477721 28435 net.cpp:165] Memory required for data: 351692404
I0113 13:58:52.477726 28435 layer_factory.hpp:77] Creating layer loss
I0113 13:58:52.477741 28435 net.cpp:106] Creating Layer loss
I0113 13:58:52.477746 28435 net.cpp:454] loss <- ip1_ip1_0_split_1
I0113 13:58:52.477754 28435 net.cpp:454] loss <- label_cifar_1_split_1
I0113 13:58:52.477762 28435 net.cpp:411] loss -> loss
I0113 13:58:52.477779 28435 layer_factory.hpp:77] Creating layer loss
I0113 13:58:52.477877 28435 net.cpp:150] Setting up loss
I0113 13:58:52.477887 28435 net.cpp:157] Top shape: (1)
I0113 13:58:52.477892 28435 net.cpp:160]     with loss weight 1
I0113 13:58:52.477907 28435 net.cpp:165] Memory required for data: 351692408
I0113 13:58:52.477912 28435 net.cpp:226] loss needs backward computation.
I0113 13:58:52.477919 28435 net.cpp:228] accuracy does not need backward computation.
I0113 13:58:52.477926 28435 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0113 13:58:52.477929 28435 net.cpp:226] ip1 needs backward computation.
I0113 13:58:52.477936 28435 net.cpp:226] pool3 needs backward computation.
I0113 13:58:52.477941 28435 net.cpp:226] relu3 needs backward computation.
I0113 13:58:52.477946 28435 net.cpp:226] conv3 needs backward computation.
I0113 13:58:52.477951 28435 net.cpp:226] norm2 needs backward computation.
I0113 13:58:52.477955 28435 net.cpp:226] pool2 needs backward computation.
I0113 13:58:52.477960 28435 net.cpp:226] relu2 needs backward computation.
I0113 13:58:52.477965 28435 net.cpp:226] conv2 needs backward computation.
I0113 13:58:52.477969 28435 net.cpp:226] norm1 needs backward computation.
I0113 13:58:52.477974 28435 net.cpp:226] relu1 needs backward computation.
I0113 13:58:52.477979 28435 net.cpp:226] pool1 needs backward computation.
I0113 13:58:52.477984 28435 net.cpp:226] conv1 needs backward computation.
I0113 13:58:52.478013 28435 net.cpp:228] label_cifar_1_split does not need backward computation.
I0113 13:58:52.478018 28435 net.cpp:228] cifar does not need backward computation.
I0113 13:58:52.478024 28435 net.cpp:270] This network produces output accuracy
I0113 13:58:52.478029 28435 net.cpp:270] This network produces output loss
I0113 13:58:52.478054 28435 net.cpp:283] Network initialization done.
I0113 13:58:52.478138 28435 solver.cpp:60] Solver scaffolding done.
I0113 13:58:52.478407 28435 caffe.cpp:213] Starting Optimization
I0113 13:58:52.478417 28435 solver.cpp:280] Solving CIFAR10_full
I0113 13:58:52.478423 28435 solver.cpp:281] Learning Rate Policy: fixed
I0113 13:58:52.479337 28435 solver.cpp:338] Iteration 0, Testing net (#0)
I0113 13:58:52.479921 28435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0113 14:00:34.674420 28435 solver.cpp:406]     Test net output #0: accuracy = 0.13314
I0113 14:00:34.674496 28435 solver.cpp:406]     Test net output #1: loss = 1.38669 (* 1 = 1.38669 loss)
I0113 14:00:34.802744 28435 solver.cpp:229] Iteration 0, loss = 1.38615
I0113 14:00:34.802783 28435 solver.cpp:245]     Train net output #0: loss = 1.38615 (* 1 = 1.38615 loss)
I0113 14:00:34.802790 28435 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0113 14:01:18.352062 28435 solver.cpp:229] Iteration 200, loss = 1.5916
I0113 14:01:18.352134 28435 solver.cpp:245]     Train net output #0: loss = 1.5916 (* 1 = 1.5916 loss)
I0113 14:01:18.352141 28435 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0113 14:02:01.882454 28435 solver.cpp:229] Iteration 400, loss = 1.39015
I0113 14:02:01.882505 28435 solver.cpp:245]     Train net output #0: loss = 1.39015 (* 1 = 1.39015 loss)
I0113 14:02:01.882511 28435 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0113 14:02:45.421886 28435 solver.cpp:229] Iteration 600, loss = 1.13013
I0113 14:02:45.421939 28435 solver.cpp:245]     Train net output #0: loss = 1.13013 (* 1 = 1.13013 loss)
I0113 14:02:45.421946 28435 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0113 14:03:28.973417 28435 solver.cpp:229] Iteration 800, loss = 1.26292
I0113 14:03:28.973479 28435 solver.cpp:245]     Train net output #0: loss = 1.26292 (* 1 = 1.26292 loss)
I0113 14:03:28.973485 28435 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0113 14:04:06.342453 28435 solver.cpp:338] Iteration 1000, Testing net (#0)
I0113 14:05:48.598853 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361524
I0113 14:05:48.598918 28435 solver.cpp:406]     Test net output #1: loss = 1.25888 (* 1 = 1.25888 loss)
I0113 14:05:48.717874 28435 solver.cpp:229] Iteration 1000, loss = 1.32975
I0113 14:05:48.717916 28435 solver.cpp:245]     Train net output #0: loss = 1.32975 (* 1 = 1.32975 loss)
I0113 14:05:48.717921 28435 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0113 14:06:32.316915 28435 solver.cpp:229] Iteration 1200, loss = 1.26356
I0113 14:06:32.316993 28435 solver.cpp:245]     Train net output #0: loss = 1.26356 (* 1 = 1.26356 loss)
I0113 14:06:32.316999 28435 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0113 14:07:15.893121 28435 solver.cpp:229] Iteration 1400, loss = 1.23373
I0113 14:07:15.893187 28435 solver.cpp:245]     Train net output #0: loss = 1.23373 (* 1 = 1.23373 loss)
I0113 14:07:15.893194 28435 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0113 14:07:59.461136 28435 solver.cpp:229] Iteration 1600, loss = 1.52287
I0113 14:07:59.461191 28435 solver.cpp:245]     Train net output #0: loss = 1.52287 (* 1 = 1.52287 loss)
I0113 14:07:59.461200 28435 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0113 14:08:43.033975 28435 solver.cpp:229] Iteration 1800, loss = 1.42481
I0113 14:08:43.034031 28435 solver.cpp:245]     Train net output #0: loss = 1.42481 (* 1 = 1.42481 loss)
I0113 14:08:43.034037 28435 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0113 14:09:20.423823 28435 solver.cpp:338] Iteration 2000, Testing net (#0)
I0113 14:11:02.740926 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387657
I0113 14:11:02.740983 28435 solver.cpp:406]     Test net output #1: loss = 1.25508 (* 1 = 1.25508 loss)
I0113 14:11:02.859971 28435 solver.cpp:229] Iteration 2000, loss = 1.15031
I0113 14:11:02.860008 28435 solver.cpp:245]     Train net output #0: loss = 1.15031 (* 1 = 1.15031 loss)
I0113 14:11:02.860013 28435 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0113 14:11:46.434468 28435 solver.cpp:229] Iteration 2200, loss = 1.28061
I0113 14:11:46.434521 28435 solver.cpp:245]     Train net output #0: loss = 1.28061 (* 1 = 1.28061 loss)
I0113 14:11:46.434526 28435 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0113 14:12:30.016062 28435 solver.cpp:229] Iteration 2400, loss = 1.19303
I0113 14:12:30.016130 28435 solver.cpp:245]     Train net output #0: loss = 1.19303 (* 1 = 1.19303 loss)
I0113 14:12:30.016135 28435 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0113 14:13:13.597559 28435 solver.cpp:229] Iteration 2600, loss = 1.21541
I0113 14:13:13.597622 28435 solver.cpp:245]     Train net output #0: loss = 1.21541 (* 1 = 1.21541 loss)
I0113 14:13:13.597627 28435 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0113 14:13:57.174322 28435 solver.cpp:229] Iteration 2800, loss = 1.2624
I0113 14:13:57.174371 28435 solver.cpp:245]     Train net output #0: loss = 1.2624 (* 1 = 1.2624 loss)
I0113 14:13:57.174377 28435 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0113 14:14:34.565462 28435 solver.cpp:338] Iteration 3000, Testing net (#0)
I0113 14:16:16.872725 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388699
I0113 14:16:16.872789 28435 solver.cpp:406]     Test net output #1: loss = 1.25458 (* 1 = 1.25458 loss)
I0113 14:16:16.998366 28435 solver.cpp:229] Iteration 3000, loss = 1.33145
I0113 14:16:16.998404 28435 solver.cpp:245]     Train net output #0: loss = 1.33145 (* 1 = 1.33145 loss)
I0113 14:16:16.998409 28435 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0113 14:17:00.567401 28435 solver.cpp:229] Iteration 3200, loss = 1.28333
I0113 14:17:00.567459 28435 solver.cpp:245]     Train net output #0: loss = 1.28333 (* 1 = 1.28333 loss)
I0113 14:17:00.567466 28435 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0113 14:17:44.143555 28435 solver.cpp:229] Iteration 3400, loss = 1.30746
I0113 14:17:44.143613 28435 solver.cpp:245]     Train net output #0: loss = 1.30746 (* 1 = 1.30746 loss)
I0113 14:17:44.143620 28435 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0113 14:18:27.724601 28435 solver.cpp:229] Iteration 3600, loss = 1.24821
I0113 14:18:27.724649 28435 solver.cpp:245]     Train net output #0: loss = 1.24821 (* 1 = 1.24821 loss)
I0113 14:18:27.724655 28435 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0113 14:19:11.294008 28435 solver.cpp:229] Iteration 3800, loss = 1.22071
I0113 14:19:11.294072 28435 solver.cpp:245]     Train net output #0: loss = 1.22071 (* 1 = 1.22071 loss)
I0113 14:19:11.294078 28435 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0113 14:19:48.697815 28435 solver.cpp:338] Iteration 4000, Testing net (#0)
I0113 14:21:31.002944 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388357
I0113 14:21:31.003001 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 14:21:31.136098 28435 solver.cpp:229] Iteration 4000, loss = 1.3166
I0113 14:21:31.136135 28435 solver.cpp:245]     Train net output #0: loss = 1.3166 (* 1 = 1.3166 loss)
I0113 14:21:31.136140 28435 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0113 14:22:14.676951 28435 solver.cpp:229] Iteration 4200, loss = 1.14304
I0113 14:22:14.677013 28435 solver.cpp:245]     Train net output #0: loss = 1.14304 (* 1 = 1.14304 loss)
I0113 14:22:14.677019 28435 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0113 14:22:58.225868 28435 solver.cpp:229] Iteration 4400, loss = 1.23654
I0113 14:22:58.225929 28435 solver.cpp:245]     Train net output #0: loss = 1.23654 (* 1 = 1.23654 loss)
I0113 14:22:58.225935 28435 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0113 14:23:41.755403 28435 solver.cpp:229] Iteration 4600, loss = 1.4452
I0113 14:23:41.755511 28435 solver.cpp:245]     Train net output #0: loss = 1.4452 (* 1 = 1.4452 loss)
I0113 14:23:41.755517 28435 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0113 14:24:25.316087 28435 solver.cpp:229] Iteration 4800, loss = 1.27299
I0113 14:24:25.316151 28435 solver.cpp:245]     Train net output #0: loss = 1.27299 (* 1 = 1.27299 loss)
I0113 14:24:25.316159 28435 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0113 14:25:02.702472 28435 solver.cpp:338] Iteration 5000, Testing net (#0)
I0113 14:26:45.030483 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388189
I0113 14:26:45.030534 28435 solver.cpp:406]     Test net output #1: loss = 1.25466 (* 1 = 1.25466 loss)
I0113 14:26:45.149693 28435 solver.cpp:229] Iteration 5000, loss = 1.37517
I0113 14:26:45.149731 28435 solver.cpp:245]     Train net output #0: loss = 1.37517 (* 1 = 1.37517 loss)
I0113 14:26:45.149736 28435 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0113 14:27:28.710891 28435 solver.cpp:229] Iteration 5200, loss = 1.28027
I0113 14:27:28.710952 28435 solver.cpp:245]     Train net output #0: loss = 1.28027 (* 1 = 1.28027 loss)
I0113 14:27:28.710958 28435 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0113 14:28:12.264453 28435 solver.cpp:229] Iteration 5400, loss = 1.40748
I0113 14:28:12.264515 28435 solver.cpp:245]     Train net output #0: loss = 1.40748 (* 1 = 1.40748 loss)
I0113 14:28:12.264521 28435 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0113 14:28:55.844979 28435 solver.cpp:229] Iteration 5600, loss = 1.24972
I0113 14:28:55.845028 28435 solver.cpp:245]     Train net output #0: loss = 1.24972 (* 1 = 1.24972 loss)
I0113 14:28:55.845033 28435 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0113 14:29:39.401851 28435 solver.cpp:229] Iteration 5800, loss = 1.24428
I0113 14:29:39.401916 28435 solver.cpp:245]     Train net output #0: loss = 1.24428 (* 1 = 1.24428 loss)
I0113 14:29:39.401922 28435 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0113 14:30:16.751340 28435 solver.cpp:338] Iteration 6000, Testing net (#0)
I0113 14:31:59.068699 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361608
I0113 14:31:59.068778 28435 solver.cpp:406]     Test net output #1: loss = 1.25617 (* 1 = 1.25617 loss)
I0113 14:31:59.194167 28435 solver.cpp:229] Iteration 6000, loss = 1.18505
I0113 14:31:59.194205 28435 solver.cpp:245]     Train net output #0: loss = 1.18505 (* 1 = 1.18505 loss)
I0113 14:31:59.194209 28435 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0113 14:32:42.766180 28435 solver.cpp:229] Iteration 6200, loss = 1.25857
I0113 14:32:42.766232 28435 solver.cpp:245]     Train net output #0: loss = 1.25857 (* 1 = 1.25857 loss)
I0113 14:32:42.766237 28435 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0113 14:33:26.345582 28435 solver.cpp:229] Iteration 6400, loss = 1.58617
I0113 14:33:26.345630 28435 solver.cpp:245]     Train net output #0: loss = 1.58617 (* 1 = 1.58617 loss)
I0113 14:33:26.345635 28435 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0113 14:34:09.907778 28435 solver.cpp:229] Iteration 6600, loss = 1.48596
I0113 14:34:09.907841 28435 solver.cpp:245]     Train net output #0: loss = 1.48596 (* 1 = 1.48596 loss)
I0113 14:34:09.907846 28435 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0113 14:34:53.459472 28435 solver.cpp:229] Iteration 6800, loss = 1.15335
I0113 14:34:53.459523 28435 solver.cpp:245]     Train net output #0: loss = 1.15335 (* 1 = 1.15335 loss)
I0113 14:34:53.459528 28435 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0113 14:35:30.798815 28435 solver.cpp:338] Iteration 7000, Testing net (#0)
I0113 14:37:13.120044 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38842
I0113 14:37:13.120115 28435 solver.cpp:406]     Test net output #1: loss = 1.25465 (* 1 = 1.25465 loss)
I0113 14:37:13.244220 28435 solver.cpp:229] Iteration 7000, loss = 1.13347
I0113 14:37:13.244257 28435 solver.cpp:245]     Train net output #0: loss = 1.13347 (* 1 = 1.13347 loss)
I0113 14:37:13.244262 28435 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0113 14:37:56.800072 28435 solver.cpp:229] Iteration 7200, loss = 1.05753
I0113 14:37:56.800164 28435 solver.cpp:245]     Train net output #0: loss = 1.05753 (* 1 = 1.05753 loss)
I0113 14:37:56.800173 28435 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0113 14:38:40.336127 28435 solver.cpp:229] Iteration 7400, loss = 1.06041
I0113 14:38:40.336182 28435 solver.cpp:245]     Train net output #0: loss = 1.06041 (* 1 = 1.06041 loss)
I0113 14:38:40.336189 28435 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0113 14:39:23.900617 28435 solver.cpp:229] Iteration 7600, loss = 1.15794
I0113 14:39:23.900666 28435 solver.cpp:245]     Train net output #0: loss = 1.15794 (* 1 = 1.15794 loss)
I0113 14:39:23.900672 28435 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0113 14:40:07.460825 28435 solver.cpp:229] Iteration 7800, loss = 1.10933
I0113 14:40:07.460888 28435 solver.cpp:245]     Train net output #0: loss = 1.10933 (* 1 = 1.10933 loss)
I0113 14:40:07.460893 28435 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0113 14:40:44.791734 28435 solver.cpp:338] Iteration 8000, Testing net (#0)
I0113 14:42:27.107594 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388322
I0113 14:42:27.107647 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 14:42:27.233364 28435 solver.cpp:229] Iteration 8000, loss = 1.25433
I0113 14:42:27.233402 28435 solver.cpp:245]     Train net output #0: loss = 1.25433 (* 1 = 1.25433 loss)
I0113 14:42:27.233407 28435 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0113 14:43:10.801615 28435 solver.cpp:229] Iteration 8200, loss = 1.16301
I0113 14:43:10.801666 28435 solver.cpp:245]     Train net output #0: loss = 1.16301 (* 1 = 1.16301 loss)
I0113 14:43:10.801671 28435 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0113 14:43:54.355219 28435 solver.cpp:229] Iteration 8400, loss = 1.36882
I0113 14:43:54.355269 28435 solver.cpp:245]     Train net output #0: loss = 1.36882 (* 1 = 1.36882 loss)
I0113 14:43:54.355275 28435 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0113 14:44:37.891309 28435 solver.cpp:229] Iteration 8600, loss = 1.17445
I0113 14:44:37.891376 28435 solver.cpp:245]     Train net output #0: loss = 1.17445 (* 1 = 1.17445 loss)
I0113 14:44:37.891382 28435 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0113 14:45:21.451202 28435 solver.cpp:229] Iteration 8800, loss = 1.04505
I0113 14:45:21.451283 28435 solver.cpp:245]     Train net output #0: loss = 1.04505 (* 1 = 1.04505 loss)
I0113 14:45:21.451290 28435 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0113 14:45:58.785750 28435 solver.cpp:338] Iteration 9000, Testing net (#0)
I0113 14:47:41.109436 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388517
I0113 14:47:41.109488 28435 solver.cpp:406]     Test net output #1: loss = 1.25446 (* 1 = 1.25446 loss)
I0113 14:47:41.228464 28435 solver.cpp:229] Iteration 9000, loss = 1.26738
I0113 14:47:41.228502 28435 solver.cpp:245]     Train net output #0: loss = 1.26738 (* 1 = 1.26738 loss)
I0113 14:47:41.228508 28435 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0113 14:48:24.796826 28435 solver.cpp:229] Iteration 9200, loss = 1.42506
I0113 14:48:24.796877 28435 solver.cpp:245]     Train net output #0: loss = 1.42506 (* 1 = 1.42506 loss)
I0113 14:48:24.796882 28435 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0113 14:49:08.353935 28435 solver.cpp:229] Iteration 9400, loss = 1.24317
I0113 14:49:08.353998 28435 solver.cpp:245]     Train net output #0: loss = 1.24317 (* 1 = 1.24317 loss)
I0113 14:49:08.354004 28435 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0113 14:49:51.881158 28435 solver.cpp:229] Iteration 9600, loss = 1.22432
I0113 14:49:51.881209 28435 solver.cpp:245]     Train net output #0: loss = 1.22432 (* 1 = 1.22432 loss)
I0113 14:49:51.881214 28435 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0113 14:50:35.440033 28435 solver.cpp:229] Iteration 9800, loss = 1.34041
I0113 14:50:35.440083 28435 solver.cpp:245]     Train net output #0: loss = 1.34041 (* 1 = 1.34041 loss)
I0113 14:50:35.440088 28435 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0113 14:51:12.736032 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_10000.caffemodel.h5
I0113 14:51:12.817077 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_10000.solverstate.h5
I0113 14:51:12.818053 28435 solver.cpp:338] Iteration 10000, Testing net (#0)
I0113 14:52:55.079701 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388161
I0113 14:52:55.079762 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 14:52:55.201326 28435 solver.cpp:229] Iteration 10000, loss = 1.40543
I0113 14:52:55.201365 28435 solver.cpp:245]     Train net output #0: loss = 1.40543 (* 1 = 1.40543 loss)
I0113 14:52:55.201370 28435 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0113 14:53:38.735900 28435 solver.cpp:229] Iteration 10200, loss = 1.07274
I0113 14:53:38.735975 28435 solver.cpp:245]     Train net output #0: loss = 1.07274 (* 1 = 1.07274 loss)
I0113 14:53:38.735980 28435 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0113 14:54:22.315476 28435 solver.cpp:229] Iteration 10400, loss = 1.21974
I0113 14:54:22.315528 28435 solver.cpp:245]     Train net output #0: loss = 1.21974 (* 1 = 1.21974 loss)
I0113 14:54:22.315534 28435 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0113 14:55:05.850612 28435 solver.cpp:229] Iteration 10600, loss = 1.2563
I0113 14:55:05.850666 28435 solver.cpp:245]     Train net output #0: loss = 1.2563 (* 1 = 1.2563 loss)
I0113 14:55:05.850672 28435 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0113 14:55:49.399597 28435 solver.cpp:229] Iteration 10800, loss = 1.09203
I0113 14:55:49.399646 28435 solver.cpp:245]     Train net output #0: loss = 1.09203 (* 1 = 1.09203 loss)
I0113 14:55:49.399652 28435 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0113 14:56:26.714740 28435 solver.cpp:338] Iteration 11000, Testing net (#0)
I0113 14:58:09.056485 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38865
I0113 14:58:09.056540 28435 solver.cpp:406]     Test net output #1: loss = 1.25466 (* 1 = 1.25466 loss)
I0113 14:58:09.177567 28435 solver.cpp:229] Iteration 11000, loss = 1.38671
I0113 14:58:09.177606 28435 solver.cpp:245]     Train net output #0: loss = 1.38671 (* 1 = 1.38671 loss)
I0113 14:58:09.177611 28435 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0113 14:58:52.710253 28435 solver.cpp:229] Iteration 11200, loss = 1.17323
I0113 14:58:52.710309 28435 solver.cpp:245]     Train net output #0: loss = 1.17323 (* 1 = 1.17323 loss)
I0113 14:58:52.710315 28435 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0113 14:59:36.276795 28435 solver.cpp:229] Iteration 11400, loss = 1.36258
I0113 14:59:36.276865 28435 solver.cpp:245]     Train net output #0: loss = 1.36258 (* 1 = 1.36258 loss)
I0113 14:59:36.276871 28435 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0113 15:00:19.860281 28435 solver.cpp:229] Iteration 11600, loss = 1.32395
I0113 15:00:19.860332 28435 solver.cpp:245]     Train net output #0: loss = 1.32395 (* 1 = 1.32395 loss)
I0113 15:00:19.860337 28435 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0113 15:01:03.400255 28435 solver.cpp:229] Iteration 11800, loss = 1.1536
I0113 15:01:03.400307 28435 solver.cpp:245]     Train net output #0: loss = 1.1536 (* 1 = 1.1536 loss)
I0113 15:01:03.400313 28435 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0113 15:01:40.720994 28435 solver.cpp:338] Iteration 12000, Testing net (#0)
I0113 15:03:20.611827 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387741
I0113 15:03:20.611902 28435 solver.cpp:406]     Test net output #1: loss = 1.25464 (* 1 = 1.25464 loss)
I0113 15:03:20.745513 28435 solver.cpp:229] Iteration 12000, loss = 1.01731
I0113 15:03:20.745551 28435 solver.cpp:245]     Train net output #0: loss = 1.01731 (* 1 = 1.01731 loss)
I0113 15:03:20.745556 28435 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0113 15:04:04.298164 28435 solver.cpp:229] Iteration 12200, loss = 1.23008
I0113 15:04:04.298239 28435 solver.cpp:245]     Train net output #0: loss = 1.23008 (* 1 = 1.23008 loss)
I0113 15:04:04.298245 28435 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0113 15:04:47.841068 28435 solver.cpp:229] Iteration 12400, loss = 1.2188
I0113 15:04:47.841163 28435 solver.cpp:245]     Train net output #0: loss = 1.2188 (* 1 = 1.2188 loss)
I0113 15:04:47.841171 28435 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0113 15:05:31.417274 28435 solver.cpp:229] Iteration 12600, loss = 1.24315
I0113 15:05:31.417346 28435 solver.cpp:245]     Train net output #0: loss = 1.24315 (* 1 = 1.24315 loss)
I0113 15:05:31.417351 28435 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0113 15:06:14.992970 28435 solver.cpp:229] Iteration 12800, loss = 1.10057
I0113 15:06:14.993027 28435 solver.cpp:245]     Train net output #0: loss = 1.10057 (* 1 = 1.10057 loss)
I0113 15:06:14.993033 28435 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0113 15:06:56.980672 28435 solver.cpp:338] Iteration 13000, Testing net (#0)
I0113 15:08:52.539566 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361343
I0113 15:08:52.539628 28435 solver.cpp:406]     Test net output #1: loss = 1.25624 (* 1 = 1.25624 loss)
I0113 15:08:52.665467 28435 solver.cpp:229] Iteration 13000, loss = 1.1591
I0113 15:08:52.665506 28435 solver.cpp:245]     Train net output #0: loss = 1.1591 (* 1 = 1.1591 loss)
I0113 15:08:52.665511 28435 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0113 15:09:36.200686 28435 solver.cpp:229] Iteration 13200, loss = 1.19814
I0113 15:09:36.200742 28435 solver.cpp:245]     Train net output #0: loss = 1.19814 (* 1 = 1.19814 loss)
I0113 15:09:36.200747 28435 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0113 15:10:18.414871 28435 solver.cpp:229] Iteration 13400, loss = 1.19288
I0113 15:10:18.414932 28435 solver.cpp:245]     Train net output #0: loss = 1.19288 (* 1 = 1.19288 loss)
I0113 15:10:18.414937 28435 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0113 15:11:01.999122 28435 solver.cpp:229] Iteration 13600, loss = 1.22449
I0113 15:11:01.999176 28435 solver.cpp:245]     Train net output #0: loss = 1.22449 (* 1 = 1.22449 loss)
I0113 15:11:01.999182 28435 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0113 15:11:45.578522 28435 solver.cpp:229] Iteration 13800, loss = 1.18742
I0113 15:11:45.578598 28435 solver.cpp:245]     Train net output #0: loss = 1.18742 (* 1 = 1.18742 loss)
I0113 15:11:45.578604 28435 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0113 15:12:28.946413 28435 solver.cpp:338] Iteration 14000, Testing net (#0)
I0113 15:14:23.122344 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388567
I0113 15:14:23.122406 28435 solver.cpp:406]     Test net output #1: loss = 1.25452 (* 1 = 1.25452 loss)
I0113 15:14:23.251791 28435 solver.cpp:229] Iteration 14000, loss = 1.2282
I0113 15:14:23.251829 28435 solver.cpp:245]     Train net output #0: loss = 1.2282 (* 1 = 1.2282 loss)
I0113 15:14:23.251835 28435 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0113 15:15:06.792615 28435 solver.cpp:229] Iteration 14200, loss = 1.31648
I0113 15:15:06.792683 28435 solver.cpp:245]     Train net output #0: loss = 1.31648 (* 1 = 1.31648 loss)
I0113 15:15:06.792690 28435 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0113 15:15:50.332514 28435 solver.cpp:229] Iteration 14400, loss = 1.19176
I0113 15:15:50.332566 28435 solver.cpp:245]     Train net output #0: loss = 1.19176 (* 1 = 1.19176 loss)
I0113 15:15:50.332573 28435 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0113 15:16:33.871186 28435 solver.cpp:229] Iteration 14600, loss = 1.33922
I0113 15:16:33.871249 28435 solver.cpp:245]     Train net output #0: loss = 1.33922 (* 1 = 1.33922 loss)
I0113 15:16:33.871256 28435 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0113 15:17:16.064168 28435 solver.cpp:229] Iteration 14800, loss = 1.20382
I0113 15:17:16.064241 28435 solver.cpp:245]     Train net output #0: loss = 1.20382 (* 1 = 1.20382 loss)
I0113 15:17:16.064249 28435 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0113 15:17:59.397500 28435 solver.cpp:338] Iteration 15000, Testing net (#0)
I0113 15:19:54.889982 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388161
I0113 15:19:54.890039 28435 solver.cpp:406]     Test net output #1: loss = 1.25463 (* 1 = 1.25463 loss)
I0113 15:19:55.015584 28435 solver.cpp:229] Iteration 15000, loss = 1.06324
I0113 15:19:55.015621 28435 solver.cpp:245]     Train net output #0: loss = 1.06324 (* 1 = 1.06324 loss)
I0113 15:19:55.015635 28435 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0113 15:20:37.985283 28435 solver.cpp:229] Iteration 15200, loss = 1.1462
I0113 15:20:37.985384 28435 solver.cpp:245]     Train net output #0: loss = 1.1462 (* 1 = 1.1462 loss)
I0113 15:20:37.985393 28435 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0113 15:21:20.766285 28435 solver.cpp:229] Iteration 15400, loss = 1.07841
I0113 15:21:20.766351 28435 solver.cpp:245]     Train net output #0: loss = 1.07841 (* 1 = 1.07841 loss)
I0113 15:21:20.766357 28435 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0113 15:22:04.327167 28435 solver.cpp:229] Iteration 15600, loss = 1.27368
I0113 15:22:04.327231 28435 solver.cpp:245]     Train net output #0: loss = 1.27368 (* 1 = 1.27368 loss)
I0113 15:22:04.327239 28435 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0113 15:22:47.895457 28435 solver.cpp:229] Iteration 15800, loss = 1.32793
I0113 15:22:47.895519 28435 solver.cpp:245]     Train net output #0: loss = 1.32793 (* 1 = 1.32793 loss)
I0113 15:22:47.895525 28435 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0113 15:23:31.245772 28435 solver.cpp:338] Iteration 16000, Testing net (#0)
I0113 15:25:25.423522 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38814
I0113 15:25:25.423584 28435 solver.cpp:406]     Test net output #1: loss = 1.25463 (* 1 = 1.25463 loss)
I0113 15:25:25.553864 28435 solver.cpp:229] Iteration 16000, loss = 1.14273
I0113 15:25:25.553906 28435 solver.cpp:245]     Train net output #0: loss = 1.14273 (* 1 = 1.14273 loss)
I0113 15:25:25.553912 28435 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0113 15:26:09.100098 28435 solver.cpp:229] Iteration 16200, loss = 1.27644
I0113 15:26:09.100162 28435 solver.cpp:245]     Train net output #0: loss = 1.27644 (* 1 = 1.27644 loss)
I0113 15:26:09.100168 28435 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0113 15:26:52.653844 28435 solver.cpp:229] Iteration 16400, loss = 1.36257
I0113 15:26:52.653944 28435 solver.cpp:245]     Train net output #0: loss = 1.36257 (* 1 = 1.36257 loss)
I0113 15:26:52.653954 28435 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0113 15:27:36.218430 28435 solver.cpp:229] Iteration 16600, loss = 1.07204
I0113 15:27:36.218519 28435 solver.cpp:245]     Train net output #0: loss = 1.07204 (* 1 = 1.07204 loss)
I0113 15:27:36.218526 28435 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0113 15:28:18.450541 28435 solver.cpp:229] Iteration 16800, loss = 1.22907
I0113 15:28:18.450613 28435 solver.cpp:245]     Train net output #0: loss = 1.22907 (* 1 = 1.22907 loss)
I0113 15:28:18.450619 28435 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0113 15:29:01.835379 28435 solver.cpp:338] Iteration 17000, Testing net (#0)
I0113 15:30:57.455992 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38844
I0113 15:30:57.456054 28435 solver.cpp:406]     Test net output #1: loss = 1.25479 (* 1 = 1.25479 loss)
I0113 15:30:57.585929 28435 solver.cpp:229] Iteration 17000, loss = 1.34394
I0113 15:30:57.585971 28435 solver.cpp:245]     Train net output #0: loss = 1.34394 (* 1 = 1.34394 loss)
I0113 15:30:57.585978 28435 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0113 15:31:39.795796 28435 solver.cpp:229] Iteration 17200, loss = 1.37105
I0113 15:31:39.795872 28435 solver.cpp:245]     Train net output #0: loss = 1.37105 (* 1 = 1.37105 loss)
I0113 15:31:39.795877 28435 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0113 15:32:23.353833 28435 solver.cpp:229] Iteration 17400, loss = 1.34262
I0113 15:32:23.353893 28435 solver.cpp:245]     Train net output #0: loss = 1.34262 (* 1 = 1.34262 loss)
I0113 15:32:23.353899 28435 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0113 15:33:06.907481 28435 solver.cpp:229] Iteration 17600, loss = 1.27515
I0113 15:33:06.907541 28435 solver.cpp:245]     Train net output #0: loss = 1.27515 (* 1 = 1.27515 loss)
I0113 15:33:06.907546 28435 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0113 15:33:50.452661 28435 solver.cpp:229] Iteration 17800, loss = 1.31839
I0113 15:33:50.452754 28435 solver.cpp:245]     Train net output #0: loss = 1.31839 (* 1 = 1.31839 loss)
I0113 15:33:50.452760 28435 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0113 15:34:33.826416 28435 solver.cpp:338] Iteration 18000, Testing net (#0)
I0113 15:36:28.021945 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388608
I0113 15:36:28.022006 28435 solver.cpp:406]     Test net output #1: loss = 1.25464 (* 1 = 1.25464 loss)
I0113 15:36:28.155791 28435 solver.cpp:229] Iteration 18000, loss = 0.991749
I0113 15:36:28.155829 28435 solver.cpp:245]     Train net output #0: loss = 0.991749 (* 1 = 0.991749 loss)
I0113 15:36:28.155834 28435 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0113 15:37:11.704953 28435 solver.cpp:229] Iteration 18200, loss = 1.33709
I0113 15:37:11.705003 28435 solver.cpp:245]     Train net output #0: loss = 1.33709 (* 1 = 1.33709 loss)
I0113 15:37:11.705008 28435 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0113 15:37:55.255255 28435 solver.cpp:229] Iteration 18400, loss = 1.22462
I0113 15:37:55.255311 28435 solver.cpp:245]     Train net output #0: loss = 1.22462 (* 1 = 1.22462 loss)
I0113 15:37:55.255316 28435 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0113 15:38:37.458103 28435 solver.cpp:229] Iteration 18600, loss = 1.28574
I0113 15:38:37.458163 28435 solver.cpp:245]     Train net output #0: loss = 1.28574 (* 1 = 1.28574 loss)
I0113 15:38:37.458168 28435 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0113 15:39:21.039674 28435 solver.cpp:229] Iteration 18800, loss = 1.18534
I0113 15:39:21.039726 28435 solver.cpp:245]     Train net output #0: loss = 1.18534 (* 1 = 1.18534 loss)
I0113 15:39:21.039731 28435 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0113 15:40:04.388131 28435 solver.cpp:338] Iteration 19000, Testing net (#0)
I0113 15:41:59.047271 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38821
I0113 15:41:59.047325 28435 solver.cpp:406]     Test net output #1: loss = 1.25465 (* 1 = 1.25465 loss)
I0113 15:41:59.161448 28435 solver.cpp:229] Iteration 19000, loss = 1.21409
I0113 15:41:59.161491 28435 solver.cpp:245]     Train net output #0: loss = 1.21409 (* 1 = 1.21409 loss)
I0113 15:41:59.161497 28435 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0113 15:42:42.209007 28435 solver.cpp:229] Iteration 19200, loss = 1.238
I0113 15:42:42.209069 28435 solver.cpp:245]     Train net output #0: loss = 1.238 (* 1 = 1.238 loss)
I0113 15:42:42.209075 28435 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0113 15:43:25.743198 28435 solver.cpp:229] Iteration 19400, loss = 1.25498
I0113 15:43:25.743257 28435 solver.cpp:245]     Train net output #0: loss = 1.25498 (* 1 = 1.25498 loss)
I0113 15:43:25.743264 28435 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0113 15:44:09.301445 28435 solver.cpp:229] Iteration 19600, loss = 1.42389
I0113 15:44:09.301520 28435 solver.cpp:245]     Train net output #0: loss = 1.42389 (* 1 = 1.42389 loss)
I0113 15:44:09.301528 28435 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0113 15:44:52.852526 28435 solver.cpp:229] Iteration 19800, loss = 1.25407
I0113 15:44:52.852587 28435 solver.cpp:245]     Train net output #0: loss = 1.25407 (* 1 = 1.25407 loss)
I0113 15:44:52.852596 28435 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0113 15:45:36.191881 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_20000.caffemodel.h5
I0113 15:45:36.281431 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_20000.solverstate.h5
I0113 15:45:36.282132 28435 solver.cpp:338] Iteration 20000, Testing net (#0)
I0113 15:47:30.484421 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361434
I0113 15:47:30.484473 28435 solver.cpp:406]     Test net output #1: loss = 1.25598 (* 1 = 1.25598 loss)
I0113 15:47:30.611804 28435 solver.cpp:229] Iteration 20000, loss = 1.39973
I0113 15:47:30.611843 28435 solver.cpp:245]     Train net output #0: loss = 1.39973 (* 1 = 1.39973 loss)
I0113 15:47:30.611850 28435 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0113 15:48:14.173694 28435 solver.cpp:229] Iteration 20200, loss = 1.04558
I0113 15:48:14.173815 28435 solver.cpp:245]     Train net output #0: loss = 1.04558 (* 1 = 1.04558 loss)
I0113 15:48:14.173822 28435 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0113 15:48:57.717237 28435 solver.cpp:229] Iteration 20400, loss = 1.42947
I0113 15:48:57.717293 28435 solver.cpp:245]     Train net output #0: loss = 1.42947 (* 1 = 1.42947 loss)
I0113 15:48:57.717299 28435 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0113 15:49:39.920166 28435 solver.cpp:229] Iteration 20600, loss = 1.37356
I0113 15:49:39.920228 28435 solver.cpp:245]     Train net output #0: loss = 1.37356 (* 1 = 1.37356 loss)
I0113 15:49:39.920235 28435 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0113 15:50:23.470563 28435 solver.cpp:229] Iteration 20800, loss = 1.37747
I0113 15:50:23.470641 28435 solver.cpp:245]     Train net output #0: loss = 1.37747 (* 1 = 1.37747 loss)
I0113 15:50:23.470650 28435 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0113 15:51:06.807983 28435 solver.cpp:338] Iteration 21000, Testing net (#0)
I0113 15:53:01.073185 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388126
I0113 15:53:01.073238 28435 solver.cpp:406]     Test net output #1: loss = 1.25457 (* 1 = 1.25457 loss)
I0113 15:53:01.204572 28435 solver.cpp:229] Iteration 21000, loss = 1.40105
I0113 15:53:01.204614 28435 solver.cpp:245]     Train net output #0: loss = 1.40105 (* 1 = 1.40105 loss)
I0113 15:53:01.204622 28435 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0113 15:53:44.765174 28435 solver.cpp:229] Iteration 21200, loss = 1.17044
I0113 15:53:44.765235 28435 solver.cpp:245]     Train net output #0: loss = 1.17044 (* 1 = 1.17044 loss)
I0113 15:53:44.765242 28435 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0113 15:54:28.318612 28435 solver.cpp:229] Iteration 21400, loss = 1.40974
I0113 15:54:28.318675 28435 solver.cpp:245]     Train net output #0: loss = 1.40974 (* 1 = 1.40974 loss)
I0113 15:54:28.318681 28435 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0113 15:55:11.874933 28435 solver.cpp:229] Iteration 21600, loss = 1.21435
I0113 15:55:11.875005 28435 solver.cpp:245]     Train net output #0: loss = 1.21435 (* 1 = 1.21435 loss)
I0113 15:55:11.875012 28435 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0113 15:55:55.437507 28435 solver.cpp:229] Iteration 21800, loss = 1.28046
I0113 15:55:55.437567 28435 solver.cpp:245]     Train net output #0: loss = 1.28046 (* 1 = 1.28046 loss)
I0113 15:55:55.437573 28435 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0113 15:56:35.459743 28435 solver.cpp:338] Iteration 22000, Testing net (#0)
I0113 15:58:30.830596 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387986
I0113 15:58:30.830648 28435 solver.cpp:406]     Test net output #1: loss = 1.25477 (* 1 = 1.25477 loss)
I0113 15:58:30.949784 28435 solver.cpp:229] Iteration 22000, loss = 1.24694
I0113 15:58:30.949820 28435 solver.cpp:245]     Train net output #0: loss = 1.24694 (* 1 = 1.24694 loss)
I0113 15:58:30.949825 28435 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0113 15:59:14.508170 28435 solver.cpp:229] Iteration 22200, loss = 1.21278
I0113 15:59:14.508221 28435 solver.cpp:245]     Train net output #0: loss = 1.21278 (* 1 = 1.21278 loss)
I0113 15:59:14.508227 28435 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0113 15:59:57.709506 28435 solver.cpp:229] Iteration 22400, loss = 1.46842
I0113 15:59:57.709558 28435 solver.cpp:245]     Train net output #0: loss = 1.46842 (* 1 = 1.46842 loss)
I0113 15:59:57.709563 28435 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0113 16:00:40.281455 28435 solver.cpp:229] Iteration 22600, loss = 1.17135
I0113 16:00:40.281517 28435 solver.cpp:245]     Train net output #0: loss = 1.17135 (* 1 = 1.17135 loss)
I0113 16:00:40.281523 28435 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0113 16:01:23.862987 28435 solver.cpp:229] Iteration 22800, loss = 1.37835
I0113 16:01:23.863055 28435 solver.cpp:245]     Train net output #0: loss = 1.37835 (* 1 = 1.37835 loss)
I0113 16:01:23.863062 28435 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0113 16:02:07.220911 28435 solver.cpp:338] Iteration 23000, Testing net (#0)
I0113 16:04:01.449396 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388252
I0113 16:04:01.449446 28435 solver.cpp:406]     Test net output #1: loss = 1.25497 (* 1 = 1.25497 loss)
I0113 16:04:01.579378 28435 solver.cpp:229] Iteration 23000, loss = 1.4114
I0113 16:04:01.579421 28435 solver.cpp:245]     Train net output #0: loss = 1.4114 (* 1 = 1.4114 loss)
I0113 16:04:01.579427 28435 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0113 16:04:45.102185 28435 solver.cpp:229] Iteration 23200, loss = 1.18424
I0113 16:04:45.102296 28435 solver.cpp:245]     Train net output #0: loss = 1.18424 (* 1 = 1.18424 loss)
I0113 16:04:45.102304 28435 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0113 16:05:28.651171 28435 solver.cpp:229] Iteration 23400, loss = 1.44745
I0113 16:05:28.651278 28435 solver.cpp:245]     Train net output #0: loss = 1.44745 (* 1 = 1.44745 loss)
I0113 16:05:28.651289 28435 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0113 16:06:12.186120 28435 solver.cpp:229] Iteration 23600, loss = 1.24302
I0113 16:06:12.186187 28435 solver.cpp:245]     Train net output #0: loss = 1.24302 (* 1 = 1.24302 loss)
I0113 16:06:12.186194 28435 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0113 16:06:55.720971 28435 solver.cpp:229] Iteration 23800, loss = 1.21422
I0113 16:06:55.721042 28435 solver.cpp:245]     Train net output #0: loss = 1.21422 (* 1 = 1.21422 loss)
I0113 16:06:55.721050 28435 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0113 16:07:37.701860 28435 solver.cpp:338] Iteration 24000, Testing net (#0)
I0113 16:09:33.208649 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388496
I0113 16:09:33.208711 28435 solver.cpp:406]     Test net output #1: loss = 1.25436 (* 1 = 1.25436 loss)
I0113 16:09:33.332726 28435 solver.cpp:229] Iteration 24000, loss = 1.17427
I0113 16:09:33.332763 28435 solver.cpp:245]     Train net output #0: loss = 1.17427 (* 1 = 1.17427 loss)
I0113 16:09:33.332768 28435 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0113 16:10:16.864892 28435 solver.cpp:229] Iteration 24200, loss = 1.28528
I0113 16:10:16.864948 28435 solver.cpp:245]     Train net output #0: loss = 1.28528 (* 1 = 1.28528 loss)
I0113 16:10:16.864953 28435 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0113 16:10:59.080670 28435 solver.cpp:229] Iteration 24400, loss = 1.23838
I0113 16:10:59.080727 28435 solver.cpp:245]     Train net output #0: loss = 1.23838 (* 1 = 1.23838 loss)
I0113 16:10:59.080734 28435 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0113 16:11:42.649098 28435 solver.cpp:229] Iteration 24600, loss = 0.984456
I0113 16:11:42.649152 28435 solver.cpp:245]     Train net output #0: loss = 0.984456 (* 1 = 0.984456 loss)
I0113 16:11:42.649158 28435 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0113 16:12:26.223605 28435 solver.cpp:229] Iteration 24800, loss = 1.19968
I0113 16:12:26.223676 28435 solver.cpp:245]     Train net output #0: loss = 1.19968 (* 1 = 1.19968 loss)
I0113 16:12:26.223682 28435 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0113 16:13:09.589932 28435 solver.cpp:338] Iteration 25000, Testing net (#0)
I0113 16:15:03.725266 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388385
I0113 16:15:03.725324 28435 solver.cpp:406]     Test net output #1: loss = 1.25493 (* 1 = 1.25493 loss)
I0113 16:15:03.858917 28435 solver.cpp:229] Iteration 25000, loss = 1.24544
I0113 16:15:03.858954 28435 solver.cpp:245]     Train net output #0: loss = 1.24544 (* 1 = 1.24544 loss)
I0113 16:15:03.858959 28435 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0113 16:15:47.402129 28435 solver.cpp:229] Iteration 25200, loss = 1.09473
I0113 16:15:47.402187 28435 solver.cpp:245]     Train net output #0: loss = 1.09473 (* 1 = 1.09473 loss)
I0113 16:15:47.402194 28435 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0113 16:16:30.932914 28435 solver.cpp:229] Iteration 25400, loss = 1.45088
I0113 16:16:30.933001 28435 solver.cpp:245]     Train net output #0: loss = 1.45088 (* 1 = 1.45088 loss)
I0113 16:16:30.933007 28435 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0113 16:17:14.490497 28435 solver.cpp:229] Iteration 25600, loss = 1.40593
I0113 16:17:14.490557 28435 solver.cpp:245]     Train net output #0: loss = 1.40593 (* 1 = 1.40593 loss)
I0113 16:17:14.490562 28435 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0113 16:17:56.685384 28435 solver.cpp:229] Iteration 25800, loss = 1.18304
I0113 16:17:56.685453 28435 solver.cpp:245]     Train net output #0: loss = 1.18304 (* 1 = 1.18304 loss)
I0113 16:17:56.685459 28435 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0113 16:18:40.018759 28435 solver.cpp:338] Iteration 26000, Testing net (#0)
I0113 16:20:35.547899 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388518
I0113 16:20:35.547952 28435 solver.cpp:406]     Test net output #1: loss = 1.25416 (* 1 = 1.25416 loss)
I0113 16:20:35.666923 28435 solver.cpp:229] Iteration 26000, loss = 1.13922
I0113 16:20:35.666960 28435 solver.cpp:245]     Train net output #0: loss = 1.13922 (* 1 = 1.13922 loss)
I0113 16:20:35.666966 28435 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0113 16:21:18.613013 28435 solver.cpp:229] Iteration 26200, loss = 1.10958
I0113 16:21:18.613106 28435 solver.cpp:245]     Train net output #0: loss = 1.10958 (* 1 = 1.10958 loss)
I0113 16:21:18.613114 28435 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0113 16:22:01.423713 28435 solver.cpp:229] Iteration 26400, loss = 1.41042
I0113 16:22:01.423773 28435 solver.cpp:245]     Train net output #0: loss = 1.41042 (* 1 = 1.41042 loss)
I0113 16:22:01.423779 28435 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0113 16:22:44.991120 28435 solver.cpp:229] Iteration 26600, loss = 1.22534
I0113 16:22:44.991181 28435 solver.cpp:245]     Train net output #0: loss = 1.22534 (* 1 = 1.22534 loss)
I0113 16:22:44.991188 28435 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0113 16:23:28.545488 28435 solver.cpp:229] Iteration 26800, loss = 1.03943
I0113 16:23:28.545559 28435 solver.cpp:245]     Train net output #0: loss = 1.03943 (* 1 = 1.03943 loss)
I0113 16:23:28.545567 28435 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0113 16:24:11.857070 28435 solver.cpp:338] Iteration 27000, Testing net (#0)
I0113 16:26:06.046301 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361357
I0113 16:26:06.046361 28435 solver.cpp:406]     Test net output #1: loss = 1.2562 (* 1 = 1.2562 loss)
I0113 16:26:06.175981 28435 solver.cpp:229] Iteration 27000, loss = 1.39379
I0113 16:26:06.176023 28435 solver.cpp:245]     Train net output #0: loss = 1.39379 (* 1 = 1.39379 loss)
I0113 16:26:06.176028 28435 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0113 16:26:49.729413 28435 solver.cpp:229] Iteration 27200, loss = 1.44268
I0113 16:26:49.729475 28435 solver.cpp:245]     Train net output #0: loss = 1.44268 (* 1 = 1.44268 loss)
I0113 16:26:49.729485 28435 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0113 16:27:33.270154 28435 solver.cpp:229] Iteration 27400, loss = 1.18837
I0113 16:27:33.270220 28435 solver.cpp:245]     Train net output #0: loss = 1.18837 (* 1 = 1.18837 loss)
I0113 16:27:33.270228 28435 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0113 16:28:16.810940 28435 solver.cpp:229] Iteration 27600, loss = 1.25495
I0113 16:28:16.811010 28435 solver.cpp:245]     Train net output #0: loss = 1.25495 (* 1 = 1.25495 loss)
I0113 16:28:16.811017 28435 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0113 16:28:59.032843 28435 solver.cpp:229] Iteration 27800, loss = 1.46294
I0113 16:28:59.032899 28435 solver.cpp:245]     Train net output #0: loss = 1.46294 (* 1 = 1.46294 loss)
I0113 16:28:59.032905 28435 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0113 16:29:42.380962 28435 solver.cpp:338] Iteration 28000, Testing net (#0)
I0113 16:31:37.898937 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388371
I0113 16:31:37.899001 28435 solver.cpp:406]     Test net output #1: loss = 1.25462 (* 1 = 1.25462 loss)
I0113 16:31:38.032440 28435 solver.cpp:229] Iteration 28000, loss = 1.39413
I0113 16:31:38.032479 28435 solver.cpp:245]     Train net output #0: loss = 1.39413 (* 1 = 1.39413 loss)
I0113 16:31:38.032490 28435 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0113 16:32:11.088636 28435 solver.cpp:229] Iteration 28200, loss = 1.28972
I0113 16:32:11.088717 28435 solver.cpp:245]     Train net output #0: loss = 1.28972 (* 1 = 1.28972 loss)
I0113 16:32:11.088723 28435 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0113 16:32:31.889509 28435 solver.cpp:229] Iteration 28400, loss = 1.1472
I0113 16:32:31.889550 28435 solver.cpp:245]     Train net output #0: loss = 1.1472 (* 1 = 1.1472 loss)
I0113 16:32:31.889556 28435 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0113 16:32:52.682833 28435 solver.cpp:229] Iteration 28600, loss = 1.38232
I0113 16:32:52.682890 28435 solver.cpp:245]     Train net output #0: loss = 1.38232 (* 1 = 1.38232 loss)
I0113 16:32:52.682896 28435 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0113 16:33:13.493752 28435 solver.cpp:229] Iteration 28800, loss = 1.04773
I0113 16:33:13.493793 28435 solver.cpp:245]     Train net output #0: loss = 1.04773 (* 1 = 1.04773 loss)
I0113 16:33:13.493799 28435 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0113 16:33:34.189244 28435 solver.cpp:338] Iteration 29000, Testing net (#0)
I0113 16:34:20.545933 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387685
I0113 16:34:20.546006 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 16:34:20.601676 28435 solver.cpp:229] Iteration 29000, loss = 1.32963
I0113 16:34:20.601716 28435 solver.cpp:245]     Train net output #0: loss = 1.32963 (* 1 = 1.32963 loss)
I0113 16:34:20.601722 28435 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0113 16:34:41.404395 28435 solver.cpp:229] Iteration 29200, loss = 1.20308
I0113 16:34:41.404435 28435 solver.cpp:245]     Train net output #0: loss = 1.20308 (* 1 = 1.20308 loss)
I0113 16:34:41.404440 28435 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0113 16:35:02.213999 28435 solver.cpp:229] Iteration 29400, loss = 1.35578
I0113 16:35:02.214083 28435 solver.cpp:245]     Train net output #0: loss = 1.35578 (* 1 = 1.35578 loss)
I0113 16:35:02.214089 28435 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0113 16:35:23.011978 28435 solver.cpp:229] Iteration 29600, loss = 1.15282
I0113 16:35:23.012017 28435 solver.cpp:245]     Train net output #0: loss = 1.15282 (* 1 = 1.15282 loss)
I0113 16:35:23.012023 28435 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0113 16:35:43.821616 28435 solver.cpp:229] Iteration 29800, loss = 1.12975
I0113 16:35:43.821717 28435 solver.cpp:245]     Train net output #0: loss = 1.12975 (* 1 = 1.12975 loss)
I0113 16:35:43.821723 28435 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0113 16:36:04.526041 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_30000.caffemodel.h5
I0113 16:36:04.575134 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_30000.solverstate.h5
I0113 16:36:04.575798 28435 solver.cpp:338] Iteration 30000, Testing net (#0)
I0113 16:36:50.931920 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388685
I0113 16:36:50.931972 28435 solver.cpp:406]     Test net output #1: loss = 1.25461 (* 1 = 1.25461 loss)
I0113 16:36:50.987665 28435 solver.cpp:229] Iteration 30000, loss = 1.16133
I0113 16:36:50.987702 28435 solver.cpp:245]     Train net output #0: loss = 1.16133 (* 1 = 1.16133 loss)
I0113 16:36:50.987707 28435 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0113 16:37:11.784524 28435 solver.cpp:229] Iteration 30200, loss = 1.23071
I0113 16:37:11.784565 28435 solver.cpp:245]     Train net output #0: loss = 1.23071 (* 1 = 1.23071 loss)
I0113 16:37:11.784571 28435 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I0113 16:37:32.594375 28435 solver.cpp:229] Iteration 30400, loss = 1.0455
I0113 16:37:32.594434 28435 solver.cpp:245]     Train net output #0: loss = 1.0455 (* 1 = 1.0455 loss)
I0113 16:37:32.594441 28435 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I0113 16:37:53.396534 28435 solver.cpp:229] Iteration 30600, loss = 1.39218
I0113 16:37:53.396572 28435 solver.cpp:245]     Train net output #0: loss = 1.39218 (* 1 = 1.39218 loss)
I0113 16:37:53.396589 28435 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0113 16:38:14.204644 28435 solver.cpp:229] Iteration 30800, loss = 1.25951
I0113 16:38:14.204761 28435 solver.cpp:245]     Train net output #0: loss = 1.25951 (* 1 = 1.25951 loss)
I0113 16:38:14.204767 28435 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I0113 16:38:34.909246 28435 solver.cpp:338] Iteration 31000, Testing net (#0)
I0113 16:39:21.315521 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38851
I0113 16:39:21.315609 28435 solver.cpp:406]     Test net output #1: loss = 1.25464 (* 1 = 1.25464 loss)
I0113 16:39:21.371322 28435 solver.cpp:229] Iteration 31000, loss = 1.20774
I0113 16:39:21.371361 28435 solver.cpp:245]     Train net output #0: loss = 1.20774 (* 1 = 1.20774 loss)
I0113 16:39:21.371366 28435 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0113 16:39:42.172219 28435 solver.cpp:229] Iteration 31200, loss = 1.25109
I0113 16:39:42.172258 28435 solver.cpp:245]     Train net output #0: loss = 1.25109 (* 1 = 1.25109 loss)
I0113 16:39:42.172263 28435 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0113 16:40:02.982390 28435 solver.cpp:229] Iteration 31400, loss = 1.28879
I0113 16:40:02.982444 28435 solver.cpp:245]     Train net output #0: loss = 1.28879 (* 1 = 1.28879 loss)
I0113 16:40:02.982450 28435 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
I0113 16:40:23.787894 28435 solver.cpp:229] Iteration 31600, loss = 1.21631
I0113 16:40:23.787935 28435 solver.cpp:245]     Train net output #0: loss = 1.21631 (* 1 = 1.21631 loss)
I0113 16:40:23.787940 28435 sgd_solver.cpp:106] Iteration 31600, lr = 0.001
I0113 16:40:44.585585 28435 solver.cpp:229] Iteration 31800, loss = 1.32235
I0113 16:40:44.585644 28435 solver.cpp:245]     Train net output #0: loss = 1.32235 (* 1 = 1.32235 loss)
I0113 16:40:44.585650 28435 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0113 16:41:05.301131 28435 solver.cpp:338] Iteration 32000, Testing net (#0)
I0113 16:41:51.712472 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388049
I0113 16:41:51.712522 28435 solver.cpp:406]     Test net output #1: loss = 1.25482 (* 1 = 1.25482 loss)
I0113 16:41:51.768241 28435 solver.cpp:229] Iteration 32000, loss = 1.19878
I0113 16:41:51.768271 28435 solver.cpp:245]     Train net output #0: loss = 1.19878 (* 1 = 1.19878 loss)
I0113 16:41:51.768277 28435 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0113 16:42:12.579320 28435 solver.cpp:229] Iteration 32200, loss = 1.37369
I0113 16:42:12.579362 28435 solver.cpp:245]     Train net output #0: loss = 1.37369 (* 1 = 1.37369 loss)
I0113 16:42:12.579370 28435 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0113 16:42:33.380605 28435 solver.cpp:229] Iteration 32400, loss = 1.18465
I0113 16:42:33.380658 28435 solver.cpp:245]     Train net output #0: loss = 1.18465 (* 1 = 1.18465 loss)
I0113 16:42:33.380664 28435 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0113 16:42:54.189821 28435 solver.cpp:229] Iteration 32600, loss = 1.18884
I0113 16:42:54.189860 28435 solver.cpp:245]     Train net output #0: loss = 1.18884 (* 1 = 1.18884 loss)
I0113 16:42:54.189865 28435 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0113 16:43:14.991602 28435 solver.cpp:229] Iteration 32800, loss = 1.10578
I0113 16:43:14.991654 28435 solver.cpp:245]     Train net output #0: loss = 1.10578 (* 1 = 1.10578 loss)
I0113 16:43:14.991662 28435 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0113 16:43:35.698676 28435 solver.cpp:338] Iteration 33000, Testing net (#0)
I0113 16:44:22.097837 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388168
I0113 16:44:22.097916 28435 solver.cpp:406]     Test net output #1: loss = 1.25481 (* 1 = 1.25481 loss)
I0113 16:44:22.153606 28435 solver.cpp:229] Iteration 33000, loss = 1.2773
I0113 16:44:22.153645 28435 solver.cpp:245]     Train net output #0: loss = 1.2773 (* 1 = 1.2773 loss)
I0113 16:44:22.153650 28435 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0113 16:44:42.961875 28435 solver.cpp:229] Iteration 33200, loss = 1.41343
I0113 16:44:42.961917 28435 solver.cpp:245]     Train net output #0: loss = 1.41343 (* 1 = 1.41343 loss)
I0113 16:44:42.961930 28435 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0113 16:45:03.765092 28435 solver.cpp:229] Iteration 33400, loss = 1.44686
I0113 16:45:03.765179 28435 solver.cpp:245]     Train net output #0: loss = 1.44686 (* 1 = 1.44686 loss)
I0113 16:45:03.765187 28435 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0113 16:45:24.575906 28435 solver.cpp:229] Iteration 33600, loss = 1.22549
I0113 16:45:24.575945 28435 solver.cpp:245]     Train net output #0: loss = 1.22549 (* 1 = 1.22549 loss)
I0113 16:45:24.575951 28435 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0113 16:45:45.378006 28435 solver.cpp:229] Iteration 33800, loss = 1.39153
I0113 16:45:45.378074 28435 solver.cpp:245]     Train net output #0: loss = 1.39153 (* 1 = 1.39153 loss)
I0113 16:45:45.378080 28435 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0113 16:46:06.074268 28435 solver.cpp:338] Iteration 34000, Testing net (#0)
I0113 16:46:52.461354 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361524
I0113 16:46:52.461431 28435 solver.cpp:406]     Test net output #1: loss = 1.25578 (* 1 = 1.25578 loss)
I0113 16:46:52.517199 28435 solver.cpp:229] Iteration 34000, loss = 1.18108
I0113 16:46:52.517237 28435 solver.cpp:245]     Train net output #0: loss = 1.18108 (* 1 = 1.18108 loss)
I0113 16:46:52.517242 28435 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0113 16:47:13.331887 28435 solver.cpp:229] Iteration 34200, loss = 1.22682
I0113 16:47:13.331926 28435 solver.cpp:245]     Train net output #0: loss = 1.22682 (* 1 = 1.22682 loss)
I0113 16:47:13.331933 28435 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0113 16:47:34.132894 28435 solver.cpp:229] Iteration 34400, loss = 1.12219
I0113 16:47:34.132982 28435 solver.cpp:245]     Train net output #0: loss = 1.12219 (* 1 = 1.12219 loss)
I0113 16:47:34.132988 28435 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0113 16:47:54.939640 28435 solver.cpp:229] Iteration 34600, loss = 1.2505
I0113 16:47:54.939680 28435 solver.cpp:245]     Train net output #0: loss = 1.2505 (* 1 = 1.2505 loss)
I0113 16:47:54.939685 28435 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0113 16:48:15.749264 28435 solver.cpp:229] Iteration 34800, loss = 1.42011
I0113 16:48:15.749348 28435 solver.cpp:245]     Train net output #0: loss = 1.42011 (* 1 = 1.42011 loss)
I0113 16:48:15.749354 28435 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0113 16:48:36.445927 28435 solver.cpp:338] Iteration 35000, Testing net (#0)
I0113 16:49:22.836030 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388322
I0113 16:49:22.836113 28435 solver.cpp:406]     Test net output #1: loss = 1.25475 (* 1 = 1.25475 loss)
I0113 16:49:22.891849 28435 solver.cpp:229] Iteration 35000, loss = 1.11129
I0113 16:49:22.891885 28435 solver.cpp:245]     Train net output #0: loss = 1.11129 (* 1 = 1.11129 loss)
I0113 16:49:22.891890 28435 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0113 16:49:43.704573 28435 solver.cpp:229] Iteration 35200, loss = 1.2676
I0113 16:49:43.704612 28435 solver.cpp:245]     Train net output #0: loss = 1.2676 (* 1 = 1.2676 loss)
I0113 16:49:43.704619 28435 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0113 16:50:04.514793 28435 solver.cpp:229] Iteration 35400, loss = 1.29996
I0113 16:50:04.514845 28435 solver.cpp:245]     Train net output #0: loss = 1.29996 (* 1 = 1.29996 loss)
I0113 16:50:04.514852 28435 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0113 16:50:25.312814 28435 solver.cpp:229] Iteration 35600, loss = 1.25355
I0113 16:50:25.312855 28435 solver.cpp:245]     Train net output #0: loss = 1.25355 (* 1 = 1.25355 loss)
I0113 16:50:25.312860 28435 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0113 16:50:46.123790 28435 solver.cpp:229] Iteration 35800, loss = 1.42109
I0113 16:50:46.123839 28435 solver.cpp:245]     Train net output #0: loss = 1.42109 (* 1 = 1.42109 loss)
I0113 16:50:46.123845 28435 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0113 16:51:06.830343 28435 solver.cpp:338] Iteration 36000, Testing net (#0)
I0113 16:51:53.197300 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388566
I0113 16:51:53.197388 28435 solver.cpp:406]     Test net output #1: loss = 1.25444 (* 1 = 1.25444 loss)
I0113 16:51:53.253151 28435 solver.cpp:229] Iteration 36000, loss = 1.30403
I0113 16:51:53.253188 28435 solver.cpp:245]     Train net output #0: loss = 1.30403 (* 1 = 1.30403 loss)
I0113 16:51:53.253193 28435 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0113 16:52:14.058545 28435 solver.cpp:229] Iteration 36200, loss = 1.40457
I0113 16:52:14.058588 28435 solver.cpp:245]     Train net output #0: loss = 1.40457 (* 1 = 1.40457 loss)
I0113 16:52:14.058593 28435 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0113 16:52:34.865635 28435 solver.cpp:229] Iteration 36400, loss = 1.15
I0113 16:52:34.865703 28435 solver.cpp:245]     Train net output #0: loss = 1.15 (* 1 = 1.15 loss)
I0113 16:52:34.865710 28435 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0113 16:52:55.665081 28435 solver.cpp:229] Iteration 36600, loss = 1.29691
I0113 16:52:55.665120 28435 solver.cpp:245]     Train net output #0: loss = 1.29691 (* 1 = 1.29691 loss)
I0113 16:52:55.665127 28435 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0113 16:53:16.482395 28435 solver.cpp:229] Iteration 36800, loss = 1.29917
I0113 16:53:16.482456 28435 solver.cpp:245]     Train net output #0: loss = 1.29917 (* 1 = 1.29917 loss)
I0113 16:53:16.482462 28435 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0113 16:53:37.183790 28435 solver.cpp:338] Iteration 37000, Testing net (#0)
I0113 16:54:23.570147 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388105
I0113 16:54:23.570199 28435 solver.cpp:406]     Test net output #1: loss = 1.25475 (* 1 = 1.25475 loss)
I0113 16:54:23.625900 28435 solver.cpp:229] Iteration 37000, loss = 1.28209
I0113 16:54:23.625939 28435 solver.cpp:245]     Train net output #0: loss = 1.28209 (* 1 = 1.28209 loss)
I0113 16:54:23.625944 28435 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0113 16:54:44.425009 28435 solver.cpp:229] Iteration 37200, loss = 1.19756
I0113 16:54:44.425050 28435 solver.cpp:245]     Train net output #0: loss = 1.19756 (* 1 = 1.19756 loss)
I0113 16:54:44.425057 28435 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0113 16:55:05.238298 28435 solver.cpp:229] Iteration 37400, loss = 1.28796
I0113 16:55:05.238350 28435 solver.cpp:245]     Train net output #0: loss = 1.28796 (* 1 = 1.28796 loss)
I0113 16:55:05.238356 28435 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0113 16:55:26.043359 28435 solver.cpp:229] Iteration 37600, loss = 1.32847
I0113 16:55:26.043398 28435 solver.cpp:245]     Train net output #0: loss = 1.32847 (* 1 = 1.32847 loss)
I0113 16:55:26.043404 28435 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0113 16:55:46.847213 28435 solver.cpp:229] Iteration 37800, loss = 1.1753
I0113 16:55:46.847308 28435 solver.cpp:245]     Train net output #0: loss = 1.1753 (* 1 = 1.1753 loss)
I0113 16:55:46.847314 28435 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0113 16:56:07.559178 28435 solver.cpp:338] Iteration 38000, Testing net (#0)
I0113 16:56:53.950176 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388699
I0113 16:56:53.950258 28435 solver.cpp:406]     Test net output #1: loss = 1.25462 (* 1 = 1.25462 loss)
I0113 16:56:54.005915 28435 solver.cpp:229] Iteration 38000, loss = 1.24569
I0113 16:56:54.005952 28435 solver.cpp:245]     Train net output #0: loss = 1.24569 (* 1 = 1.24569 loss)
I0113 16:56:54.005957 28435 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0113 16:57:14.812382 28435 solver.cpp:229] Iteration 38200, loss = 1.34343
I0113 16:57:14.812425 28435 solver.cpp:245]     Train net output #0: loss = 1.34343 (* 1 = 1.34343 loss)
I0113 16:57:14.812432 28435 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0113 16:57:35.624352 28435 solver.cpp:229] Iteration 38400, loss = 1.05587
I0113 16:57:35.624404 28435 solver.cpp:245]     Train net output #0: loss = 1.05587 (* 1 = 1.05587 loss)
I0113 16:57:35.624410 28435 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0113 16:57:56.429752 28435 solver.cpp:229] Iteration 38600, loss = 1.20356
I0113 16:57:56.429792 28435 solver.cpp:245]     Train net output #0: loss = 1.20356 (* 1 = 1.20356 loss)
I0113 16:57:56.429797 28435 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0113 16:58:17.229197 28435 solver.cpp:229] Iteration 38800, loss = 1.11758
I0113 16:58:17.229310 28435 solver.cpp:245]     Train net output #0: loss = 1.11758 (* 1 = 1.11758 loss)
I0113 16:58:17.229316 28435 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0113 16:58:37.939527 28435 solver.cpp:338] Iteration 39000, Testing net (#0)
I0113 16:59:24.303809 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38772
I0113 16:59:24.303867 28435 solver.cpp:406]     Test net output #1: loss = 1.25483 (* 1 = 1.25483 loss)
I0113 16:59:24.359586 28435 solver.cpp:229] Iteration 39000, loss = 1.25492
I0113 16:59:24.359622 28435 solver.cpp:245]     Train net output #0: loss = 1.25492 (* 1 = 1.25492 loss)
I0113 16:59:24.359627 28435 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0113 16:59:45.167397 28435 solver.cpp:229] Iteration 39200, loss = 1.41276
I0113 16:59:45.167438 28435 solver.cpp:245]     Train net output #0: loss = 1.41276 (* 1 = 1.41276 loss)
I0113 16:59:45.167443 28435 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0113 17:00:05.977812 28435 solver.cpp:229] Iteration 39400, loss = 1.21446
I0113 17:00:05.977864 28435 solver.cpp:245]     Train net output #0: loss = 1.21446 (* 1 = 1.21446 loss)
I0113 17:00:05.977870 28435 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0113 17:00:26.796270 28435 solver.cpp:229] Iteration 39600, loss = 1.14475
I0113 17:00:26.796313 28435 solver.cpp:245]     Train net output #0: loss = 1.14475 (* 1 = 1.14475 loss)
I0113 17:00:26.796319 28435 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0113 17:00:47.611893 28435 solver.cpp:229] Iteration 39800, loss = 1.11943
I0113 17:00:47.611945 28435 solver.cpp:245]     Train net output #0: loss = 1.11943 (* 1 = 1.11943 loss)
I0113 17:00:47.611951 28435 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0113 17:01:08.329154 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_40000.caffemodel.h5
I0113 17:01:08.378347 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_40000.solverstate.h5
I0113 17:01:08.378996 28435 solver.cpp:338] Iteration 40000, Testing net (#0)
I0113 17:01:54.695648 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388524
I0113 17:01:54.695724 28435 solver.cpp:406]     Test net output #1: loss = 1.25486 (* 1 = 1.25486 loss)
I0113 17:01:54.751476 28435 solver.cpp:229] Iteration 40000, loss = 1.19428
I0113 17:01:54.751510 28435 solver.cpp:245]     Train net output #0: loss = 1.19428 (* 1 = 1.19428 loss)
I0113 17:01:54.751516 28435 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0113 17:02:15.576043 28435 solver.cpp:229] Iteration 40200, loss = 1.29943
I0113 17:02:15.576086 28435 solver.cpp:245]     Train net output #0: loss = 1.29943 (* 1 = 1.29943 loss)
I0113 17:02:15.576091 28435 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0113 17:02:36.385823 28435 solver.cpp:229] Iteration 40400, loss = 1.36557
I0113 17:02:36.385875 28435 solver.cpp:245]     Train net output #0: loss = 1.36557 (* 1 = 1.36557 loss)
I0113 17:02:36.385881 28435 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0113 17:02:57.211452 28435 solver.cpp:229] Iteration 40600, loss = 1.19444
I0113 17:02:57.211490 28435 solver.cpp:245]     Train net output #0: loss = 1.19444 (* 1 = 1.19444 loss)
I0113 17:02:57.211496 28435 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0113 17:03:18.034232 28435 solver.cpp:229] Iteration 40800, loss = 1.46726
I0113 17:03:18.034303 28435 solver.cpp:245]     Train net output #0: loss = 1.46726 (* 1 = 1.46726 loss)
I0113 17:03:18.034310 28435 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0113 17:03:38.745111 28435 solver.cpp:338] Iteration 41000, Testing net (#0)
I0113 17:04:25.122735 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361664
I0113 17:04:25.122830 28435 solver.cpp:406]     Test net output #1: loss = 1.25561 (* 1 = 1.25561 loss)
I0113 17:04:25.178588 28435 solver.cpp:229] Iteration 41000, loss = 1.19386
I0113 17:04:25.178625 28435 solver.cpp:245]     Train net output #0: loss = 1.19386 (* 1 = 1.19386 loss)
I0113 17:04:25.178630 28435 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0113 17:04:46.001880 28435 solver.cpp:229] Iteration 41200, loss = 1.12952
I0113 17:04:46.001924 28435 solver.cpp:245]     Train net output #0: loss = 1.12952 (* 1 = 1.12952 loss)
I0113 17:04:46.001929 28435 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0113 17:05:06.824991 28435 solver.cpp:229] Iteration 41400, loss = 1.35186
I0113 17:05:06.825069 28435 solver.cpp:245]     Train net output #0: loss = 1.35186 (* 1 = 1.35186 loss)
I0113 17:05:06.825076 28435 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0113 17:05:27.644393 28435 solver.cpp:229] Iteration 41600, loss = 1.31151
I0113 17:05:27.644433 28435 solver.cpp:245]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I0113 17:05:27.644440 28435 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0113 17:05:48.464148 28435 solver.cpp:229] Iteration 41800, loss = 1.39929
I0113 17:05:48.464198 28435 solver.cpp:245]     Train net output #0: loss = 1.39929 (* 1 = 1.39929 loss)
I0113 17:05:48.464205 28435 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0113 17:06:09.178473 28435 solver.cpp:338] Iteration 42000, Testing net (#0)
I0113 17:06:55.528132 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388112
I0113 17:06:55.528185 28435 solver.cpp:406]     Test net output #1: loss = 1.25466 (* 1 = 1.25466 loss)
I0113 17:06:55.583912 28435 solver.cpp:229] Iteration 42000, loss = 1.23807
I0113 17:06:55.583950 28435 solver.cpp:245]     Train net output #0: loss = 1.23807 (* 1 = 1.23807 loss)
I0113 17:06:55.583955 28435 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0113 17:07:16.400775 28435 solver.cpp:229] Iteration 42200, loss = 1.16363
I0113 17:07:16.400817 28435 solver.cpp:245]     Train net output #0: loss = 1.16363 (* 1 = 1.16363 loss)
I0113 17:07:16.400823 28435 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0113 17:07:37.210937 28435 solver.cpp:229] Iteration 42400, loss = 1.3553
I0113 17:07:37.210989 28435 solver.cpp:245]     Train net output #0: loss = 1.3553 (* 1 = 1.3553 loss)
I0113 17:07:37.210995 28435 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0113 17:07:58.021865 28435 solver.cpp:229] Iteration 42600, loss = 1.16267
I0113 17:07:58.021908 28435 solver.cpp:245]     Train net output #0: loss = 1.16267 (* 1 = 1.16267 loss)
I0113 17:07:58.021914 28435 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0113 17:08:18.837375 28435 solver.cpp:229] Iteration 42800, loss = 1.30009
I0113 17:08:18.837425 28435 solver.cpp:245]     Train net output #0: loss = 1.30009 (* 1 = 1.30009 loss)
I0113 17:08:18.837431 28435 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0113 17:08:39.541486 28435 solver.cpp:338] Iteration 43000, Testing net (#0)
I0113 17:09:25.935423 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388266
I0113 17:09:25.935523 28435 solver.cpp:406]     Test net output #1: loss = 1.25458 (* 1 = 1.25458 loss)
I0113 17:09:25.991284 28435 solver.cpp:229] Iteration 43000, loss = 1.38089
I0113 17:09:25.991323 28435 solver.cpp:245]     Train net output #0: loss = 1.38089 (* 1 = 1.38089 loss)
I0113 17:09:25.991328 28435 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0113 17:09:46.799319 28435 solver.cpp:229] Iteration 43200, loss = 1.084
I0113 17:09:46.799358 28435 solver.cpp:245]     Train net output #0: loss = 1.084 (* 1 = 1.084 loss)
I0113 17:09:46.799365 28435 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0113 17:10:07.609413 28435 solver.cpp:229] Iteration 43400, loss = 1.20545
I0113 17:10:07.609467 28435 solver.cpp:245]     Train net output #0: loss = 1.20545 (* 1 = 1.20545 loss)
I0113 17:10:07.609472 28435 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0113 17:10:28.410702 28435 solver.cpp:229] Iteration 43600, loss = 1.50827
I0113 17:10:28.410742 28435 solver.cpp:245]     Train net output #0: loss = 1.50827 (* 1 = 1.50827 loss)
I0113 17:10:28.410748 28435 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0113 17:10:49.224128 28435 solver.cpp:229] Iteration 43800, loss = 1.43814
I0113 17:10:49.224212 28435 solver.cpp:245]     Train net output #0: loss = 1.43814 (* 1 = 1.43814 loss)
I0113 17:10:49.224220 28435 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0113 17:11:09.936640 28435 solver.cpp:338] Iteration 44000, Testing net (#0)
I0113 17:11:56.336637 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388441
I0113 17:11:56.336690 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 17:11:56.392477 28435 solver.cpp:229] Iteration 44000, loss = 1.51873
I0113 17:11:56.392513 28435 solver.cpp:245]     Train net output #0: loss = 1.51873 (* 1 = 1.51873 loss)
I0113 17:11:56.392518 28435 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0113 17:12:17.200121 28435 solver.cpp:229] Iteration 44200, loss = 1.32571
I0113 17:12:17.200161 28435 solver.cpp:245]     Train net output #0: loss = 1.32571 (* 1 = 1.32571 loss)
I0113 17:12:17.200167 28435 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0113 17:12:38.015547 28435 solver.cpp:229] Iteration 44400, loss = 1.22407
I0113 17:12:38.015597 28435 solver.cpp:245]     Train net output #0: loss = 1.22407 (* 1 = 1.22407 loss)
I0113 17:12:38.015604 28435 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0113 17:12:58.821933 28435 solver.cpp:229] Iteration 44600, loss = 1.14538
I0113 17:12:58.821972 28435 solver.cpp:245]     Train net output #0: loss = 1.14538 (* 1 = 1.14538 loss)
I0113 17:12:58.821979 28435 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0113 17:13:19.628433 28435 solver.cpp:229] Iteration 44800, loss = 1.69986
I0113 17:13:19.628505 28435 solver.cpp:245]     Train net output #0: loss = 1.69986 (* 1 = 1.69986 loss)
I0113 17:13:19.628510 28435 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0113 17:13:40.336061 28435 solver.cpp:338] Iteration 45000, Testing net (#0)
I0113 17:14:26.738041 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388587
I0113 17:14:26.738142 28435 solver.cpp:406]     Test net output #1: loss = 1.25468 (* 1 = 1.25468 loss)
I0113 17:14:26.793978 28435 solver.cpp:229] Iteration 45000, loss = 1.04644
I0113 17:14:26.794014 28435 solver.cpp:245]     Train net output #0: loss = 1.04644 (* 1 = 1.04644 loss)
I0113 17:14:26.794019 28435 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0113 17:14:47.595808 28435 solver.cpp:229] Iteration 45200, loss = 1.17146
I0113 17:14:47.595847 28435 solver.cpp:245]     Train net output #0: loss = 1.17146 (* 1 = 1.17146 loss)
I0113 17:14:47.595854 28435 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0113 17:15:08.415994 28435 solver.cpp:229] Iteration 45400, loss = 1.37668
I0113 17:15:08.416059 28435 solver.cpp:245]     Train net output #0: loss = 1.37668 (* 1 = 1.37668 loss)
I0113 17:15:08.416065 28435 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0113 17:15:29.223904 28435 solver.cpp:229] Iteration 45600, loss = 1.24768
I0113 17:15:29.223943 28435 solver.cpp:245]     Train net output #0: loss = 1.24768 (* 1 = 1.24768 loss)
I0113 17:15:29.223949 28435 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0113 17:15:50.026964 28435 solver.cpp:229] Iteration 45800, loss = 1.16378
I0113 17:15:50.027062 28435 solver.cpp:245]     Train net output #0: loss = 1.16378 (* 1 = 1.16378 loss)
I0113 17:15:50.027067 28435 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0113 17:16:10.742058 28435 solver.cpp:338] Iteration 46000, Testing net (#0)
I0113 17:16:57.141356 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388182
I0113 17:16:57.141429 28435 solver.cpp:406]     Test net output #1: loss = 1.25474 (* 1 = 1.25474 loss)
I0113 17:16:57.197271 28435 solver.cpp:229] Iteration 46000, loss = 1.28219
I0113 17:16:57.197309 28435 solver.cpp:245]     Train net output #0: loss = 1.28219 (* 1 = 1.28219 loss)
I0113 17:16:57.197314 28435 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0113 17:17:18.005429 28435 solver.cpp:229] Iteration 46200, loss = 1.13406
I0113 17:17:18.005470 28435 solver.cpp:245]     Train net output #0: loss = 1.13406 (* 1 = 1.13406 loss)
I0113 17:17:18.005481 28435 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0113 17:17:38.810537 28435 solver.cpp:229] Iteration 46400, loss = 1.12555
I0113 17:17:38.810647 28435 solver.cpp:245]     Train net output #0: loss = 1.12555 (* 1 = 1.12555 loss)
I0113 17:17:38.810652 28435 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0113 17:17:59.623193 28435 solver.cpp:229] Iteration 46600, loss = 1.21497
I0113 17:17:59.623234 28435 solver.cpp:245]     Train net output #0: loss = 1.21497 (* 1 = 1.21497 loss)
I0113 17:17:59.623240 28435 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0113 17:18:20.436075 28435 solver.cpp:229] Iteration 46800, loss = 1.37747
I0113 17:18:20.436130 28435 solver.cpp:245]     Train net output #0: loss = 1.37747 (* 1 = 1.37747 loss)
I0113 17:18:20.436136 28435 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0113 17:18:41.145337 28435 solver.cpp:338] Iteration 47000, Testing net (#0)
I0113 17:19:27.527148 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388552
I0113 17:19:27.527235 28435 solver.cpp:406]     Test net output #1: loss = 1.25471 (* 1 = 1.25471 loss)
I0113 17:19:27.583003 28435 solver.cpp:229] Iteration 47000, loss = 1.45604
I0113 17:19:27.583040 28435 solver.cpp:245]     Train net output #0: loss = 1.45604 (* 1 = 1.45604 loss)
I0113 17:19:27.583046 28435 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0113 17:19:48.392495 28435 solver.cpp:229] Iteration 47200, loss = 1.23205
I0113 17:19:48.392534 28435 solver.cpp:245]     Train net output #0: loss = 1.23205 (* 1 = 1.23205 loss)
I0113 17:19:48.392540 28435 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0113 17:20:09.200706 28435 solver.cpp:229] Iteration 47400, loss = 1.40488
I0113 17:20:09.200776 28435 solver.cpp:245]     Train net output #0: loss = 1.40488 (* 1 = 1.40488 loss)
I0113 17:20:09.200783 28435 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0113 17:20:30.018316 28435 solver.cpp:229] Iteration 47600, loss = 1.32757
I0113 17:20:30.018354 28435 solver.cpp:245]     Train net output #0: loss = 1.32757 (* 1 = 1.32757 loss)
I0113 17:20:30.018359 28435 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0113 17:20:50.825717 28435 solver.cpp:229] Iteration 47800, loss = 1.26642
I0113 17:20:50.825768 28435 solver.cpp:245]     Train net output #0: loss = 1.26642 (* 1 = 1.26642 loss)
I0113 17:20:50.825774 28435 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0113 17:21:11.526471 28435 solver.cpp:338] Iteration 48000, Testing net (#0)
I0113 17:21:57.892338 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361839
I0113 17:21:57.892390 28435 solver.cpp:406]     Test net output #1: loss = 1.25561 (* 1 = 1.25561 loss)
I0113 17:21:57.948110 28435 solver.cpp:229] Iteration 48000, loss = 1.45296
I0113 17:21:57.948148 28435 solver.cpp:245]     Train net output #0: loss = 1.45296 (* 1 = 1.45296 loss)
I0113 17:21:57.948153 28435 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0113 17:22:18.761169 28435 solver.cpp:229] Iteration 48200, loss = 1.35664
I0113 17:22:18.761209 28435 solver.cpp:245]     Train net output #0: loss = 1.35664 (* 1 = 1.35664 loss)
I0113 17:22:18.761214 28435 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0113 17:22:39.567417 28435 solver.cpp:229] Iteration 48400, loss = 1.33156
I0113 17:22:39.567502 28435 solver.cpp:245]     Train net output #0: loss = 1.33156 (* 1 = 1.33156 loss)
I0113 17:22:39.567507 28435 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0113 17:23:00.383049 28435 solver.cpp:229] Iteration 48600, loss = 1.13497
I0113 17:23:00.383090 28435 solver.cpp:245]     Train net output #0: loss = 1.13497 (* 1 = 1.13497 loss)
I0113 17:23:00.383095 28435 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0113 17:23:21.191438 28435 solver.cpp:229] Iteration 48800, loss = 1.16664
I0113 17:23:21.191490 28435 solver.cpp:245]     Train net output #0: loss = 1.16664 (* 1 = 1.16664 loss)
I0113 17:23:21.191496 28435 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0113 17:23:41.890636 28435 solver.cpp:338] Iteration 49000, Testing net (#0)
I0113 17:24:28.248757 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387881
I0113 17:24:28.248857 28435 solver.cpp:406]     Test net output #1: loss = 1.25476 (* 1 = 1.25476 loss)
I0113 17:24:28.304664 28435 solver.cpp:229] Iteration 49000, loss = 1.09727
I0113 17:24:28.304702 28435 solver.cpp:245]     Train net output #0: loss = 1.09727 (* 1 = 1.09727 loss)
I0113 17:24:28.304708 28435 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0113 17:24:49.120914 28435 solver.cpp:229] Iteration 49200, loss = 1.31676
I0113 17:24:49.120954 28435 solver.cpp:245]     Train net output #0: loss = 1.31676 (* 1 = 1.31676 loss)
I0113 17:24:49.120959 28435 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0113 17:25:09.928182 28435 solver.cpp:229] Iteration 49400, loss = 1.20031
I0113 17:25:09.928298 28435 solver.cpp:245]     Train net output #0: loss = 1.20031 (* 1 = 1.20031 loss)
I0113 17:25:09.928304 28435 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0113 17:25:30.728111 28435 solver.cpp:229] Iteration 49600, loss = 1.18261
I0113 17:25:30.728150 28435 solver.cpp:245]     Train net output #0: loss = 1.18261 (* 1 = 1.18261 loss)
I0113 17:25:30.728155 28435 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0113 17:25:51.540841 28435 solver.cpp:229] Iteration 49800, loss = 1.10589
I0113 17:25:51.540890 28435 solver.cpp:245]     Train net output #0: loss = 1.10589 (* 1 = 1.10589 loss)
I0113 17:25:51.540896 28435 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0113 17:26:12.249960 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_50000.caffemodel.h5
I0113 17:26:12.299075 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_50000.solverstate.h5
I0113 17:26:12.299700 28435 solver.cpp:338] Iteration 50000, Testing net (#0)
I0113 17:26:58.608783 28435 solver.cpp:406]     Test net output #0: accuracy = 0.38842
I0113 17:26:58.608837 28435 solver.cpp:406]     Test net output #1: loss = 1.25494 (* 1 = 1.25494 loss)
I0113 17:26:58.664510 28435 solver.cpp:229] Iteration 50000, loss = 1.45884
I0113 17:26:58.664548 28435 solver.cpp:245]     Train net output #0: loss = 1.45884 (* 1 = 1.45884 loss)
I0113 17:26:58.664553 28435 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0113 17:27:19.475378 28435 solver.cpp:229] Iteration 50200, loss = 1.04024
I0113 17:27:19.475419 28435 solver.cpp:245]     Train net output #0: loss = 1.04024 (* 1 = 1.04024 loss)
I0113 17:27:19.475425 28435 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0113 17:27:40.282351 28435 solver.cpp:229] Iteration 50400, loss = 1.29898
I0113 17:27:40.282400 28435 solver.cpp:245]     Train net output #0: loss = 1.29898 (* 1 = 1.29898 loss)
I0113 17:27:40.282407 28435 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0113 17:28:01.081993 28435 solver.cpp:229] Iteration 50600, loss = 1.23868
I0113 17:28:01.082027 28435 solver.cpp:245]     Train net output #0: loss = 1.23868 (* 1 = 1.23868 loss)
I0113 17:28:01.082032 28435 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0113 17:28:21.895135 28435 solver.cpp:229] Iteration 50800, loss = 1.0758
I0113 17:28:21.895195 28435 solver.cpp:245]     Train net output #0: loss = 1.0758 (* 1 = 1.0758 loss)
I0113 17:28:21.895200 28435 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0113 17:28:42.599632 28435 solver.cpp:338] Iteration 51000, Testing net (#0)
I0113 17:29:28.989907 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388427
I0113 17:29:28.989959 28435 solver.cpp:406]     Test net output #1: loss = 1.25439 (* 1 = 1.25439 loss)
I0113 17:29:29.045682 28435 solver.cpp:229] Iteration 51000, loss = 1.10744
I0113 17:29:29.045719 28435 solver.cpp:245]     Train net output #0: loss = 1.10744 (* 1 = 1.10744 loss)
I0113 17:29:29.045724 28435 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0113 17:29:49.845109 28435 solver.cpp:229] Iteration 51200, loss = 1.20072
I0113 17:29:49.845149 28435 solver.cpp:245]     Train net output #0: loss = 1.20072 (* 1 = 1.20072 loss)
I0113 17:29:49.845155 28435 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0113 17:30:10.664547 28435 solver.cpp:229] Iteration 51400, loss = 1.11578
I0113 17:30:10.664631 28435 solver.cpp:245]     Train net output #0: loss = 1.11578 (* 1 = 1.11578 loss)
I0113 17:30:10.664638 28435 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0113 17:30:31.469210 28435 solver.cpp:229] Iteration 51600, loss = 1.33789
I0113 17:30:31.469250 28435 solver.cpp:245]     Train net output #0: loss = 1.33789 (* 1 = 1.33789 loss)
I0113 17:30:31.469255 28435 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0113 17:30:52.272408 28435 solver.cpp:229] Iteration 51800, loss = 1.23783
I0113 17:30:52.272493 28435 solver.cpp:245]     Train net output #0: loss = 1.23783 (* 1 = 1.23783 loss)
I0113 17:30:52.272500 28435 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0113 17:31:12.978034 28435 solver.cpp:338] Iteration 52000, Testing net (#0)
I0113 17:31:59.378861 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388315
I0113 17:31:59.378916 28435 solver.cpp:406]     Test net output #1: loss = 1.25483 (* 1 = 1.25483 loss)
I0113 17:31:59.434723 28435 solver.cpp:229] Iteration 52000, loss = 1.172
I0113 17:31:59.434762 28435 solver.cpp:245]     Train net output #0: loss = 1.172 (* 1 = 1.172 loss)
I0113 17:31:59.434767 28435 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0113 17:32:20.239281 28435 solver.cpp:229] Iteration 52200, loss = 1.22857
I0113 17:32:20.239323 28435 solver.cpp:245]     Train net output #0: loss = 1.22857 (* 1 = 1.22857 loss)
I0113 17:32:20.239328 28435 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0113 17:32:41.051990 28435 solver.cpp:229] Iteration 52400, loss = 1.18388
I0113 17:32:41.052040 28435 solver.cpp:245]     Train net output #0: loss = 1.18388 (* 1 = 1.18388 loss)
I0113 17:32:41.052045 28435 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0113 17:33:01.865708 28435 solver.cpp:229] Iteration 52600, loss = 1.24261
I0113 17:33:01.865746 28435 solver.cpp:245]     Train net output #0: loss = 1.24261 (* 1 = 1.24261 loss)
I0113 17:33:01.865751 28435 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0113 17:33:22.663892 28435 solver.cpp:229] Iteration 52800, loss = 1.12762
I0113 17:33:22.663941 28435 solver.cpp:245]     Train net output #0: loss = 1.12762 (* 1 = 1.12762 loss)
I0113 17:33:22.663946 28435 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0113 17:33:43.372870 28435 solver.cpp:338] Iteration 53000, Testing net (#0)
I0113 17:34:29.765254 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388559
I0113 17:34:29.765342 28435 solver.cpp:406]     Test net output #1: loss = 1.2543 (* 1 = 1.2543 loss)
I0113 17:34:29.821074 28435 solver.cpp:229] Iteration 53000, loss = 1.1884
I0113 17:34:29.821111 28435 solver.cpp:245]     Train net output #0: loss = 1.1884 (* 1 = 1.1884 loss)
I0113 17:34:29.821118 28435 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0113 17:34:50.626593 28435 solver.cpp:229] Iteration 53200, loss = 1.18082
I0113 17:34:50.626634 28435 solver.cpp:245]     Train net output #0: loss = 1.18082 (* 1 = 1.18082 loss)
I0113 17:34:50.626641 28435 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0113 17:35:11.433876 28435 solver.cpp:229] Iteration 53400, loss = 1.22523
I0113 17:35:11.433961 28435 solver.cpp:245]     Train net output #0: loss = 1.22523 (* 1 = 1.22523 loss)
I0113 17:35:11.433967 28435 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0113 17:35:32.245332 28435 solver.cpp:229] Iteration 53600, loss = 1.4821
I0113 17:35:32.245371 28435 solver.cpp:245]     Train net output #0: loss = 1.4821 (* 1 = 1.4821 loss)
I0113 17:35:32.245378 28435 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0113 17:35:53.049789 28435 solver.cpp:229] Iteration 53800, loss = 1.34172
I0113 17:35:53.049839 28435 solver.cpp:245]     Train net output #0: loss = 1.34172 (* 1 = 1.34172 loss)
I0113 17:35:53.049844 28435 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0113 17:36:13.763303 28435 solver.cpp:338] Iteration 54000, Testing net (#0)
I0113 17:37:00.156632 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388426
I0113 17:37:00.156697 28435 solver.cpp:406]     Test net output #1: loss = 1.25496 (* 1 = 1.25496 loss)
I0113 17:37:00.212463 28435 solver.cpp:229] Iteration 54000, loss = 1.51929
I0113 17:37:00.212507 28435 solver.cpp:245]     Train net output #0: loss = 1.51929 (* 1 = 1.51929 loss)
I0113 17:37:00.212513 28435 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0113 17:37:21.018501 28435 solver.cpp:229] Iteration 54200, loss = 1.31935
I0113 17:37:21.018543 28435 solver.cpp:245]     Train net output #0: loss = 1.31935 (* 1 = 1.31935 loss)
I0113 17:37:21.018548 28435 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0113 17:37:41.816069 28435 solver.cpp:229] Iteration 54400, loss = 1.25927
I0113 17:37:41.816220 28435 solver.cpp:245]     Train net output #0: loss = 1.25927 (* 1 = 1.25927 loss)
I0113 17:37:41.816226 28435 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0113 17:38:02.635406 28435 solver.cpp:229] Iteration 54600, loss = 1.16929
I0113 17:38:02.635445 28435 solver.cpp:245]     Train net output #0: loss = 1.16929 (* 1 = 1.16929 loss)
I0113 17:38:02.635450 28435 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0113 17:38:23.440847 28435 solver.cpp:229] Iteration 54800, loss = 1.16391
I0113 17:38:23.440899 28435 solver.cpp:245]     Train net output #0: loss = 1.16391 (* 1 = 1.16391 loss)
I0113 17:38:23.440906 28435 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0113 17:38:44.138959 28435 solver.cpp:338] Iteration 55000, Testing net (#0)
I0113 17:39:30.535054 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361664
I0113 17:39:30.535107 28435 solver.cpp:406]     Test net output #1: loss = 1.25567 (* 1 = 1.25567 loss)
I0113 17:39:30.590885 28435 solver.cpp:229] Iteration 55000, loss = 1.42143
I0113 17:39:30.590922 28435 solver.cpp:245]     Train net output #0: loss = 1.42143 (* 1 = 1.42143 loss)
I0113 17:39:30.590929 28435 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0113 17:39:51.402518 28435 solver.cpp:229] Iteration 55200, loss = 1.14545
I0113 17:39:51.402559 28435 solver.cpp:245]     Train net output #0: loss = 1.14545 (* 1 = 1.14545 loss)
I0113 17:39:51.402565 28435 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0113 17:40:12.206128 28435 solver.cpp:229] Iteration 55400, loss = 1.10339
I0113 17:40:12.206200 28435 solver.cpp:245]     Train net output #0: loss = 1.10339 (* 1 = 1.10339 loss)
I0113 17:40:12.206207 28435 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0113 17:40:33.012766 28435 solver.cpp:229] Iteration 55600, loss = 1.3256
I0113 17:40:33.012805 28435 solver.cpp:245]     Train net output #0: loss = 1.3256 (* 1 = 1.3256 loss)
I0113 17:40:33.012811 28435 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0113 17:40:53.820052 28435 solver.cpp:229] Iteration 55800, loss = 1.11776
I0113 17:40:53.820101 28435 solver.cpp:245]     Train net output #0: loss = 1.11776 (* 1 = 1.11776 loss)
I0113 17:40:53.820107 28435 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0113 17:41:14.522222 28435 solver.cpp:338] Iteration 56000, Testing net (#0)
I0113 17:42:00.908478 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387734
I0113 17:42:00.908531 28435 solver.cpp:406]     Test net output #1: loss = 1.25465 (* 1 = 1.25465 loss)
I0113 17:42:00.964200 28435 solver.cpp:229] Iteration 56000, loss = 1.02329
I0113 17:42:00.964239 28435 solver.cpp:245]     Train net output #0: loss = 1.02329 (* 1 = 1.02329 loss)
I0113 17:42:00.964244 28435 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0113 17:42:21.782299 28435 solver.cpp:229] Iteration 56200, loss = 1.36887
I0113 17:42:21.782340 28435 solver.cpp:245]     Train net output #0: loss = 1.36887 (* 1 = 1.36887 loss)
I0113 17:42:21.782344 28435 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0113 17:42:42.586900 28435 solver.cpp:229] Iteration 56400, loss = 1.0565
I0113 17:42:42.586951 28435 solver.cpp:245]     Train net output #0: loss = 1.0565 (* 1 = 1.0565 loss)
I0113 17:42:42.586957 28435 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0113 17:43:03.386492 28435 solver.cpp:229] Iteration 56600, loss = 1.12789
I0113 17:43:03.386531 28435 solver.cpp:245]     Train net output #0: loss = 1.12789 (* 1 = 1.12789 loss)
I0113 17:43:03.386538 28435 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0113 17:43:24.197983 28435 solver.cpp:229] Iteration 56800, loss = 1.14326
I0113 17:43:24.198096 28435 solver.cpp:245]     Train net output #0: loss = 1.14326 (* 1 = 1.14326 loss)
I0113 17:43:24.198103 28435 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0113 17:43:44.899101 28435 solver.cpp:338] Iteration 57000, Testing net (#0)
I0113 17:44:31.288897 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388748
I0113 17:44:31.288962 28435 solver.cpp:406]     Test net output #1: loss = 1.25458 (* 1 = 1.25458 loss)
I0113 17:44:31.344727 28435 solver.cpp:229] Iteration 57000, loss = 1.39011
I0113 17:44:31.344764 28435 solver.cpp:245]     Train net output #0: loss = 1.39011 (* 1 = 1.39011 loss)
I0113 17:44:31.344769 28435 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0113 17:44:52.152428 28435 solver.cpp:229] Iteration 57200, loss = 1.33685
I0113 17:44:52.152468 28435 solver.cpp:245]     Train net output #0: loss = 1.33685 (* 1 = 1.33685 loss)
I0113 17:44:52.152473 28435 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0113 17:45:12.965194 28435 solver.cpp:229] Iteration 57400, loss = 1.15587
I0113 17:45:12.965255 28435 solver.cpp:245]     Train net output #0: loss = 1.15587 (* 1 = 1.15587 loss)
I0113 17:45:12.965261 28435 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0113 17:45:33.765604 28435 solver.cpp:229] Iteration 57600, loss = 1.26021
I0113 17:45:33.765643 28435 solver.cpp:245]     Train net output #0: loss = 1.26021 (* 1 = 1.26021 loss)
I0113 17:45:33.765650 28435 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0113 17:45:54.577788 28435 solver.cpp:229] Iteration 57800, loss = 1.20762
I0113 17:45:54.577837 28435 solver.cpp:245]     Train net output #0: loss = 1.20762 (* 1 = 1.20762 loss)
I0113 17:45:54.577842 28435 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0113 17:46:15.282101 28435 solver.cpp:338] Iteration 58000, Testing net (#0)
I0113 17:47:01.659230 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388476
I0113 17:47:01.659279 28435 solver.cpp:406]     Test net output #1: loss = 1.25461 (* 1 = 1.25461 loss)
I0113 17:47:01.715029 28435 solver.cpp:229] Iteration 58000, loss = 1.2499
I0113 17:47:01.715065 28435 solver.cpp:245]     Train net output #0: loss = 1.2499 (* 1 = 1.2499 loss)
I0113 17:47:01.715070 28435 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0113 17:47:22.516928 28435 solver.cpp:229] Iteration 58200, loss = 1.14273
I0113 17:47:22.516969 28435 solver.cpp:245]     Train net output #0: loss = 1.14273 (* 1 = 1.14273 loss)
I0113 17:47:22.516974 28435 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0113 17:47:43.332582 28435 solver.cpp:229] Iteration 58400, loss = 1.29593
I0113 17:47:43.332633 28435 solver.cpp:245]     Train net output #0: loss = 1.29593 (* 1 = 1.29593 loss)
I0113 17:47:43.332639 28435 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0113 17:48:04.146651 28435 solver.cpp:229] Iteration 58600, loss = 1.2272
I0113 17:48:04.146690 28435 solver.cpp:245]     Train net output #0: loss = 1.2272 (* 1 = 1.2272 loss)
I0113 17:48:04.146697 28435 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0113 17:48:24.953971 28435 solver.cpp:229] Iteration 58800, loss = 1.2421
I0113 17:48:24.954038 28435 solver.cpp:245]     Train net output #0: loss = 1.2421 (* 1 = 1.2421 loss)
I0113 17:48:24.954044 28435 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0113 17:48:45.661728 28435 solver.cpp:338] Iteration 59000, Testing net (#0)
I0113 17:49:32.033200 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388091
I0113 17:49:32.033282 28435 solver.cpp:406]     Test net output #1: loss = 1.25472 (* 1 = 1.25472 loss)
I0113 17:49:32.089017 28435 solver.cpp:229] Iteration 59000, loss = 1.32325
I0113 17:49:32.089053 28435 solver.cpp:245]     Train net output #0: loss = 1.32325 (* 1 = 1.32325 loss)
I0113 17:49:32.089058 28435 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0113 17:49:52.892232 28435 solver.cpp:229] Iteration 59200, loss = 1.16656
I0113 17:49:52.892271 28435 solver.cpp:245]     Train net output #0: loss = 1.16656 (* 1 = 1.16656 loss)
I0113 17:49:52.892277 28435 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0113 17:50:13.709908 28435 solver.cpp:229] Iteration 59400, loss = 1.22505
I0113 17:50:13.709993 28435 solver.cpp:245]     Train net output #0: loss = 1.22505 (* 1 = 1.22505 loss)
I0113 17:50:13.710000 28435 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0113 17:50:34.516330 28435 solver.cpp:229] Iteration 59600, loss = 1.35425
I0113 17:50:34.516369 28435 solver.cpp:245]     Train net output #0: loss = 1.35425 (* 1 = 1.35425 loss)
I0113 17:50:34.516374 28435 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0113 17:50:55.316283 28435 solver.cpp:229] Iteration 59800, loss = 1.40666
I0113 17:50:55.316373 28435 solver.cpp:245]     Train net output #0: loss = 1.40666 (* 1 = 1.40666 loss)
I0113 17:50:55.316380 28435 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0113 17:51:16.031836 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_60000.caffemodel.h5
I0113 17:51:16.080904 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_60000.solverstate.h5
I0113 17:51:16.081528 28435 solver.cpp:338] Iteration 60000, Testing net (#0)
I0113 17:52:02.419550 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388014
I0113 17:52:02.419615 28435 solver.cpp:406]     Test net output #1: loss = 1.25495 (* 1 = 1.25495 loss)
I0113 17:52:02.475347 28435 solver.cpp:229] Iteration 60000, loss = 1.0511
I0113 17:52:02.475384 28435 solver.cpp:245]     Train net output #0: loss = 1.0511 (* 1 = 1.0511 loss)
I0113 17:52:02.475390 28435 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0113 17:52:23.279855 28435 solver.cpp:229] Iteration 60200, loss = 1.25497
I0113 17:52:23.279893 28435 solver.cpp:245]     Train net output #0: loss = 1.25497 (* 1 = 1.25497 loss)
I0113 17:52:23.279898 28435 sgd_solver.cpp:106] Iteration 60200, lr = 0.001
I0113 17:52:44.082936 28435 solver.cpp:229] Iteration 60400, loss = 1.22828
I0113 17:52:44.082991 28435 solver.cpp:245]     Train net output #0: loss = 1.22828 (* 1 = 1.22828 loss)
I0113 17:52:44.082998 28435 sgd_solver.cpp:106] Iteration 60400, lr = 0.001
I0113 17:53:04.900413 28435 solver.cpp:229] Iteration 60600, loss = 1.20156
I0113 17:53:04.900452 28435 solver.cpp:245]     Train net output #0: loss = 1.20156 (* 1 = 1.20156 loss)
I0113 17:53:04.900457 28435 sgd_solver.cpp:106] Iteration 60600, lr = 0.001
I0113 17:53:25.704747 28435 solver.cpp:229] Iteration 60800, loss = 1.31333
I0113 17:53:25.704797 28435 solver.cpp:245]     Train net output #0: loss = 1.31333 (* 1 = 1.31333 loss)
I0113 17:53:25.704802 28435 sgd_solver.cpp:106] Iteration 60800, lr = 0.001
I0113 17:53:46.411545 28435 solver.cpp:338] Iteration 61000, Testing net (#0)
I0113 17:54:32.791007 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388601
I0113 17:54:32.791071 28435 solver.cpp:406]     Test net output #1: loss = 1.25463 (* 1 = 1.25463 loss)
I0113 17:54:32.846765 28435 solver.cpp:229] Iteration 61000, loss = 1.05969
I0113 17:54:32.846803 28435 solver.cpp:245]     Train net output #0: loss = 1.05969 (* 1 = 1.05969 loss)
I0113 17:54:32.846809 28435 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I0113 17:54:53.655391 28435 solver.cpp:229] Iteration 61200, loss = 1.13587
I0113 17:54:53.655431 28435 solver.cpp:245]     Train net output #0: loss = 1.13587 (* 1 = 1.13587 loss)
I0113 17:54:53.655436 28435 sgd_solver.cpp:106] Iteration 61200, lr = 0.001
I0113 17:55:14.457914 28435 solver.cpp:229] Iteration 61400, loss = 1.06309
I0113 17:55:14.457974 28435 solver.cpp:245]     Train net output #0: loss = 1.06309 (* 1 = 1.06309 loss)
I0113 17:55:14.457980 28435 sgd_solver.cpp:106] Iteration 61400, lr = 0.001
I0113 17:55:35.272182 28435 solver.cpp:229] Iteration 61600, loss = 1.16216
I0113 17:55:35.272223 28435 solver.cpp:245]     Train net output #0: loss = 1.16216 (* 1 = 1.16216 loss)
I0113 17:55:35.272230 28435 sgd_solver.cpp:106] Iteration 61600, lr = 0.001
I0113 17:55:56.077513 28435 solver.cpp:229] Iteration 61800, loss = 1.01612
I0113 17:55:56.077596 28435 solver.cpp:245]     Train net output #0: loss = 1.01612 (* 1 = 1.01612 loss)
I0113 17:55:56.077602 28435 sgd_solver.cpp:106] Iteration 61800, lr = 0.001
I0113 17:56:16.783051 28435 solver.cpp:338] Iteration 62000, Testing net (#0)
I0113 17:57:03.164551 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361552
I0113 17:57:03.164618 28435 solver.cpp:406]     Test net output #1: loss = 1.25568 (* 1 = 1.25568 loss)
I0113 17:57:03.220368 28435 solver.cpp:229] Iteration 62000, loss = 1.16435
I0113 17:57:03.220405 28435 solver.cpp:245]     Train net output #0: loss = 1.16435 (* 1 = 1.16435 loss)
I0113 17:57:03.220410 28435 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I0113 17:57:24.031980 28435 solver.cpp:229] Iteration 62200, loss = 1.16757
I0113 17:57:24.032019 28435 solver.cpp:245]     Train net output #0: loss = 1.16757 (* 1 = 1.16757 loss)
I0113 17:57:24.032025 28435 sgd_solver.cpp:106] Iteration 62200, lr = 0.001
I0113 17:57:44.834213 28435 solver.cpp:229] Iteration 62400, loss = 1.36989
I0113 17:57:44.834265 28435 solver.cpp:245]     Train net output #0: loss = 1.36989 (* 1 = 1.36989 loss)
I0113 17:57:44.834270 28435 sgd_solver.cpp:106] Iteration 62400, lr = 0.001
I0113 17:58:05.641043 28435 solver.cpp:229] Iteration 62600, loss = 1.23388
I0113 17:58:05.641083 28435 solver.cpp:245]     Train net output #0: loss = 1.23388 (* 1 = 1.23388 loss)
I0113 17:58:05.641089 28435 sgd_solver.cpp:106] Iteration 62600, lr = 0.001
I0113 17:58:26.449034 28435 solver.cpp:229] Iteration 62800, loss = 1.39301
I0113 17:58:26.449093 28435 solver.cpp:245]     Train net output #0: loss = 1.39301 (* 1 = 1.39301 loss)
I0113 17:58:26.449100 28435 sgd_solver.cpp:106] Iteration 62800, lr = 0.001
I0113 17:58:47.146421 28435 solver.cpp:338] Iteration 63000, Testing net (#0)
I0113 17:59:33.512200 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388559
I0113 17:59:33.512264 28435 solver.cpp:406]     Test net output #1: loss = 1.25445 (* 1 = 1.25445 loss)
I0113 17:59:33.567981 28435 solver.cpp:229] Iteration 63000, loss = 1.09047
I0113 17:59:33.568019 28435 solver.cpp:245]     Train net output #0: loss = 1.09047 (* 1 = 1.09047 loss)
I0113 17:59:33.568024 28435 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0113 17:59:54.381891 28435 solver.cpp:229] Iteration 63200, loss = 1.30684
I0113 17:59:54.381932 28435 solver.cpp:245]     Train net output #0: loss = 1.30684 (* 1 = 1.30684 loss)
I0113 17:59:54.381937 28435 sgd_solver.cpp:106] Iteration 63200, lr = 0.001
I0113 18:00:15.194816 28435 solver.cpp:229] Iteration 63400, loss = 1.17797
I0113 18:00:15.194885 28435 solver.cpp:245]     Train net output #0: loss = 1.17797 (* 1 = 1.17797 loss)
I0113 18:00:15.194890 28435 sgd_solver.cpp:106] Iteration 63400, lr = 0.001
I0113 18:00:35.986047 28435 solver.cpp:229] Iteration 63600, loss = 1.58306
I0113 18:00:35.986084 28435 solver.cpp:245]     Train net output #0: loss = 1.58306 (* 1 = 1.58306 loss)
I0113 18:00:35.986089 28435 sgd_solver.cpp:106] Iteration 63600, lr = 0.001
I0113 18:00:56.789716 28435 solver.cpp:229] Iteration 63800, loss = 1.21259
I0113 18:00:56.789767 28435 solver.cpp:245]     Train net output #0: loss = 1.21259 (* 1 = 1.21259 loss)
I0113 18:00:56.789772 28435 sgd_solver.cpp:106] Iteration 63800, lr = 0.001
I0113 18:01:17.488646 28435 solver.cpp:338] Iteration 64000, Testing net (#0)
I0113 18:02:03.871003 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388196
I0113 18:02:03.871057 28435 solver.cpp:406]     Test net output #1: loss = 1.25468 (* 1 = 1.25468 loss)
I0113 18:02:03.926769 28435 solver.cpp:229] Iteration 64000, loss = 1.16435
I0113 18:02:03.926806 28435 solver.cpp:245]     Train net output #0: loss = 1.16435 (* 1 = 1.16435 loss)
I0113 18:02:03.926811 28435 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I0113 18:02:24.733606 28435 solver.cpp:229] Iteration 64200, loss = 1.12549
I0113 18:02:24.733647 28435 solver.cpp:245]     Train net output #0: loss = 1.12549 (* 1 = 1.12549 loss)
I0113 18:02:24.733652 28435 sgd_solver.cpp:106] Iteration 64200, lr = 0.001
I0113 18:02:45.543186 28435 solver.cpp:229] Iteration 64400, loss = 1.3364
I0113 18:02:45.543272 28435 solver.cpp:245]     Train net output #0: loss = 1.3364 (* 1 = 1.3364 loss)
I0113 18:02:45.543279 28435 sgd_solver.cpp:106] Iteration 64400, lr = 0.001
I0113 18:03:06.350522 28435 solver.cpp:229] Iteration 64600, loss = 1.35606
I0113 18:03:06.350563 28435 solver.cpp:245]     Train net output #0: loss = 1.35606 (* 1 = 1.35606 loss)
I0113 18:03:06.350567 28435 sgd_solver.cpp:106] Iteration 64600, lr = 0.001
I0113 18:03:27.164168 28435 solver.cpp:229] Iteration 64800, loss = 1.10421
I0113 18:03:27.164224 28435 solver.cpp:245]     Train net output #0: loss = 1.10421 (* 1 = 1.10421 loss)
I0113 18:03:27.164232 28435 sgd_solver.cpp:106] Iteration 64800, lr = 0.001
I0113 18:03:47.868782 28435 solver.cpp:338] Iteration 65000, Testing net (#0)
I0113 18:04:34.252918 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388678
I0113 18:04:34.252990 28435 solver.cpp:406]     Test net output #1: loss = 1.25461 (* 1 = 1.25461 loss)
I0113 18:04:34.308830 28435 solver.cpp:229] Iteration 65000, loss = 1.21317
I0113 18:04:34.308867 28435 solver.cpp:245]     Train net output #0: loss = 1.21317 (* 1 = 1.21317 loss)
I0113 18:04:34.308873 28435 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0113 18:04:55.107173 28435 solver.cpp:229] Iteration 65200, loss = 1.34783
I0113 18:04:55.107213 28435 solver.cpp:245]     Train net output #0: loss = 1.34783 (* 1 = 1.34783 loss)
I0113 18:04:55.107220 28435 sgd_solver.cpp:106] Iteration 65200, lr = 0.001
I0113 18:05:15.925705 28435 solver.cpp:229] Iteration 65400, loss = 1.35627
I0113 18:05:15.925776 28435 solver.cpp:245]     Train net output #0: loss = 1.35627 (* 1 = 1.35627 loss)
I0113 18:05:15.925782 28435 sgd_solver.cpp:106] Iteration 65400, lr = 0.001
I0113 18:05:36.730397 28435 solver.cpp:229] Iteration 65600, loss = 1.07286
I0113 18:05:36.730437 28435 solver.cpp:245]     Train net output #0: loss = 1.07286 (* 1 = 1.07286 loss)
I0113 18:05:36.730443 28435 sgd_solver.cpp:106] Iteration 65600, lr = 0.001
I0113 18:05:57.534363 28435 solver.cpp:229] Iteration 65800, loss = 1.38299
I0113 18:05:57.534411 28435 solver.cpp:245]     Train net output #0: loss = 1.38299 (* 1 = 1.38299 loss)
I0113 18:05:57.534417 28435 sgd_solver.cpp:106] Iteration 65800, lr = 0.001
I0113 18:06:18.246493 28435 solver.cpp:338] Iteration 66000, Testing net (#0)
I0113 18:07:04.637352 28435 solver.cpp:406]     Test net output #0: accuracy = 0.387664
I0113 18:07:04.637408 28435 solver.cpp:406]     Test net output #1: loss = 1.2547 (* 1 = 1.2547 loss)
I0113 18:07:04.693166 28435 solver.cpp:229] Iteration 66000, loss = 1.26826
I0113 18:07:04.693204 28435 solver.cpp:245]     Train net output #0: loss = 1.26826 (* 1 = 1.26826 loss)
I0113 18:07:04.693209 28435 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0113 18:07:25.491953 28435 solver.cpp:229] Iteration 66200, loss = 1.14845
I0113 18:07:25.491994 28435 solver.cpp:245]     Train net output #0: loss = 1.14845 (* 1 = 1.14845 loss)
I0113 18:07:25.491999 28435 sgd_solver.cpp:106] Iteration 66200, lr = 0.001
I0113 18:07:46.299904 28435 solver.cpp:229] Iteration 66400, loss = 1.37316
I0113 18:07:46.299957 28435 solver.cpp:245]     Train net output #0: loss = 1.37316 (* 1 = 1.37316 loss)
I0113 18:07:46.299962 28435 sgd_solver.cpp:106] Iteration 66400, lr = 0.001
I0113 18:08:07.109650 28435 solver.cpp:229] Iteration 66600, loss = 1.41311
I0113 18:08:07.109689 28435 solver.cpp:245]     Train net output #0: loss = 1.41311 (* 1 = 1.41311 loss)
I0113 18:08:07.109694 28435 sgd_solver.cpp:106] Iteration 66600, lr = 0.001
I0113 18:08:27.905560 28435 solver.cpp:229] Iteration 66800, loss = 1.1688
I0113 18:08:27.905609 28435 solver.cpp:245]     Train net output #0: loss = 1.1688 (* 1 = 1.1688 loss)
I0113 18:08:27.905614 28435 sgd_solver.cpp:106] Iteration 66800, lr = 0.001
I0113 18:08:48.612932 28435 solver.cpp:338] Iteration 67000, Testing net (#0)
I0113 18:09:35.006676 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388546
I0113 18:09:35.006750 28435 solver.cpp:406]     Test net output #1: loss = 1.25492 (* 1 = 1.25492 loss)
I0113 18:09:35.062485 28435 solver.cpp:229] Iteration 67000, loss = 1.27123
I0113 18:09:35.062525 28435 solver.cpp:245]     Train net output #0: loss = 1.27123 (* 1 = 1.27123 loss)
I0113 18:09:35.062541 28435 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I0113 18:09:55.865905 28435 solver.cpp:229] Iteration 67200, loss = 1.51945
I0113 18:09:55.865942 28435 solver.cpp:245]     Train net output #0: loss = 1.51945 (* 1 = 1.51945 loss)
I0113 18:09:55.865948 28435 sgd_solver.cpp:106] Iteration 67200, lr = 0.001
I0113 18:10:16.664252 28435 solver.cpp:229] Iteration 67400, loss = 1.36937
I0113 18:10:16.664356 28435 solver.cpp:245]     Train net output #0: loss = 1.36937 (* 1 = 1.36937 loss)
I0113 18:10:16.664362 28435 sgd_solver.cpp:106] Iteration 67400, lr = 0.001
I0113 18:10:37.471946 28435 solver.cpp:229] Iteration 67600, loss = 1.27416
I0113 18:10:37.471985 28435 solver.cpp:245]     Train net output #0: loss = 1.27416 (* 1 = 1.27416 loss)
I0113 18:10:37.471990 28435 sgd_solver.cpp:106] Iteration 67600, lr = 0.001
I0113 18:10:58.279247 28435 solver.cpp:229] Iteration 67800, loss = 1.16599
I0113 18:10:58.279299 28435 solver.cpp:245]     Train net output #0: loss = 1.16599 (* 1 = 1.16599 loss)
I0113 18:10:58.279304 28435 sgd_solver.cpp:106] Iteration 67800, lr = 0.001
I0113 18:11:18.984583 28435 solver.cpp:338] Iteration 68000, Testing net (#0)
I0113 18:12:05.383677 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388455
I0113 18:12:05.383752 28435 solver.cpp:406]     Test net output #1: loss = 1.25459 (* 1 = 1.25459 loss)
I0113 18:12:05.439465 28435 solver.cpp:229] Iteration 68000, loss = 1.50927
I0113 18:12:05.439503 28435 solver.cpp:245]     Train net output #0: loss = 1.50927 (* 1 = 1.50927 loss)
I0113 18:12:05.439508 28435 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I0113 18:12:26.244505 28435 solver.cpp:229] Iteration 68200, loss = 1.22524
I0113 18:12:26.244546 28435 solver.cpp:245]     Train net output #0: loss = 1.22524 (* 1 = 1.22524 loss)
I0113 18:12:26.244552 28435 sgd_solver.cpp:106] Iteration 68200, lr = 0.001
I0113 18:12:47.041990 28435 solver.cpp:229] Iteration 68400, loss = 1.35548
I0113 18:12:47.042042 28435 solver.cpp:245]     Train net output #0: loss = 1.35548 (* 1 = 1.35548 loss)
I0113 18:12:47.042047 28435 sgd_solver.cpp:106] Iteration 68400, lr = 0.001
I0113 18:13:07.855571 28435 solver.cpp:229] Iteration 68600, loss = 1.68349
I0113 18:13:07.855609 28435 solver.cpp:245]     Train net output #0: loss = 1.68349 (* 1 = 1.68349 loss)
I0113 18:13:07.855615 28435 sgd_solver.cpp:106] Iteration 68600, lr = 0.001
I0113 18:13:28.659191 28435 solver.cpp:229] Iteration 68800, loss = 1.22274
I0113 18:13:28.659242 28435 solver.cpp:245]     Train net output #0: loss = 1.22274 (* 1 = 1.22274 loss)
I0113 18:13:28.659248 28435 sgd_solver.cpp:106] Iteration 68800, lr = 0.001
I0113 18:13:49.355557 28435 solver.cpp:338] Iteration 69000, Testing net (#0)
I0113 18:14:35.744493 28435 solver.cpp:406]     Test net output #0: accuracy = 0.361846
I0113 18:14:35.744544 28435 solver.cpp:406]     Test net output #1: loss = 1.2555 (* 1 = 1.2555 loss)
I0113 18:14:35.800328 28435 solver.cpp:229] Iteration 69000, loss = 1.14705
I0113 18:14:35.800365 28435 solver.cpp:245]     Train net output #0: loss = 1.14705 (* 1 = 1.14705 loss)
I0113 18:14:35.800371 28435 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0113 18:14:56.609866 28435 solver.cpp:229] Iteration 69200, loss = 1.2984
I0113 18:14:56.609907 28435 solver.cpp:245]     Train net output #0: loss = 1.2984 (* 1 = 1.2984 loss)
I0113 18:14:56.609912 28435 sgd_solver.cpp:106] Iteration 69200, lr = 0.001
I0113 18:15:17.419912 28435 solver.cpp:229] Iteration 69400, loss = 1.18697
I0113 18:15:17.419986 28435 solver.cpp:245]     Train net output #0: loss = 1.18697 (* 1 = 1.18697 loss)
I0113 18:15:17.419991 28435 sgd_solver.cpp:106] Iteration 69400, lr = 0.001
I0113 18:15:38.227452 28435 solver.cpp:229] Iteration 69600, loss = 1.27363
I0113 18:15:38.227493 28435 solver.cpp:245]     Train net output #0: loss = 1.27363 (* 1 = 1.27363 loss)
I0113 18:15:38.227497 28435 sgd_solver.cpp:106] Iteration 69600, lr = 0.001
I0113 18:15:59.035728 28435 solver.cpp:229] Iteration 69800, loss = 1.46962
I0113 18:15:59.035820 28435 solver.cpp:245]     Train net output #0: loss = 1.46962 (* 1 = 1.46962 loss)
I0113 18:15:59.035826 28435 sgd_solver.cpp:106] Iteration 69800, lr = 0.001
I0113 18:16:19.733099 28435 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_70000.caffemodel.h5
I0113 18:16:19.782131 28435 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_70000.solverstate.h5
I0113 18:16:19.814968 28435 solver.cpp:318] Iteration 70000, loss = 1.50116
I0113 18:16:19.815001 28435 solver.cpp:338] Iteration 70000, Testing net (#0)
I0113 18:17:06.148283 28435 solver.cpp:406]     Test net output #0: accuracy = 0.388322
I0113 18:17:06.148342 28435 solver.cpp:406]     Test net output #1: loss = 1.25453 (* 1 = 1.25453 loss)
I0113 18:17:06.148349 28435 solver.cpp:323] Optimization Done.
I0113 18:17:06.148351 28435 caffe.cpp:216] Optimization Done.
I0113 18:17:06.303409  1825 caffe.cpp:185] Using GPUs 0
I0113 18:17:06.480029  1825 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 200
max_iter: 85000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 5000
snapshot_prefix: "krnet_full"
solver_mode: GPU
device_id: 0
net: "krnet_full_train_test.prototxt"
snapshot_format: HDF5
I0113 18:17:06.480155  1825 solver.cpp:91] Creating training net from net file: krnet_full_train_test.prototxt
I0113 18:17:06.480646  1825 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0113 18:17:06.480667  1825 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0113 18:17:06.480864  1825 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "train_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 18:17:06.480967  1825 layer_factory.hpp:77] Creating layer cifar
I0113 18:17:06.481921  1825 net.cpp:106] Creating Layer cifar
I0113 18:17:06.481935  1825 net.cpp:411] cifar -> data
I0113 18:17:06.481957  1825 net.cpp:411] cifar -> label
I0113 18:17:06.481968  1825 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 18:17:06.482507  1829 db_lmdb.cpp:38] Opened lmdb train_lmdb
I0113 18:17:06.495949  1825 data_layer.cpp:41] output data size: 100,3,100,100
I0113 18:17:06.509549  1825 net.cpp:150] Setting up cifar
I0113 18:17:06.509585  1825 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 18:17:06.509603  1825 net.cpp:157] Top shape: 100 (100)
I0113 18:17:06.509606  1825 net.cpp:165] Memory required for data: 12000400
I0113 18:17:06.509621  1825 layer_factory.hpp:77] Creating layer conv1
I0113 18:17:06.509652  1825 net.cpp:106] Creating Layer conv1
I0113 18:17:06.509660  1825 net.cpp:454] conv1 <- data
I0113 18:17:06.509677  1825 net.cpp:411] conv1 -> conv1
I0113 18:17:06.512136  1825 net.cpp:150] Setting up conv1
I0113 18:17:06.512166  1825 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 18:17:06.512168  1825 net.cpp:165] Memory required for data: 140000400
I0113 18:17:06.512190  1825 layer_factory.hpp:77] Creating layer pool1
I0113 18:17:06.512208  1825 net.cpp:106] Creating Layer pool1
I0113 18:17:06.512213  1825 net.cpp:454] pool1 <- conv1
I0113 18:17:06.512225  1825 net.cpp:411] pool1 -> pool1
I0113 18:17:06.512267  1825 net.cpp:150] Setting up pool1
I0113 18:17:06.512274  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.512276  1825 net.cpp:165] Memory required for data: 172000400
I0113 18:17:06.512279  1825 layer_factory.hpp:77] Creating layer relu1
I0113 18:17:06.512287  1825 net.cpp:106] Creating Layer relu1
I0113 18:17:06.512290  1825 net.cpp:454] relu1 <- pool1
I0113 18:17:06.512296  1825 net.cpp:397] relu1 -> pool1 (in-place)
I0113 18:17:06.512302  1825 net.cpp:150] Setting up relu1
I0113 18:17:06.512305  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.512307  1825 net.cpp:165] Memory required for data: 204000400
I0113 18:17:06.512310  1825 layer_factory.hpp:77] Creating layer norm1
I0113 18:17:06.512318  1825 net.cpp:106] Creating Layer norm1
I0113 18:17:06.512321  1825 net.cpp:454] norm1 <- pool1
I0113 18:17:06.512327  1825 net.cpp:411] norm1 -> norm1
I0113 18:17:06.512415  1825 net.cpp:150] Setting up norm1
I0113 18:17:06.512424  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.512426  1825 net.cpp:165] Memory required for data: 236000400
I0113 18:17:06.512429  1825 layer_factory.hpp:77] Creating layer conv2
I0113 18:17:06.512444  1825 net.cpp:106] Creating Layer conv2
I0113 18:17:06.512446  1825 net.cpp:454] conv2 <- norm1
I0113 18:17:06.512454  1825 net.cpp:411] conv2 -> conv2
I0113 18:17:06.515542  1825 net.cpp:150] Setting up conv2
I0113 18:17:06.515575  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.515578  1825 net.cpp:165] Memory required for data: 268000400
I0113 18:17:06.515596  1825 layer_factory.hpp:77] Creating layer relu2
I0113 18:17:06.515610  1825 net.cpp:106] Creating Layer relu2
I0113 18:17:06.515615  1825 net.cpp:454] relu2 <- conv2
I0113 18:17:06.515624  1825 net.cpp:397] relu2 -> conv2 (in-place)
I0113 18:17:06.515632  1825 net.cpp:150] Setting up relu2
I0113 18:17:06.515636  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.515638  1825 net.cpp:165] Memory required for data: 300000400
I0113 18:17:06.515641  1825 layer_factory.hpp:77] Creating layer pool2
I0113 18:17:06.515650  1825 net.cpp:106] Creating Layer pool2
I0113 18:17:06.515653  1825 net.cpp:454] pool2 <- conv2
I0113 18:17:06.515661  1825 net.cpp:411] pool2 -> pool2
I0113 18:17:06.515691  1825 net.cpp:150] Setting up pool2
I0113 18:17:06.515698  1825 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:17:06.515700  1825 net.cpp:165] Memory required for data: 308000400
I0113 18:17:06.515703  1825 layer_factory.hpp:77] Creating layer norm2
I0113 18:17:06.515713  1825 net.cpp:106] Creating Layer norm2
I0113 18:17:06.515717  1825 net.cpp:454] norm2 <- pool2
I0113 18:17:06.515724  1825 net.cpp:411] norm2 -> norm2
I0113 18:17:06.515797  1825 net.cpp:150] Setting up norm2
I0113 18:17:06.515805  1825 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:17:06.515806  1825 net.cpp:165] Memory required for data: 316000400
I0113 18:17:06.515810  1825 layer_factory.hpp:77] Creating layer conv3
I0113 18:17:06.515823  1825 net.cpp:106] Creating Layer conv3
I0113 18:17:06.515826  1825 net.cpp:454] conv3 <- norm2
I0113 18:17:06.515835  1825 net.cpp:411] conv3 -> conv3
I0113 18:17:06.522459  1825 net.cpp:150] Setting up conv3
I0113 18:17:06.522503  1825 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:17:06.522506  1825 net.cpp:165] Memory required for data: 332000400
I0113 18:17:06.522526  1825 layer_factory.hpp:77] Creating layer relu3
I0113 18:17:06.522542  1825 net.cpp:106] Creating Layer relu3
I0113 18:17:06.522548  1825 net.cpp:454] relu3 <- conv3
I0113 18:17:06.522557  1825 net.cpp:397] relu3 -> conv3 (in-place)
I0113 18:17:06.522565  1825 net.cpp:150] Setting up relu3
I0113 18:17:06.522569  1825 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:17:06.522572  1825 net.cpp:165] Memory required for data: 348000400
I0113 18:17:06.522573  1825 layer_factory.hpp:77] Creating layer pool3
I0113 18:17:06.522584  1825 net.cpp:106] Creating Layer pool3
I0113 18:17:06.522588  1825 net.cpp:454] pool3 <- conv3
I0113 18:17:06.522593  1825 net.cpp:411] pool3 -> pool3
I0113 18:17:06.522619  1825 net.cpp:150] Setting up pool3
I0113 18:17:06.522625  1825 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 18:17:06.522627  1825 net.cpp:165] Memory required for data: 351686800
I0113 18:17:06.522630  1825 layer_factory.hpp:77] Creating layer ip1
I0113 18:17:06.522644  1825 net.cpp:106] Creating Layer ip1
I0113 18:17:06.522647  1825 net.cpp:454] ip1 <- pool3
I0113 18:17:06.522655  1825 net.cpp:411] ip1 -> ip1
I0113 18:17:06.526904  1825 net.cpp:150] Setting up ip1
I0113 18:17:06.526935  1825 net.cpp:157] Top shape: 100 4 (400)
I0113 18:17:06.526937  1825 net.cpp:165] Memory required for data: 351688400
I0113 18:17:06.526948  1825 layer_factory.hpp:77] Creating layer loss
I0113 18:17:06.526964  1825 net.cpp:106] Creating Layer loss
I0113 18:17:06.526970  1825 net.cpp:454] loss <- ip1
I0113 18:17:06.526978  1825 net.cpp:454] loss <- label
I0113 18:17:06.526984  1825 net.cpp:411] loss -> loss
I0113 18:17:06.526998  1825 layer_factory.hpp:77] Creating layer loss
I0113 18:17:06.527078  1825 net.cpp:150] Setting up loss
I0113 18:17:06.527086  1825 net.cpp:157] Top shape: (1)
I0113 18:17:06.527087  1825 net.cpp:160]     with loss weight 1
I0113 18:17:06.527117  1825 net.cpp:165] Memory required for data: 351688404
I0113 18:17:06.527120  1825 net.cpp:226] loss needs backward computation.
I0113 18:17:06.527124  1825 net.cpp:226] ip1 needs backward computation.
I0113 18:17:06.527127  1825 net.cpp:226] pool3 needs backward computation.
I0113 18:17:06.527130  1825 net.cpp:226] relu3 needs backward computation.
I0113 18:17:06.527133  1825 net.cpp:226] conv3 needs backward computation.
I0113 18:17:06.527135  1825 net.cpp:226] norm2 needs backward computation.
I0113 18:17:06.527138  1825 net.cpp:226] pool2 needs backward computation.
I0113 18:17:06.527142  1825 net.cpp:226] relu2 needs backward computation.
I0113 18:17:06.527144  1825 net.cpp:226] conv2 needs backward computation.
I0113 18:17:06.527146  1825 net.cpp:226] norm1 needs backward computation.
I0113 18:17:06.527149  1825 net.cpp:226] relu1 needs backward computation.
I0113 18:17:06.527153  1825 net.cpp:226] pool1 needs backward computation.
I0113 18:17:06.527155  1825 net.cpp:226] conv1 needs backward computation.
I0113 18:17:06.527158  1825 net.cpp:228] cifar does not need backward computation.
I0113 18:17:06.527168  1825 net.cpp:270] This network produces output loss
I0113 18:17:06.527182  1825 net.cpp:283] Network initialization done.
I0113 18:17:06.527627  1825 solver.cpp:181] Creating test net (#0) specified by net file: krnet_full_train_test.prototxt
I0113 18:17:06.527670  1825 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0113 18:17:06.527906  1825 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "test_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 18:17:06.528030  1825 layer_factory.hpp:77] Creating layer cifar
I0113 18:17:06.528805  1825 net.cpp:106] Creating Layer cifar
I0113 18:17:06.528820  1825 net.cpp:411] cifar -> data
I0113 18:17:06.528834  1825 net.cpp:411] cifar -> label
I0113 18:17:06.528844  1825 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 18:17:06.529500  1831 db_lmdb.cpp:38] Opened lmdb test_lmdb
I0113 18:17:06.530405  1825 data_layer.cpp:41] output data size: 100,3,100,100
I0113 18:17:06.544354  1825 net.cpp:150] Setting up cifar
I0113 18:17:06.544406  1825 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 18:17:06.544419  1825 net.cpp:157] Top shape: 100 (100)
I0113 18:17:06.544423  1825 net.cpp:165] Memory required for data: 12000400
I0113 18:17:06.544443  1825 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0113 18:17:06.544471  1825 net.cpp:106] Creating Layer label_cifar_1_split
I0113 18:17:06.544481  1825 net.cpp:454] label_cifar_1_split <- label
I0113 18:17:06.544499  1825 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_0
I0113 18:17:06.544518  1825 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_1
I0113 18:17:06.544574  1825 net.cpp:150] Setting up label_cifar_1_split
I0113 18:17:06.544585  1825 net.cpp:157] Top shape: 100 (100)
I0113 18:17:06.544591  1825 net.cpp:157] Top shape: 100 (100)
I0113 18:17:06.544595  1825 net.cpp:165] Memory required for data: 12001200
I0113 18:17:06.544600  1825 layer_factory.hpp:77] Creating layer conv1
I0113 18:17:06.544623  1825 net.cpp:106] Creating Layer conv1
I0113 18:17:06.544630  1825 net.cpp:454] conv1 <- data
I0113 18:17:06.544649  1825 net.cpp:411] conv1 -> conv1
I0113 18:17:06.546510  1825 net.cpp:150] Setting up conv1
I0113 18:17:06.546558  1825 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 18:17:06.546564  1825 net.cpp:165] Memory required for data: 140001200
I0113 18:17:06.546589  1825 layer_factory.hpp:77] Creating layer pool1
I0113 18:17:06.546608  1825 net.cpp:106] Creating Layer pool1
I0113 18:17:06.546617  1825 net.cpp:454] pool1 <- conv1
I0113 18:17:06.546629  1825 net.cpp:411] pool1 -> pool1
I0113 18:17:06.546682  1825 net.cpp:150] Setting up pool1
I0113 18:17:06.546700  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.546705  1825 net.cpp:165] Memory required for data: 172001200
I0113 18:17:06.546710  1825 layer_factory.hpp:77] Creating layer relu1
I0113 18:17:06.546725  1825 net.cpp:106] Creating Layer relu1
I0113 18:17:06.546731  1825 net.cpp:454] relu1 <- pool1
I0113 18:17:06.546741  1825 net.cpp:397] relu1 -> pool1 (in-place)
I0113 18:17:06.546751  1825 net.cpp:150] Setting up relu1
I0113 18:17:06.546756  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.546761  1825 net.cpp:165] Memory required for data: 204001200
I0113 18:17:06.546764  1825 layer_factory.hpp:77] Creating layer norm1
I0113 18:17:06.546777  1825 net.cpp:106] Creating Layer norm1
I0113 18:17:06.546782  1825 net.cpp:454] norm1 <- pool1
I0113 18:17:06.546790  1825 net.cpp:411] norm1 -> norm1
I0113 18:17:06.546901  1825 net.cpp:150] Setting up norm1
I0113 18:17:06.546912  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.546916  1825 net.cpp:165] Memory required for data: 236001200
I0113 18:17:06.546921  1825 layer_factory.hpp:77] Creating layer conv2
I0113 18:17:06.546937  1825 net.cpp:106] Creating Layer conv2
I0113 18:17:06.546943  1825 net.cpp:454] conv2 <- norm1
I0113 18:17:06.546957  1825 net.cpp:411] conv2 -> conv2
I0113 18:17:06.551640  1825 net.cpp:150] Setting up conv2
I0113 18:17:06.551698  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.551707  1825 net.cpp:165] Memory required for data: 268001200
I0113 18:17:06.551734  1825 layer_factory.hpp:77] Creating layer relu2
I0113 18:17:06.551759  1825 net.cpp:106] Creating Layer relu2
I0113 18:17:06.551769  1825 net.cpp:454] relu2 <- conv2
I0113 18:17:06.551781  1825 net.cpp:397] relu2 -> conv2 (in-place)
I0113 18:17:06.551795  1825 net.cpp:150] Setting up relu2
I0113 18:17:06.551802  1825 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:17:06.551806  1825 net.cpp:165] Memory required for data: 300001200
I0113 18:17:06.551811  1825 layer_factory.hpp:77] Creating layer pool2
I0113 18:17:06.551828  1825 net.cpp:106] Creating Layer pool2
I0113 18:17:06.551833  1825 net.cpp:454] pool2 <- conv2
I0113 18:17:06.551843  1825 net.cpp:411] pool2 -> pool2
I0113 18:17:06.551888  1825 net.cpp:150] Setting up pool2
I0113 18:17:06.551898  1825 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:17:06.551901  1825 net.cpp:165] Memory required for data: 308001200
I0113 18:17:06.551906  1825 layer_factory.hpp:77] Creating layer norm2
I0113 18:17:06.551919  1825 net.cpp:106] Creating Layer norm2
I0113 18:17:06.551925  1825 net.cpp:454] norm2 <- pool2
I0113 18:17:06.551944  1825 net.cpp:411] norm2 -> norm2
I0113 18:17:06.552070  1825 net.cpp:150] Setting up norm2
I0113 18:17:06.552081  1825 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:17:06.552085  1825 net.cpp:165] Memory required for data: 316001200
I0113 18:17:06.552090  1825 layer_factory.hpp:77] Creating layer conv3
I0113 18:17:06.552109  1825 net.cpp:106] Creating Layer conv3
I0113 18:17:06.552114  1825 net.cpp:454] conv3 <- norm2
I0113 18:17:06.552126  1825 net.cpp:411] conv3 -> conv3
I0113 18:17:06.561182  1825 net.cpp:150] Setting up conv3
I0113 18:17:06.561234  1825 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:17:06.561241  1825 net.cpp:165] Memory required for data: 332001200
I0113 18:17:06.561267  1825 layer_factory.hpp:77] Creating layer relu3
I0113 18:17:06.561291  1825 net.cpp:106] Creating Layer relu3
I0113 18:17:06.561298  1825 net.cpp:454] relu3 <- conv3
I0113 18:17:06.561311  1825 net.cpp:397] relu3 -> conv3 (in-place)
I0113 18:17:06.561343  1825 net.cpp:150] Setting up relu3
I0113 18:17:06.561350  1825 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:17:06.561353  1825 net.cpp:165] Memory required for data: 348001200
I0113 18:17:06.561358  1825 layer_factory.hpp:77] Creating layer pool3
I0113 18:17:06.561369  1825 net.cpp:106] Creating Layer pool3
I0113 18:17:06.561373  1825 net.cpp:454] pool3 <- conv3
I0113 18:17:06.561383  1825 net.cpp:411] pool3 -> pool3
I0113 18:17:06.561415  1825 net.cpp:150] Setting up pool3
I0113 18:17:06.561424  1825 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 18:17:06.561427  1825 net.cpp:165] Memory required for data: 351687600
I0113 18:17:06.561432  1825 layer_factory.hpp:77] Creating layer ip1
I0113 18:17:06.561445  1825 net.cpp:106] Creating Layer ip1
I0113 18:17:06.561450  1825 net.cpp:454] ip1 <- pool3
I0113 18:17:06.561461  1825 net.cpp:411] ip1 -> ip1
I0113 18:17:06.568091  1825 net.cpp:150] Setting up ip1
I0113 18:17:06.568179  1825 net.cpp:157] Top shape: 100 4 (400)
I0113 18:17:06.568193  1825 net.cpp:165] Memory required for data: 351689200
I0113 18:17:06.568233  1825 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0113 18:17:06.568270  1825 net.cpp:106] Creating Layer ip1_ip1_0_split
I0113 18:17:06.568284  1825 net.cpp:454] ip1_ip1_0_split <- ip1
I0113 18:17:06.568305  1825 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0113 18:17:06.568326  1825 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0113 18:17:06.568405  1825 net.cpp:150] Setting up ip1_ip1_0_split
I0113 18:17:06.568418  1825 net.cpp:157] Top shape: 100 4 (400)
I0113 18:17:06.568423  1825 net.cpp:157] Top shape: 100 4 (400)
I0113 18:17:06.568428  1825 net.cpp:165] Memory required for data: 351692400
I0113 18:17:06.568434  1825 layer_factory.hpp:77] Creating layer accuracy
I0113 18:17:06.568457  1825 net.cpp:106] Creating Layer accuracy
I0113 18:17:06.568464  1825 net.cpp:454] accuracy <- ip1_ip1_0_split_0
I0113 18:17:06.568473  1825 net.cpp:454] accuracy <- label_cifar_1_split_0
I0113 18:17:06.568483  1825 net.cpp:411] accuracy -> accuracy
I0113 18:17:06.568500  1825 net.cpp:150] Setting up accuracy
I0113 18:17:06.568508  1825 net.cpp:157] Top shape: (1)
I0113 18:17:06.568512  1825 net.cpp:165] Memory required for data: 351692404
I0113 18:17:06.568517  1825 layer_factory.hpp:77] Creating layer loss
I0113 18:17:06.568544  1825 net.cpp:106] Creating Layer loss
I0113 18:17:06.568552  1825 net.cpp:454] loss <- ip1_ip1_0_split_1
I0113 18:17:06.568560  1825 net.cpp:454] loss <- label_cifar_1_split_1
I0113 18:17:06.568569  1825 net.cpp:411] loss -> loss
I0113 18:17:06.568590  1825 layer_factory.hpp:77] Creating layer loss
I0113 18:17:06.568759  1825 net.cpp:150] Setting up loss
I0113 18:17:06.568771  1825 net.cpp:157] Top shape: (1)
I0113 18:17:06.568775  1825 net.cpp:160]     with loss weight 1
I0113 18:17:06.568796  1825 net.cpp:165] Memory required for data: 351692408
I0113 18:17:06.568804  1825 net.cpp:226] loss needs backward computation.
I0113 18:17:06.568810  1825 net.cpp:228] accuracy does not need backward computation.
I0113 18:17:06.568815  1825 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0113 18:17:06.568835  1825 net.cpp:226] ip1 needs backward computation.
I0113 18:17:06.568841  1825 net.cpp:226] pool3 needs backward computation.
I0113 18:17:06.568846  1825 net.cpp:226] relu3 needs backward computation.
I0113 18:17:06.568851  1825 net.cpp:226] conv3 needs backward computation.
I0113 18:17:06.568857  1825 net.cpp:226] norm2 needs backward computation.
I0113 18:17:06.568862  1825 net.cpp:226] pool2 needs backward computation.
I0113 18:17:06.568866  1825 net.cpp:226] relu2 needs backward computation.
I0113 18:17:06.568871  1825 net.cpp:226] conv2 needs backward computation.
I0113 18:17:06.568876  1825 net.cpp:226] norm1 needs backward computation.
I0113 18:17:06.568881  1825 net.cpp:226] relu1 needs backward computation.
I0113 18:17:06.568886  1825 net.cpp:226] pool1 needs backward computation.
I0113 18:17:06.568891  1825 net.cpp:226] conv1 needs backward computation.
I0113 18:17:06.568920  1825 net.cpp:228] label_cifar_1_split does not need backward computation.
I0113 18:17:06.568927  1825 net.cpp:228] cifar does not need backward computation.
I0113 18:17:06.568929  1825 net.cpp:270] This network produces output accuracy
I0113 18:17:06.568935  1825 net.cpp:270] This network produces output loss
I0113 18:17:06.568959  1825 net.cpp:283] Network initialization done.
I0113 18:17:06.569048  1825 solver.cpp:60] Solver scaffolding done.
I0113 18:17:06.569310  1825 caffe.cpp:203] Resuming from krnet_full_iter_70000.solverstate.h5
I0113 18:17:06.571187  1825 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0113 18:17:06.572760  1825 caffe.cpp:213] Starting Optimization
I0113 18:17:06.572795  1825 solver.cpp:280] Solving CIFAR10_full
I0113 18:17:06.572800  1825 solver.cpp:281] Learning Rate Policy: fixed
I0113 18:17:06.573688  1825 solver.cpp:338] Iteration 70000, Testing net (#0)
I0113 18:17:06.573843  1825 blocking_queue.cpp:50] Data layer prefetch queue empty
I0113 18:17:09.832047  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3867
I0113 18:17:09.832108  1825 solver.cpp:406]     Test net output #1: loss = 1.25842 (* 1 = 1.25842 loss)
I0113 18:17:09.893004  1825 solver.cpp:229] Iteration 70000, loss = 1.45634
I0113 18:17:09.893040  1825 solver.cpp:245]     Train net output #0: loss = 1.45634 (* 1 = 1.45634 loss)
I0113 18:17:09.893049  1825 sgd_solver.cpp:106] Iteration 70000, lr = 0.0001
I0113 18:17:30.720041  1825 solver.cpp:229] Iteration 70200, loss = 1.55744
I0113 18:17:30.720080  1825 solver.cpp:245]     Train net output #0: loss = 1.55744 (* 1 = 1.55744 loss)
I0113 18:17:30.720088  1825 sgd_solver.cpp:106] Iteration 70200, lr = 0.0001
I0113 18:17:51.537026  1825 solver.cpp:229] Iteration 70400, loss = 1.43135
I0113 18:17:51.537096  1825 solver.cpp:245]     Train net output #0: loss = 1.43135 (* 1 = 1.43135 loss)
I0113 18:17:51.537102  1825 sgd_solver.cpp:106] Iteration 70400, lr = 0.0001
I0113 18:18:12.356726  1825 solver.cpp:229] Iteration 70600, loss = 1.14498
I0113 18:18:12.356767  1825 solver.cpp:245]     Train net output #0: loss = 1.14498 (* 1 = 1.14498 loss)
I0113 18:18:12.356775  1825 sgd_solver.cpp:106] Iteration 70600, lr = 0.0001
I0113 18:18:33.176693  1825 solver.cpp:229] Iteration 70800, loss = 1.23239
I0113 18:18:33.176746  1825 solver.cpp:245]     Train net output #0: loss = 1.23239 (* 1 = 1.23239 loss)
I0113 18:18:33.176753  1825 sgd_solver.cpp:106] Iteration 70800, lr = 0.0001
I0113 18:18:53.887145  1825 solver.cpp:338] Iteration 71000, Testing net (#0)
I0113 18:18:57.180685  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3877
I0113 18:18:57.180727  1825 solver.cpp:406]     Test net output #1: loss = 1.25324 (* 1 = 1.25324 loss)
I0113 18:18:57.236532  1825 solver.cpp:229] Iteration 71000, loss = 1.33396
I0113 18:18:57.236572  1825 solver.cpp:245]     Train net output #0: loss = 1.33396 (* 1 = 1.33396 loss)
I0113 18:18:57.236577  1825 sgd_solver.cpp:106] Iteration 71000, lr = 0.0001
I0113 18:19:18.055377  1825 solver.cpp:229] Iteration 71200, loss = 1.26942
I0113 18:19:18.055431  1825 solver.cpp:245]     Train net output #0: loss = 1.26942 (* 1 = 1.26942 loss)
I0113 18:19:18.055443  1825 sgd_solver.cpp:106] Iteration 71200, lr = 0.0001
I0113 18:19:38.872424  1825 solver.cpp:229] Iteration 71400, loss = 1.23162
I0113 18:19:38.872465  1825 solver.cpp:245]     Train net output #0: loss = 1.23162 (* 1 = 1.23162 loss)
I0113 18:19:38.872472  1825 sgd_solver.cpp:106] Iteration 71400, lr = 0.0001
I0113 18:19:59.685889  1825 solver.cpp:229] Iteration 71600, loss = 1.53509
I0113 18:19:59.685941  1825 solver.cpp:245]     Train net output #0: loss = 1.53509 (* 1 = 1.53509 loss)
I0113 18:19:59.685947  1825 sgd_solver.cpp:106] Iteration 71600, lr = 0.0001
I0113 18:20:20.510002  1825 solver.cpp:229] Iteration 71800, loss = 1.44064
I0113 18:20:20.510045  1825 solver.cpp:245]     Train net output #0: loss = 1.44064 (* 1 = 1.44064 loss)
I0113 18:20:20.510051  1825 sgd_solver.cpp:106] Iteration 71800, lr = 0.0001
I0113 18:20:41.224515  1825 solver.cpp:338] Iteration 72000, Testing net (#0)
I0113 18:20:44.519460  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3855
I0113 18:20:44.519502  1825 solver.cpp:406]     Test net output #1: loss = 1.25575 (* 1 = 1.25575 loss)
I0113 18:20:44.575356  1825 solver.cpp:229] Iteration 72000, loss = 1.15715
I0113 18:20:44.575394  1825 solver.cpp:245]     Train net output #0: loss = 1.15715 (* 1 = 1.15715 loss)
I0113 18:20:44.575399  1825 sgd_solver.cpp:106] Iteration 72000, lr = 0.0001
I0113 18:21:05.392238  1825 solver.cpp:229] Iteration 72200, loss = 1.2797
I0113 18:21:05.392280  1825 solver.cpp:245]     Train net output #0: loss = 1.2797 (* 1 = 1.2797 loss)
I0113 18:21:05.392287  1825 sgd_solver.cpp:106] Iteration 72200, lr = 0.0001
I0113 18:21:26.218158  1825 solver.cpp:229] Iteration 72400, loss = 1.15838
I0113 18:21:26.218219  1825 solver.cpp:245]     Train net output #0: loss = 1.15838 (* 1 = 1.15838 loss)
I0113 18:21:26.218226  1825 sgd_solver.cpp:106] Iteration 72400, lr = 0.0001
I0113 18:21:47.035872  1825 solver.cpp:229] Iteration 72600, loss = 1.2182
I0113 18:21:47.035913  1825 solver.cpp:245]     Train net output #0: loss = 1.2182 (* 1 = 1.2182 loss)
I0113 18:21:47.035919  1825 sgd_solver.cpp:106] Iteration 72600, lr = 0.0001
I0113 18:22:07.853358  1825 solver.cpp:229] Iteration 72800, loss = 1.28411
I0113 18:22:07.853421  1825 solver.cpp:245]     Train net output #0: loss = 1.28411 (* 1 = 1.28411 loss)
I0113 18:22:07.853427  1825 sgd_solver.cpp:106] Iteration 72800, lr = 0.0001
I0113 18:22:28.567528  1825 solver.cpp:338] Iteration 73000, Testing net (#0)
I0113 18:22:31.861824  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3925
I0113 18:22:31.861865  1825 solver.cpp:406]     Test net output #1: loss = 1.25127 (* 1 = 1.25127 loss)
I0113 18:22:31.917770  1825 solver.cpp:229] Iteration 73000, loss = 1.32598
I0113 18:22:31.917810  1825 solver.cpp:245]     Train net output #0: loss = 1.32598 (* 1 = 1.32598 loss)
I0113 18:22:31.917815  1825 sgd_solver.cpp:106] Iteration 73000, lr = 0.0001
I0113 18:22:52.726544  1825 solver.cpp:229] Iteration 73200, loss = 1.28267
I0113 18:22:52.726599  1825 solver.cpp:245]     Train net output #0: loss = 1.28267 (* 1 = 1.28267 loss)
I0113 18:22:52.726605  1825 sgd_solver.cpp:106] Iteration 73200, lr = 0.0001
I0113 18:23:13.553653  1825 solver.cpp:229] Iteration 73400, loss = 1.30992
I0113 18:23:13.553694  1825 solver.cpp:245]     Train net output #0: loss = 1.30992 (* 1 = 1.30992 loss)
I0113 18:23:13.553699  1825 sgd_solver.cpp:106] Iteration 73400, lr = 0.0001
I0113 18:23:34.369276  1825 solver.cpp:229] Iteration 73600, loss = 1.24884
I0113 18:23:34.369331  1825 solver.cpp:245]     Train net output #0: loss = 1.24884 (* 1 = 1.24884 loss)
I0113 18:23:34.369338  1825 sgd_solver.cpp:106] Iteration 73600, lr = 0.0001
I0113 18:23:55.176698  1825 solver.cpp:229] Iteration 73800, loss = 1.22148
I0113 18:23:55.176739  1825 solver.cpp:245]     Train net output #0: loss = 1.22148 (* 1 = 1.22148 loss)
I0113 18:23:55.176745  1825 sgd_solver.cpp:106] Iteration 73800, lr = 0.0001
I0113 18:24:15.901583  1825 solver.cpp:338] Iteration 74000, Testing net (#0)
I0113 18:24:19.195451  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3857
I0113 18:24:19.195507  1825 solver.cpp:406]     Test net output #1: loss = 1.25813 (* 1 = 1.25813 loss)
I0113 18:24:19.251370  1825 solver.cpp:229] Iteration 74000, loss = 1.31201
I0113 18:24:19.251410  1825 solver.cpp:245]     Train net output #0: loss = 1.31201 (* 1 = 1.31201 loss)
I0113 18:24:19.251415  1825 sgd_solver.cpp:106] Iteration 74000, lr = 0.0001
I0113 18:24:40.067703  1825 solver.cpp:229] Iteration 74200, loss = 1.12329
I0113 18:24:40.067744  1825 solver.cpp:245]     Train net output #0: loss = 1.12329 (* 1 = 1.12329 loss)
I0113 18:24:40.067749  1825 sgd_solver.cpp:106] Iteration 74200, lr = 0.0001
I0113 18:25:00.882560  1825 solver.cpp:229] Iteration 74400, loss = 1.25203
I0113 18:25:00.882663  1825 solver.cpp:245]     Train net output #0: loss = 1.25203 (* 1 = 1.25203 loss)
I0113 18:25:00.882669  1825 sgd_solver.cpp:106] Iteration 74400, lr = 0.0001
I0113 18:25:21.703316  1825 solver.cpp:229] Iteration 74600, loss = 1.43171
I0113 18:25:21.703357  1825 solver.cpp:245]     Train net output #0: loss = 1.43171 (* 1 = 1.43171 loss)
I0113 18:25:21.703363  1825 sgd_solver.cpp:106] Iteration 74600, lr = 0.0001
I0113 18:25:42.516975  1825 solver.cpp:229] Iteration 74800, loss = 1.27296
I0113 18:25:42.517065  1825 solver.cpp:245]     Train net output #0: loss = 1.27296 (* 1 = 1.27296 loss)
I0113 18:25:42.517071  1825 sgd_solver.cpp:106] Iteration 74800, lr = 0.0001
I0113 18:26:03.241436  1825 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_75000.caffemodel.h5
I0113 18:26:03.313987  1825 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_75000.solverstate.h5
I0113 18:26:03.314677  1825 solver.cpp:338] Iteration 75000, Testing net (#0)
I0113 18:26:06.562891  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3915
I0113 18:26:06.562930  1825 solver.cpp:406]     Test net output #1: loss = 1.25317 (* 1 = 1.25317 loss)
I0113 18:26:06.618715  1825 solver.cpp:229] Iteration 75000, loss = 1.37473
I0113 18:26:06.618751  1825 solver.cpp:245]     Train net output #0: loss = 1.37473 (* 1 = 1.37473 loss)
I0113 18:26:06.618755  1825 sgd_solver.cpp:106] Iteration 75000, lr = 0.0001
I0113 18:26:27.436729  1825 solver.cpp:229] Iteration 75200, loss = 1.28011
I0113 18:26:27.436803  1825 solver.cpp:245]     Train net output #0: loss = 1.28011 (* 1 = 1.28011 loss)
I0113 18:26:27.436810  1825 sgd_solver.cpp:106] Iteration 75200, lr = 0.0001
I0113 18:26:48.247143  1825 solver.cpp:229] Iteration 75400, loss = 1.40731
I0113 18:26:48.247185  1825 solver.cpp:245]     Train net output #0: loss = 1.40731 (* 1 = 1.40731 loss)
I0113 18:26:48.247190  1825 sgd_solver.cpp:106] Iteration 75400, lr = 0.0001
I0113 18:27:09.077706  1825 solver.cpp:229] Iteration 75600, loss = 1.25848
I0113 18:27:09.077760  1825 solver.cpp:245]     Train net output #0: loss = 1.25848 (* 1 = 1.25848 loss)
I0113 18:27:09.077766  1825 sgd_solver.cpp:106] Iteration 75600, lr = 0.0001
I0113 18:27:29.893347  1825 solver.cpp:229] Iteration 75800, loss = 1.24974
I0113 18:27:29.893389  1825 solver.cpp:245]     Train net output #0: loss = 1.24974 (* 1 = 1.24974 loss)
I0113 18:27:29.893395  1825 sgd_solver.cpp:106] Iteration 75800, lr = 0.0001
I0113 18:27:50.600955  1825 solver.cpp:338] Iteration 76000, Testing net (#0)
I0113 18:27:53.892828  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3847
I0113 18:27:53.892868  1825 solver.cpp:406]     Test net output #1: loss = 1.25458 (* 1 = 1.25458 loss)
I0113 18:27:53.948767  1825 solver.cpp:229] Iteration 76000, loss = 1.22149
I0113 18:27:53.948804  1825 solver.cpp:245]     Train net output #0: loss = 1.22149 (* 1 = 1.22149 loss)
I0113 18:27:53.948809  1825 sgd_solver.cpp:106] Iteration 76000, lr = 0.0001
I0113 18:28:14.769358  1825 solver.cpp:229] Iteration 76200, loss = 1.25467
I0113 18:28:14.769399  1825 solver.cpp:245]     Train net output #0: loss = 1.25467 (* 1 = 1.25467 loss)
I0113 18:28:14.769404  1825 sgd_solver.cpp:106] Iteration 76200, lr = 0.0001
I0113 18:28:35.581573  1825 solver.cpp:229] Iteration 76400, loss = 1.59085
I0113 18:28:35.581665  1825 solver.cpp:245]     Train net output #0: loss = 1.59085 (* 1 = 1.59085 loss)
I0113 18:28:35.581672  1825 sgd_solver.cpp:106] Iteration 76400, lr = 0.0001
I0113 18:28:56.397855  1825 solver.cpp:229] Iteration 76600, loss = 1.49025
I0113 18:28:56.397897  1825 solver.cpp:245]     Train net output #0: loss = 1.49025 (* 1 = 1.49025 loss)
I0113 18:28:56.397902  1825 sgd_solver.cpp:106] Iteration 76600, lr = 0.0001
I0113 18:29:17.219039  1825 solver.cpp:229] Iteration 76800, loss = 1.15581
I0113 18:29:17.219131  1825 solver.cpp:245]     Train net output #0: loss = 1.15581 (* 1 = 1.15581 loss)
I0113 18:29:17.219137  1825 sgd_solver.cpp:106] Iteration 76800, lr = 0.0001
I0113 18:29:37.922960  1825 solver.cpp:338] Iteration 77000, Testing net (#0)
I0113 18:29:41.216421  1825 solver.cpp:406]     Test net output #0: accuracy = 0.391
I0113 18:29:41.216459  1825 solver.cpp:406]     Test net output #1: loss = 1.25231 (* 1 = 1.25231 loss)
I0113 18:29:41.272239  1825 solver.cpp:229] Iteration 77000, loss = 1.13593
I0113 18:29:41.272275  1825 solver.cpp:245]     Train net output #0: loss = 1.13593 (* 1 = 1.13593 loss)
I0113 18:29:41.272280  1825 sgd_solver.cpp:106] Iteration 77000, lr = 0.0001
I0113 18:30:02.097350  1825 solver.cpp:229] Iteration 77200, loss = 1.06321
I0113 18:30:02.097421  1825 solver.cpp:245]     Train net output #0: loss = 1.06321 (* 1 = 1.06321 loss)
I0113 18:30:02.097427  1825 sgd_solver.cpp:106] Iteration 77200, lr = 0.0001
I0113 18:30:22.910261  1825 solver.cpp:229] Iteration 77400, loss = 1.05925
I0113 18:30:22.910301  1825 solver.cpp:245]     Train net output #0: loss = 1.05925 (* 1 = 1.05925 loss)
I0113 18:30:22.910307  1825 sgd_solver.cpp:106] Iteration 77400, lr = 0.0001
I0113 18:30:43.720305  1825 solver.cpp:229] Iteration 77600, loss = 1.16664
I0113 18:30:43.720396  1825 solver.cpp:245]     Train net output #0: loss = 1.16664 (* 1 = 1.16664 loss)
I0113 18:30:43.720402  1825 sgd_solver.cpp:106] Iteration 77600, lr = 0.0001
I0113 18:31:04.541376  1825 solver.cpp:229] Iteration 77800, loss = 1.11526
I0113 18:31:04.541419  1825 solver.cpp:245]     Train net output #0: loss = 1.11526 (* 1 = 1.11526 loss)
I0113 18:31:04.541424  1825 sgd_solver.cpp:106] Iteration 77800, lr = 0.0001
I0113 18:31:25.252514  1825 solver.cpp:338] Iteration 78000, Testing net (#0)
I0113 18:31:28.542820  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3863
I0113 18:31:28.542860  1825 solver.cpp:406]     Test net output #1: loss = 1.25832 (* 1 = 1.25832 loss)
I0113 18:31:28.598659  1825 solver.cpp:229] Iteration 78000, loss = 1.24936
I0113 18:31:28.598693  1825 solver.cpp:245]     Train net output #0: loss = 1.24936 (* 1 = 1.24936 loss)
I0113 18:31:28.598698  1825 sgd_solver.cpp:106] Iteration 78000, lr = 0.0001
I0113 18:31:49.415501  1825 solver.cpp:229] Iteration 78200, loss = 1.13935
I0113 18:31:49.415542  1825 solver.cpp:245]     Train net output #0: loss = 1.13935 (* 1 = 1.13935 loss)
I0113 18:31:49.415547  1825 sgd_solver.cpp:106] Iteration 78200, lr = 0.0001
I0113 18:32:10.237141  1825 solver.cpp:229] Iteration 78400, loss = 1.36862
I0113 18:32:10.237215  1825 solver.cpp:245]     Train net output #0: loss = 1.36862 (* 1 = 1.36862 loss)
I0113 18:32:10.237226  1825 sgd_solver.cpp:106] Iteration 78400, lr = 0.0001
I0113 18:32:31.046090  1825 solver.cpp:229] Iteration 78600, loss = 1.17241
I0113 18:32:31.046131  1825 solver.cpp:245]     Train net output #0: loss = 1.17241 (* 1 = 1.17241 loss)
I0113 18:32:31.046138  1825 sgd_solver.cpp:106] Iteration 78600, lr = 0.0001
I0113 18:32:51.866513  1825 solver.cpp:229] Iteration 78800, loss = 1.0517
I0113 18:32:51.866565  1825 solver.cpp:245]     Train net output #0: loss = 1.0517 (* 1 = 1.0517 loss)
I0113 18:32:51.866571  1825 sgd_solver.cpp:106] Iteration 78800, lr = 0.0001
I0113 18:33:12.576997  1825 solver.cpp:338] Iteration 79000, Testing net (#0)
I0113 18:33:15.869632  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3911
I0113 18:33:15.869670  1825 solver.cpp:406]     Test net output #1: loss = 1.25359 (* 1 = 1.25359 loss)
I0113 18:33:15.925384  1825 solver.cpp:229] Iteration 79000, loss = 1.2706
I0113 18:33:15.925420  1825 solver.cpp:245]     Train net output #0: loss = 1.2706 (* 1 = 1.2706 loss)
I0113 18:33:15.925426  1825 sgd_solver.cpp:106] Iteration 79000, lr = 0.0001
I0113 18:33:36.733604  1825 solver.cpp:229] Iteration 79200, loss = 1.42953
I0113 18:33:36.733656  1825 solver.cpp:245]     Train net output #0: loss = 1.42953 (* 1 = 1.42953 loss)
I0113 18:33:36.733662  1825 sgd_solver.cpp:106] Iteration 79200, lr = 0.0001
I0113 18:33:57.556035  1825 solver.cpp:229] Iteration 79400, loss = 1.24879
I0113 18:33:57.556076  1825 solver.cpp:245]     Train net output #0: loss = 1.24879 (* 1 = 1.24879 loss)
I0113 18:33:57.556082  1825 sgd_solver.cpp:106] Iteration 79400, lr = 0.0001
I0113 18:34:18.371245  1825 solver.cpp:229] Iteration 79600, loss = 1.21563
I0113 18:34:18.371343  1825 solver.cpp:245]     Train net output #0: loss = 1.21563 (* 1 = 1.21563 loss)
I0113 18:34:18.371351  1825 sgd_solver.cpp:106] Iteration 79600, lr = 0.0001
I0113 18:34:39.186146  1825 solver.cpp:229] Iteration 79800, loss = 1.36653
I0113 18:34:39.186183  1825 solver.cpp:245]     Train net output #0: loss = 1.36653 (* 1 = 1.36653 loss)
I0113 18:34:39.186189  1825 sgd_solver.cpp:106] Iteration 79800, lr = 0.0001
I0113 18:34:59.907505  1825 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_80000.caffemodel.h5
I0113 18:34:59.956639  1825 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_80000.solverstate.h5
I0113 18:34:59.957289  1825 solver.cpp:338] Iteration 80000, Testing net (#0)
I0113 18:35:03.204211  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3861
I0113 18:35:03.204252  1825 solver.cpp:406]     Test net output #1: loss = 1.25431 (* 1 = 1.25431 loss)
I0113 18:35:03.260105  1825 solver.cpp:229] Iteration 80000, loss = 1.40453
I0113 18:35:03.260141  1825 solver.cpp:245]     Train net output #0: loss = 1.40453 (* 1 = 1.40453 loss)
I0113 18:35:03.260146  1825 sgd_solver.cpp:106] Iteration 80000, lr = 0.0001
I0113 18:35:24.067775  1825 solver.cpp:229] Iteration 80200, loss = 1.07013
I0113 18:35:24.067816  1825 solver.cpp:245]     Train net output #0: loss = 1.07013 (* 1 = 1.07013 loss)
I0113 18:35:24.067822  1825 sgd_solver.cpp:106] Iteration 80200, lr = 0.0001
I0113 18:35:44.885949  1825 solver.cpp:229] Iteration 80400, loss = 1.22301
I0113 18:35:44.886021  1825 solver.cpp:245]     Train net output #0: loss = 1.22301 (* 1 = 1.22301 loss)
I0113 18:35:44.886028  1825 sgd_solver.cpp:106] Iteration 80400, lr = 0.0001
I0113 18:36:05.704551  1825 solver.cpp:229] Iteration 80600, loss = 1.25588
I0113 18:36:05.704593  1825 solver.cpp:245]     Train net output #0: loss = 1.25588 (* 1 = 1.25588 loss)
I0113 18:36:05.704598  1825 sgd_solver.cpp:106] Iteration 80600, lr = 0.0001
I0113 18:36:26.509596  1825 solver.cpp:229] Iteration 80800, loss = 1.09234
I0113 18:36:26.509666  1825 solver.cpp:245]     Train net output #0: loss = 1.09234 (* 1 = 1.09234 loss)
I0113 18:36:26.509672  1825 sgd_solver.cpp:106] Iteration 80800, lr = 0.0001
I0113 18:36:47.226709  1825 solver.cpp:338] Iteration 81000, Testing net (#0)
I0113 18:36:50.519379  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3891
I0113 18:36:50.519419  1825 solver.cpp:406]     Test net output #1: loss = 1.25265 (* 1 = 1.25265 loss)
I0113 18:36:50.575184  1825 solver.cpp:229] Iteration 81000, loss = 1.37203
I0113 18:36:50.575223  1825 solver.cpp:245]     Train net output #0: loss = 1.37203 (* 1 = 1.37203 loss)
I0113 18:36:50.575228  1825 sgd_solver.cpp:106] Iteration 81000, lr = 0.0001
I0113 18:37:11.387377  1825 solver.cpp:229] Iteration 81200, loss = 1.1512
I0113 18:37:11.387437  1825 solver.cpp:245]     Train net output #0: loss = 1.1512 (* 1 = 1.1512 loss)
I0113 18:37:11.387444  1825 sgd_solver.cpp:106] Iteration 81200, lr = 0.0001
I0113 18:37:32.197254  1825 solver.cpp:229] Iteration 81400, loss = 1.33223
I0113 18:37:32.197294  1825 solver.cpp:245]     Train net output #0: loss = 1.33223 (* 1 = 1.33223 loss)
I0113 18:37:32.197299  1825 sgd_solver.cpp:106] Iteration 81400, lr = 0.0001
I0113 18:37:53.014041  1825 solver.cpp:229] Iteration 81600, loss = 1.31925
I0113 18:37:53.014094  1825 solver.cpp:245]     Train net output #0: loss = 1.31925 (* 1 = 1.31925 loss)
I0113 18:37:53.014101  1825 sgd_solver.cpp:106] Iteration 81600, lr = 0.0001
I0113 18:38:13.829355  1825 solver.cpp:229] Iteration 81800, loss = 1.14609
I0113 18:38:13.829396  1825 solver.cpp:245]     Train net output #0: loss = 1.14609 (* 1 = 1.14609 loss)
I0113 18:38:13.829401  1825 sgd_solver.cpp:106] Iteration 81800, lr = 0.0001
I0113 18:38:34.544247  1825 solver.cpp:338] Iteration 82000, Testing net (#0)
I0113 18:38:37.835639  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3881
I0113 18:38:37.835677  1825 solver.cpp:406]     Test net output #1: loss = 1.25752 (* 1 = 1.25752 loss)
I0113 18:38:37.891486  1825 solver.cpp:229] Iteration 82000, loss = 1.01887
I0113 18:38:37.891523  1825 solver.cpp:245]     Train net output #0: loss = 1.01887 (* 1 = 1.01887 loss)
I0113 18:38:37.891528  1825 sgd_solver.cpp:106] Iteration 82000, lr = 0.0001
I0113 18:38:58.705061  1825 solver.cpp:229] Iteration 82200, loss = 1.22935
I0113 18:38:58.705101  1825 solver.cpp:245]     Train net output #0: loss = 1.22935 (* 1 = 1.22935 loss)
I0113 18:38:58.705107  1825 sgd_solver.cpp:106] Iteration 82200, lr = 0.0001
I0113 18:39:19.518366  1825 solver.cpp:229] Iteration 82400, loss = 1.21792
I0113 18:39:19.518467  1825 solver.cpp:245]     Train net output #0: loss = 1.21792 (* 1 = 1.21792 loss)
I0113 18:39:19.518474  1825 sgd_solver.cpp:106] Iteration 82400, lr = 0.0001
I0113 18:39:40.340337  1825 solver.cpp:229] Iteration 82600, loss = 1.23054
I0113 18:39:40.340375  1825 solver.cpp:245]     Train net output #0: loss = 1.23054 (* 1 = 1.23054 loss)
I0113 18:39:40.340380  1825 sgd_solver.cpp:106] Iteration 82600, lr = 0.0001
I0113 18:40:01.153048  1825 solver.cpp:229] Iteration 82800, loss = 1.09467
I0113 18:40:01.153106  1825 solver.cpp:245]     Train net output #0: loss = 1.09467 (* 1 = 1.09467 loss)
I0113 18:40:01.153112  1825 sgd_solver.cpp:106] Iteration 82800, lr = 0.0001
I0113 18:40:21.857636  1825 solver.cpp:338] Iteration 83000, Testing net (#0)
I0113 18:40:25.150943  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3895
I0113 18:40:25.150982  1825 solver.cpp:406]     Test net output #1: loss = 1.25379 (* 1 = 1.25379 loss)
I0113 18:40:25.206780  1825 solver.cpp:229] Iteration 83000, loss = 1.11656
I0113 18:40:25.206816  1825 solver.cpp:245]     Train net output #0: loss = 1.11656 (* 1 = 1.11656 loss)
I0113 18:40:25.206821  1825 sgd_solver.cpp:106] Iteration 83000, lr = 0.0001
I0113 18:40:46.026473  1825 solver.cpp:229] Iteration 83200, loss = 1.19725
I0113 18:40:46.026523  1825 solver.cpp:245]     Train net output #0: loss = 1.19725 (* 1 = 1.19725 loss)
I0113 18:40:46.026530  1825 sgd_solver.cpp:106] Iteration 83200, lr = 0.0001
I0113 18:41:06.844840  1825 solver.cpp:229] Iteration 83400, loss = 1.19074
I0113 18:41:06.844879  1825 solver.cpp:245]     Train net output #0: loss = 1.19074 (* 1 = 1.19074 loss)
I0113 18:41:06.844885  1825 sgd_solver.cpp:106] Iteration 83400, lr = 0.0001
I0113 18:41:27.662596  1825 solver.cpp:229] Iteration 83600, loss = 1.2132
I0113 18:41:27.662649  1825 solver.cpp:245]     Train net output #0: loss = 1.2132 (* 1 = 1.2132 loss)
I0113 18:41:27.662655  1825 sgd_solver.cpp:106] Iteration 83600, lr = 0.0001
I0113 18:41:48.477300  1825 solver.cpp:229] Iteration 83800, loss = 1.18973
I0113 18:41:48.477341  1825 solver.cpp:245]     Train net output #0: loss = 1.18973 (* 1 = 1.18973 loss)
I0113 18:41:48.477347  1825 sgd_solver.cpp:106] Iteration 83800, lr = 0.0001
I0113 18:42:09.186704  1825 solver.cpp:338] Iteration 84000, Testing net (#0)
I0113 18:42:12.480718  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3869
I0113 18:42:12.480758  1825 solver.cpp:406]     Test net output #1: loss = 1.25467 (* 1 = 1.25467 loss)
I0113 18:42:12.536614  1825 solver.cpp:229] Iteration 84000, loss = 1.21822
I0113 18:42:12.536650  1825 solver.cpp:245]     Train net output #0: loss = 1.21822 (* 1 = 1.21822 loss)
I0113 18:42:12.536661  1825 sgd_solver.cpp:106] Iteration 84000, lr = 0.0001
I0113 18:42:33.358463  1825 solver.cpp:229] Iteration 84200, loss = 1.31354
I0113 18:42:33.358503  1825 solver.cpp:245]     Train net output #0: loss = 1.31354 (* 1 = 1.31354 loss)
I0113 18:42:33.358510  1825 sgd_solver.cpp:106] Iteration 84200, lr = 0.0001
I0113 18:42:54.173460  1825 solver.cpp:229] Iteration 84400, loss = 1.18936
I0113 18:42:54.173514  1825 solver.cpp:245]     Train net output #0: loss = 1.18936 (* 1 = 1.18936 loss)
I0113 18:42:54.173521  1825 sgd_solver.cpp:106] Iteration 84400, lr = 0.0001
I0113 18:43:14.982008  1825 solver.cpp:229] Iteration 84600, loss = 1.35382
I0113 18:43:14.982048  1825 solver.cpp:245]     Train net output #0: loss = 1.35382 (* 1 = 1.35382 loss)
I0113 18:43:14.982054  1825 sgd_solver.cpp:106] Iteration 84600, lr = 0.0001
I0113 18:43:35.801143  1825 solver.cpp:229] Iteration 84800, loss = 1.19593
I0113 18:43:35.801236  1825 solver.cpp:245]     Train net output #0: loss = 1.19593 (* 1 = 1.19593 loss)
I0113 18:43:35.801242  1825 sgd_solver.cpp:106] Iteration 84800, lr = 0.0001
I0113 18:43:56.515902  1825 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_85000.caffemodel.h5
I0113 18:43:56.565016  1825 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_85000.solverstate.h5
I0113 18:43:56.597980  1825 solver.cpp:318] Iteration 85000, loss = 1.06838
I0113 18:43:56.598012  1825 solver.cpp:338] Iteration 85000, Testing net (#0)
I0113 18:43:59.844400  1825 solver.cpp:406]     Test net output #0: accuracy = 0.3858
I0113 18:43:59.844440  1825 solver.cpp:406]     Test net output #1: loss = 1.25384 (* 1 = 1.25384 loss)
I0113 18:43:59.844445  1825 solver.cpp:323] Optimization Done.
I0113 18:43:59.844447  1825 caffe.cpp:216] Optimization Done.
I0113 18:43:59.971408  2396 caffe.cpp:185] Using GPUs 0
I0113 18:44:00.147197  2396 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 1e-05
display: 200
max_iter: 95000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 5000
snapshot_prefix: "krnet_full"
solver_mode: GPU
device_id: 0
net: "krnet_full_train_test.prototxt"
snapshot_format: HDF5
I0113 18:44:00.147326  2396 solver.cpp:91] Creating training net from net file: krnet_full_train_test.prototxt
I0113 18:44:00.147799  2396 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0113 18:44:00.147815  2396 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0113 18:44:00.148013  2396 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "train_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 18:44:00.148118  2396 layer_factory.hpp:77] Creating layer cifar
I0113 18:44:00.149102  2396 net.cpp:106] Creating Layer cifar
I0113 18:44:00.149121  2396 net.cpp:411] cifar -> data
I0113 18:44:00.149142  2396 net.cpp:411] cifar -> label
I0113 18:44:00.149153  2396 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 18:44:00.149667  2400 db_lmdb.cpp:38] Opened lmdb train_lmdb
I0113 18:44:00.163555  2396 data_layer.cpp:41] output data size: 100,3,100,100
I0113 18:44:00.177500  2396 net.cpp:150] Setting up cifar
I0113 18:44:00.177534  2396 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 18:44:00.177551  2396 net.cpp:157] Top shape: 100 (100)
I0113 18:44:00.177554  2396 net.cpp:165] Memory required for data: 12000400
I0113 18:44:00.177568  2396 layer_factory.hpp:77] Creating layer conv1
I0113 18:44:00.177599  2396 net.cpp:106] Creating Layer conv1
I0113 18:44:00.177605  2396 net.cpp:454] conv1 <- data
I0113 18:44:00.177623  2396 net.cpp:411] conv1 -> conv1
I0113 18:44:00.180163  2396 net.cpp:150] Setting up conv1
I0113 18:44:00.180194  2396 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 18:44:00.180197  2396 net.cpp:165] Memory required for data: 140000400
I0113 18:44:00.180223  2396 layer_factory.hpp:77] Creating layer pool1
I0113 18:44:00.180243  2396 net.cpp:106] Creating Layer pool1
I0113 18:44:00.180248  2396 net.cpp:454] pool1 <- conv1
I0113 18:44:00.180256  2396 net.cpp:411] pool1 -> pool1
I0113 18:44:00.180296  2396 net.cpp:150] Setting up pool1
I0113 18:44:00.180302  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.180305  2396 net.cpp:165] Memory required for data: 172000400
I0113 18:44:00.180307  2396 layer_factory.hpp:77] Creating layer relu1
I0113 18:44:00.180315  2396 net.cpp:106] Creating Layer relu1
I0113 18:44:00.180317  2396 net.cpp:454] relu1 <- pool1
I0113 18:44:00.180323  2396 net.cpp:397] relu1 -> pool1 (in-place)
I0113 18:44:00.180330  2396 net.cpp:150] Setting up relu1
I0113 18:44:00.180333  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.180335  2396 net.cpp:165] Memory required for data: 204000400
I0113 18:44:00.180337  2396 layer_factory.hpp:77] Creating layer norm1
I0113 18:44:00.180346  2396 net.cpp:106] Creating Layer norm1
I0113 18:44:00.180349  2396 net.cpp:454] norm1 <- pool1
I0113 18:44:00.180354  2396 net.cpp:411] norm1 -> norm1
I0113 18:44:00.180430  2396 net.cpp:150] Setting up norm1
I0113 18:44:00.180438  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.180439  2396 net.cpp:165] Memory required for data: 236000400
I0113 18:44:00.180443  2396 layer_factory.hpp:77] Creating layer conv2
I0113 18:44:00.180455  2396 net.cpp:106] Creating Layer conv2
I0113 18:44:00.180459  2396 net.cpp:454] conv2 <- norm1
I0113 18:44:00.180466  2396 net.cpp:411] conv2 -> conv2
I0113 18:44:00.183568  2396 net.cpp:150] Setting up conv2
I0113 18:44:00.183600  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.183604  2396 net.cpp:165] Memory required for data: 268000400
I0113 18:44:00.183621  2396 layer_factory.hpp:77] Creating layer relu2
I0113 18:44:00.183635  2396 net.cpp:106] Creating Layer relu2
I0113 18:44:00.183640  2396 net.cpp:454] relu2 <- conv2
I0113 18:44:00.183648  2396 net.cpp:397] relu2 -> conv2 (in-place)
I0113 18:44:00.183656  2396 net.cpp:150] Setting up relu2
I0113 18:44:00.183660  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.183662  2396 net.cpp:165] Memory required for data: 300000400
I0113 18:44:00.183665  2396 layer_factory.hpp:77] Creating layer pool2
I0113 18:44:00.183673  2396 net.cpp:106] Creating Layer pool2
I0113 18:44:00.183676  2396 net.cpp:454] pool2 <- conv2
I0113 18:44:00.183681  2396 net.cpp:411] pool2 -> pool2
I0113 18:44:00.183703  2396 net.cpp:150] Setting up pool2
I0113 18:44:00.183708  2396 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:44:00.183711  2396 net.cpp:165] Memory required for data: 308000400
I0113 18:44:00.183713  2396 layer_factory.hpp:77] Creating layer norm2
I0113 18:44:00.183724  2396 net.cpp:106] Creating Layer norm2
I0113 18:44:00.183727  2396 net.cpp:454] norm2 <- pool2
I0113 18:44:00.183733  2396 net.cpp:411] norm2 -> norm2
I0113 18:44:00.183802  2396 net.cpp:150] Setting up norm2
I0113 18:44:00.183809  2396 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:44:00.183811  2396 net.cpp:165] Memory required for data: 316000400
I0113 18:44:00.183814  2396 layer_factory.hpp:77] Creating layer conv3
I0113 18:44:00.183825  2396 net.cpp:106] Creating Layer conv3
I0113 18:44:00.183828  2396 net.cpp:454] conv3 <- norm2
I0113 18:44:00.183836  2396 net.cpp:411] conv3 -> conv3
I0113 18:44:00.190516  2396 net.cpp:150] Setting up conv3
I0113 18:44:00.190562  2396 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:44:00.190565  2396 net.cpp:165] Memory required for data: 332000400
I0113 18:44:00.190585  2396 layer_factory.hpp:77] Creating layer relu3
I0113 18:44:00.190600  2396 net.cpp:106] Creating Layer relu3
I0113 18:44:00.190606  2396 net.cpp:454] relu3 <- conv3
I0113 18:44:00.190614  2396 net.cpp:397] relu3 -> conv3 (in-place)
I0113 18:44:00.190623  2396 net.cpp:150] Setting up relu3
I0113 18:44:00.190628  2396 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:44:00.190629  2396 net.cpp:165] Memory required for data: 348000400
I0113 18:44:00.190631  2396 layer_factory.hpp:77] Creating layer pool3
I0113 18:44:00.190639  2396 net.cpp:106] Creating Layer pool3
I0113 18:44:00.190642  2396 net.cpp:454] pool3 <- conv3
I0113 18:44:00.190649  2396 net.cpp:411] pool3 -> pool3
I0113 18:44:00.190675  2396 net.cpp:150] Setting up pool3
I0113 18:44:00.190681  2396 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 18:44:00.190683  2396 net.cpp:165] Memory required for data: 351686800
I0113 18:44:00.190686  2396 layer_factory.hpp:77] Creating layer ip1
I0113 18:44:00.190698  2396 net.cpp:106] Creating Layer ip1
I0113 18:44:00.190702  2396 net.cpp:454] ip1 <- pool3
I0113 18:44:00.190709  2396 net.cpp:411] ip1 -> ip1
I0113 18:44:00.195035  2396 net.cpp:150] Setting up ip1
I0113 18:44:00.195063  2396 net.cpp:157] Top shape: 100 4 (400)
I0113 18:44:00.195066  2396 net.cpp:165] Memory required for data: 351688400
I0113 18:44:00.195076  2396 layer_factory.hpp:77] Creating layer loss
I0113 18:44:00.195089  2396 net.cpp:106] Creating Layer loss
I0113 18:44:00.195096  2396 net.cpp:454] loss <- ip1
I0113 18:44:00.195102  2396 net.cpp:454] loss <- label
I0113 18:44:00.195108  2396 net.cpp:411] loss -> loss
I0113 18:44:00.195122  2396 layer_factory.hpp:77] Creating layer loss
I0113 18:44:00.195194  2396 net.cpp:150] Setting up loss
I0113 18:44:00.195200  2396 net.cpp:157] Top shape: (1)
I0113 18:44:00.195204  2396 net.cpp:160]     with loss weight 1
I0113 18:44:00.195238  2396 net.cpp:165] Memory required for data: 351688404
I0113 18:44:00.195242  2396 net.cpp:226] loss needs backward computation.
I0113 18:44:00.195246  2396 net.cpp:226] ip1 needs backward computation.
I0113 18:44:00.195260  2396 net.cpp:226] pool3 needs backward computation.
I0113 18:44:00.195262  2396 net.cpp:226] relu3 needs backward computation.
I0113 18:44:00.195266  2396 net.cpp:226] conv3 needs backward computation.
I0113 18:44:00.195269  2396 net.cpp:226] norm2 needs backward computation.
I0113 18:44:00.195272  2396 net.cpp:226] pool2 needs backward computation.
I0113 18:44:00.195276  2396 net.cpp:226] relu2 needs backward computation.
I0113 18:44:00.195278  2396 net.cpp:226] conv2 needs backward computation.
I0113 18:44:00.195281  2396 net.cpp:226] norm1 needs backward computation.
I0113 18:44:00.195284  2396 net.cpp:226] relu1 needs backward computation.
I0113 18:44:00.195286  2396 net.cpp:226] pool1 needs backward computation.
I0113 18:44:00.195289  2396 net.cpp:226] conv1 needs backward computation.
I0113 18:44:00.195293  2396 net.cpp:228] cifar does not need backward computation.
I0113 18:44:00.195296  2396 net.cpp:270] This network produces output loss
I0113 18:44:00.195310  2396 net.cpp:283] Network initialization done.
I0113 18:44:00.195755  2396 solver.cpp:181] Creating test net (#0) specified by net file: krnet_full_train_test.prototxt
I0113 18:44:00.195796  2396 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0113 18:44:00.196036  2396 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "test_lmdb"
    batch_size: 100
    backend: LMDB
    prefetch: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 250
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0113 18:44:00.196167  2396 layer_factory.hpp:77] Creating layer cifar
I0113 18:44:00.196856  2396 net.cpp:106] Creating Layer cifar
I0113 18:44:00.196869  2396 net.cpp:411] cifar -> data
I0113 18:44:00.196882  2396 net.cpp:411] cifar -> label
I0113 18:44:00.196892  2396 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0113 18:44:00.197541  2402 db_lmdb.cpp:38] Opened lmdb test_lmdb
I0113 18:44:00.198359  2396 data_layer.cpp:41] output data size: 100,3,100,100
I0113 18:44:00.212697  2396 net.cpp:150] Setting up cifar
I0113 18:44:00.212749  2396 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0113 18:44:00.212760  2396 net.cpp:157] Top shape: 100 (100)
I0113 18:44:00.212765  2396 net.cpp:165] Memory required for data: 12000400
I0113 18:44:00.212775  2396 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0113 18:44:00.212802  2396 net.cpp:106] Creating Layer label_cifar_1_split
I0113 18:44:00.212812  2396 net.cpp:454] label_cifar_1_split <- label
I0113 18:44:00.212831  2396 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_0
I0113 18:44:00.212849  2396 net.cpp:411] label_cifar_1_split -> label_cifar_1_split_1
I0113 18:44:00.212924  2396 net.cpp:150] Setting up label_cifar_1_split
I0113 18:44:00.212935  2396 net.cpp:157] Top shape: 100 (100)
I0113 18:44:00.212941  2396 net.cpp:157] Top shape: 100 (100)
I0113 18:44:00.212946  2396 net.cpp:165] Memory required for data: 12001200
I0113 18:44:00.212951  2396 layer_factory.hpp:77] Creating layer conv1
I0113 18:44:00.212975  2396 net.cpp:106] Creating Layer conv1
I0113 18:44:00.212981  2396 net.cpp:454] conv1 <- data
I0113 18:44:00.212994  2396 net.cpp:411] conv1 -> conv1
I0113 18:44:00.214937  2396 net.cpp:150] Setting up conv1
I0113 18:44:00.215010  2396 net.cpp:157] Top shape: 100 32 100 100 (32000000)
I0113 18:44:00.215018  2396 net.cpp:165] Memory required for data: 140001200
I0113 18:44:00.215049  2396 layer_factory.hpp:77] Creating layer pool1
I0113 18:44:00.215072  2396 net.cpp:106] Creating Layer pool1
I0113 18:44:00.215080  2396 net.cpp:454] pool1 <- conv1
I0113 18:44:00.215092  2396 net.cpp:411] pool1 -> pool1
I0113 18:44:00.215150  2396 net.cpp:150] Setting up pool1
I0113 18:44:00.215159  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.215163  2396 net.cpp:165] Memory required for data: 172001200
I0113 18:44:00.215168  2396 layer_factory.hpp:77] Creating layer relu1
I0113 18:44:00.215181  2396 net.cpp:106] Creating Layer relu1
I0113 18:44:00.215185  2396 net.cpp:454] relu1 <- pool1
I0113 18:44:00.215195  2396 net.cpp:397] relu1 -> pool1 (in-place)
I0113 18:44:00.215204  2396 net.cpp:150] Setting up relu1
I0113 18:44:00.215209  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.215214  2396 net.cpp:165] Memory required for data: 204001200
I0113 18:44:00.215222  2396 layer_factory.hpp:77] Creating layer norm1
I0113 18:44:00.215239  2396 net.cpp:106] Creating Layer norm1
I0113 18:44:00.215243  2396 net.cpp:454] norm1 <- pool1
I0113 18:44:00.215252  2396 net.cpp:411] norm1 -> norm1
I0113 18:44:00.215364  2396 net.cpp:150] Setting up norm1
I0113 18:44:00.215374  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.215378  2396 net.cpp:165] Memory required for data: 236001200
I0113 18:44:00.215384  2396 layer_factory.hpp:77] Creating layer conv2
I0113 18:44:00.215404  2396 net.cpp:106] Creating Layer conv2
I0113 18:44:00.215409  2396 net.cpp:454] conv2 <- norm1
I0113 18:44:00.215421  2396 net.cpp:411] conv2 -> conv2
I0113 18:44:00.220075  2396 net.cpp:150] Setting up conv2
I0113 18:44:00.220125  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.220130  2396 net.cpp:165] Memory required for data: 268001200
I0113 18:44:00.220156  2396 layer_factory.hpp:77] Creating layer relu2
I0113 18:44:00.220175  2396 net.cpp:106] Creating Layer relu2
I0113 18:44:00.220183  2396 net.cpp:454] relu2 <- conv2
I0113 18:44:00.220194  2396 net.cpp:397] relu2 -> conv2 (in-place)
I0113 18:44:00.220227  2396 net.cpp:150] Setting up relu2
I0113 18:44:00.220235  2396 net.cpp:157] Top shape: 100 32 50 50 (8000000)
I0113 18:44:00.220239  2396 net.cpp:165] Memory required for data: 300001200
I0113 18:44:00.220243  2396 layer_factory.hpp:77] Creating layer pool2
I0113 18:44:00.220260  2396 net.cpp:106] Creating Layer pool2
I0113 18:44:00.220265  2396 net.cpp:454] pool2 <- conv2
I0113 18:44:00.220275  2396 net.cpp:411] pool2 -> pool2
I0113 18:44:00.220311  2396 net.cpp:150] Setting up pool2
I0113 18:44:00.220320  2396 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:44:00.220324  2396 net.cpp:165] Memory required for data: 308001200
I0113 18:44:00.220329  2396 layer_factory.hpp:77] Creating layer norm2
I0113 18:44:00.220340  2396 net.cpp:106] Creating Layer norm2
I0113 18:44:00.220345  2396 net.cpp:454] norm2 <- pool2
I0113 18:44:00.220355  2396 net.cpp:411] norm2 -> norm2
I0113 18:44:00.220456  2396 net.cpp:150] Setting up norm2
I0113 18:44:00.220466  2396 net.cpp:157] Top shape: 100 32 25 25 (2000000)
I0113 18:44:00.220470  2396 net.cpp:165] Memory required for data: 316001200
I0113 18:44:00.220474  2396 layer_factory.hpp:77] Creating layer conv3
I0113 18:44:00.220491  2396 net.cpp:106] Creating Layer conv3
I0113 18:44:00.220497  2396 net.cpp:454] conv3 <- norm2
I0113 18:44:00.220507  2396 net.cpp:411] conv3 -> conv3
I0113 18:44:00.229418  2396 net.cpp:150] Setting up conv3
I0113 18:44:00.229465  2396 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:44:00.229470  2396 net.cpp:165] Memory required for data: 332001200
I0113 18:44:00.229496  2396 layer_factory.hpp:77] Creating layer relu3
I0113 18:44:00.229516  2396 net.cpp:106] Creating Layer relu3
I0113 18:44:00.229524  2396 net.cpp:454] relu3 <- conv3
I0113 18:44:00.229537  2396 net.cpp:397] relu3 -> conv3 (in-place)
I0113 18:44:00.229570  2396 net.cpp:150] Setting up relu3
I0113 18:44:00.229578  2396 net.cpp:157] Top shape: 100 64 25 25 (4000000)
I0113 18:44:00.229581  2396 net.cpp:165] Memory required for data: 348001200
I0113 18:44:00.229586  2396 layer_factory.hpp:77] Creating layer pool3
I0113 18:44:00.229598  2396 net.cpp:106] Creating Layer pool3
I0113 18:44:00.229602  2396 net.cpp:454] pool3 <- conv3
I0113 18:44:00.229611  2396 net.cpp:411] pool3 -> pool3
I0113 18:44:00.229643  2396 net.cpp:150] Setting up pool3
I0113 18:44:00.229651  2396 net.cpp:157] Top shape: 100 64 12 12 (921600)
I0113 18:44:00.229655  2396 net.cpp:165] Memory required for data: 351687600
I0113 18:44:00.229660  2396 layer_factory.hpp:77] Creating layer ip1
I0113 18:44:00.229673  2396 net.cpp:106] Creating Layer ip1
I0113 18:44:00.229678  2396 net.cpp:454] ip1 <- pool3
I0113 18:44:00.229689  2396 net.cpp:411] ip1 -> ip1
I0113 18:44:00.236111  2396 net.cpp:150] Setting up ip1
I0113 18:44:00.236189  2396 net.cpp:157] Top shape: 100 4 (400)
I0113 18:44:00.236196  2396 net.cpp:165] Memory required for data: 351689200
I0113 18:44:00.236224  2396 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0113 18:44:00.236248  2396 net.cpp:106] Creating Layer ip1_ip1_0_split
I0113 18:44:00.236256  2396 net.cpp:454] ip1_ip1_0_split <- ip1
I0113 18:44:00.236279  2396 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0113 18:44:00.236294  2396 net.cpp:411] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0113 18:44:00.236333  2396 net.cpp:150] Setting up ip1_ip1_0_split
I0113 18:44:00.236341  2396 net.cpp:157] Top shape: 100 4 (400)
I0113 18:44:00.236346  2396 net.cpp:157] Top shape: 100 4 (400)
I0113 18:44:00.236351  2396 net.cpp:165] Memory required for data: 351692400
I0113 18:44:00.236354  2396 layer_factory.hpp:77] Creating layer accuracy
I0113 18:44:00.236371  2396 net.cpp:106] Creating Layer accuracy
I0113 18:44:00.236377  2396 net.cpp:454] accuracy <- ip1_ip1_0_split_0
I0113 18:44:00.236384  2396 net.cpp:454] accuracy <- label_cifar_1_split_0
I0113 18:44:00.236392  2396 net.cpp:411] accuracy -> accuracy
I0113 18:44:00.236405  2396 net.cpp:150] Setting up accuracy
I0113 18:44:00.236412  2396 net.cpp:157] Top shape: (1)
I0113 18:44:00.236415  2396 net.cpp:165] Memory required for data: 351692404
I0113 18:44:00.236428  2396 layer_factory.hpp:77] Creating layer loss
I0113 18:44:00.236444  2396 net.cpp:106] Creating Layer loss
I0113 18:44:00.236449  2396 net.cpp:454] loss <- ip1_ip1_0_split_1
I0113 18:44:00.236456  2396 net.cpp:454] loss <- label_cifar_1_split_1
I0113 18:44:00.236464  2396 net.cpp:411] loss -> loss
I0113 18:44:00.236480  2396 layer_factory.hpp:77] Creating layer loss
I0113 18:44:00.236569  2396 net.cpp:150] Setting up loss
I0113 18:44:00.236578  2396 net.cpp:157] Top shape: (1)
I0113 18:44:00.236582  2396 net.cpp:160]     with loss weight 1
I0113 18:44:00.236596  2396 net.cpp:165] Memory required for data: 351692408
I0113 18:44:00.236601  2396 net.cpp:226] loss needs backward computation.
I0113 18:44:00.236608  2396 net.cpp:228] accuracy does not need backward computation.
I0113 18:44:00.236613  2396 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0113 18:44:00.236618  2396 net.cpp:226] ip1 needs backward computation.
I0113 18:44:00.236621  2396 net.cpp:226] pool3 needs backward computation.
I0113 18:44:00.236626  2396 net.cpp:226] relu3 needs backward computation.
I0113 18:44:00.236630  2396 net.cpp:226] conv3 needs backward computation.
I0113 18:44:00.236635  2396 net.cpp:226] norm2 needs backward computation.
I0113 18:44:00.236639  2396 net.cpp:226] pool2 needs backward computation.
I0113 18:44:00.236644  2396 net.cpp:226] relu2 needs backward computation.
I0113 18:44:00.236649  2396 net.cpp:226] conv2 needs backward computation.
I0113 18:44:00.236654  2396 net.cpp:226] norm1 needs backward computation.
I0113 18:44:00.236657  2396 net.cpp:226] relu1 needs backward computation.
I0113 18:44:00.236661  2396 net.cpp:226] pool1 needs backward computation.
I0113 18:44:00.236666  2396 net.cpp:226] conv1 needs backward computation.
I0113 18:44:00.236685  2396 net.cpp:228] label_cifar_1_split does not need backward computation.
I0113 18:44:00.236690  2396 net.cpp:228] cifar does not need backward computation.
I0113 18:44:00.236693  2396 net.cpp:270] This network produces output accuracy
I0113 18:44:00.236699  2396 net.cpp:270] This network produces output loss
I0113 18:44:00.236721  2396 net.cpp:283] Network initialization done.
I0113 18:44:00.236800  2396 solver.cpp:60] Solver scaffolding done.
I0113 18:44:00.237046  2396 caffe.cpp:203] Resuming from krnet_full_iter_85000.solverstate.h5
I0113 18:44:00.238764  2396 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0113 18:44:00.240296  2396 caffe.cpp:213] Starting Optimization
I0113 18:44:00.240330  2396 solver.cpp:280] Solving CIFAR10_full
I0113 18:44:00.240335  2396 solver.cpp:281] Learning Rate Policy: fixed
I0113 18:44:00.241173  2396 solver.cpp:338] Iteration 85000, Testing net (#0)
I0113 18:44:00.241329  2396 blocking_queue.cpp:50] Data layer prefetch queue empty
I0113 18:44:03.487540  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3867
I0113 18:44:03.487578  2396 solver.cpp:406]     Test net output #1: loss = 1.25838 (* 1 = 1.25838 loss)
I0113 18:44:03.546838  2396 solver.cpp:229] Iteration 85000, loss = 1.45483
I0113 18:44:03.546874  2396 solver.cpp:245]     Train net output #0: loss = 1.45483 (* 1 = 1.45483 loss)
I0113 18:44:03.546880  2396 sgd_solver.cpp:106] Iteration 85000, lr = 1e-05
I0113 18:44:24.371805  2396 solver.cpp:229] Iteration 85200, loss = 1.55686
I0113 18:44:24.371846  2396 solver.cpp:245]     Train net output #0: loss = 1.55686 (* 1 = 1.55686 loss)
I0113 18:44:24.371851  2396 sgd_solver.cpp:106] Iteration 85200, lr = 1e-05
I0113 18:44:45.187075  2396 solver.cpp:229] Iteration 85400, loss = 1.43041
I0113 18:44:45.187144  2396 solver.cpp:245]     Train net output #0: loss = 1.43041 (* 1 = 1.43041 loss)
I0113 18:44:45.187150  2396 sgd_solver.cpp:106] Iteration 85400, lr = 1e-05
I0113 18:45:06.000068  2396 solver.cpp:229] Iteration 85600, loss = 1.14765
I0113 18:45:06.000109  2396 solver.cpp:245]     Train net output #0: loss = 1.14765 (* 1 = 1.14765 loss)
I0113 18:45:06.000115  2396 sgd_solver.cpp:106] Iteration 85600, lr = 1e-05
I0113 18:45:26.817916  2396 solver.cpp:229] Iteration 85800, loss = 1.23167
I0113 18:45:26.817989  2396 solver.cpp:245]     Train net output #0: loss = 1.23167 (* 1 = 1.23167 loss)
I0113 18:45:26.817996  2396 sgd_solver.cpp:106] Iteration 85800, lr = 1e-05
I0113 18:45:47.526759  2396 solver.cpp:338] Iteration 86000, Testing net (#0)
I0113 18:45:50.809844  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3877
I0113 18:45:50.809885  2396 solver.cpp:406]     Test net output #1: loss = 1.25328 (* 1 = 1.25328 loss)
I0113 18:45:50.865608  2396 solver.cpp:229] Iteration 86000, loss = 1.33348
I0113 18:45:50.865646  2396 solver.cpp:245]     Train net output #0: loss = 1.33348 (* 1 = 1.33348 loss)
I0113 18:45:50.865651  2396 sgd_solver.cpp:106] Iteration 86000, lr = 1e-05
I0113 18:46:11.679010  2396 solver.cpp:229] Iteration 86200, loss = 1.26755
I0113 18:46:11.679085  2396 solver.cpp:245]     Train net output #0: loss = 1.26755 (* 1 = 1.26755 loss)
I0113 18:46:11.679090  2396 sgd_solver.cpp:106] Iteration 86200, lr = 1e-05
I0113 18:46:32.493041  2396 solver.cpp:229] Iteration 86400, loss = 1.23141
I0113 18:46:32.493083  2396 solver.cpp:245]     Train net output #0: loss = 1.23141 (* 1 = 1.23141 loss)
I0113 18:46:32.493088  2396 sgd_solver.cpp:106] Iteration 86400, lr = 1e-05
I0113 18:46:53.299891  2396 solver.cpp:229] Iteration 86600, loss = 1.53396
I0113 18:46:53.299945  2396 solver.cpp:245]     Train net output #0: loss = 1.53396 (* 1 = 1.53396 loss)
I0113 18:46:53.299952  2396 sgd_solver.cpp:106] Iteration 86600, lr = 1e-05
I0113 18:47:14.126471  2396 solver.cpp:229] Iteration 86800, loss = 1.4391
I0113 18:47:14.126513  2396 solver.cpp:245]     Train net output #0: loss = 1.4391 (* 1 = 1.4391 loss)
I0113 18:47:14.126518  2396 sgd_solver.cpp:106] Iteration 86800, lr = 1e-05
I0113 18:47:34.839543  2396 solver.cpp:338] Iteration 87000, Testing net (#0)
I0113 18:47:38.122985  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3855
I0113 18:47:38.123025  2396 solver.cpp:406]     Test net output #1: loss = 1.25578 (* 1 = 1.25578 loss)
I0113 18:47:38.178699  2396 solver.cpp:229] Iteration 87000, loss = 1.15639
I0113 18:47:38.178736  2396 solver.cpp:245]     Train net output #0: loss = 1.15639 (* 1 = 1.15639 loss)
I0113 18:47:38.178740  2396 sgd_solver.cpp:106] Iteration 87000, lr = 1e-05
I0113 18:47:58.987751  2396 solver.cpp:229] Iteration 87200, loss = 1.27959
I0113 18:47:58.987792  2396 solver.cpp:245]     Train net output #0: loss = 1.27959 (* 1 = 1.27959 loss)
I0113 18:47:58.987797  2396 sgd_solver.cpp:106] Iteration 87200, lr = 1e-05
I0113 18:48:19.816295  2396 solver.cpp:229] Iteration 87400, loss = 1.15878
I0113 18:48:19.816364  2396 solver.cpp:245]     Train net output #0: loss = 1.15878 (* 1 = 1.15878 loss)
I0113 18:48:19.816370  2396 sgd_solver.cpp:106] Iteration 87400, lr = 1e-05
I0113 18:48:40.628657  2396 solver.cpp:229] Iteration 87600, loss = 1.21824
I0113 18:48:40.628700  2396 solver.cpp:245]     Train net output #0: loss = 1.21824 (* 1 = 1.21824 loss)
I0113 18:48:40.628705  2396 sgd_solver.cpp:106] Iteration 87600, lr = 1e-05
I0113 18:49:01.439038  2396 solver.cpp:229] Iteration 87800, loss = 1.2876
I0113 18:49:01.439092  2396 solver.cpp:245]     Train net output #0: loss = 1.2876 (* 1 = 1.2876 loss)
I0113 18:49:01.439097  2396 sgd_solver.cpp:106] Iteration 87800, lr = 1e-05
I0113 18:49:22.154140  2396 solver.cpp:338] Iteration 88000, Testing net (#0)
I0113 18:49:25.438021  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3925
I0113 18:49:25.438061  2396 solver.cpp:406]     Test net output #1: loss = 1.2513 (* 1 = 1.2513 loss)
I0113 18:49:25.493821  2396 solver.cpp:229] Iteration 88000, loss = 1.32554
I0113 18:49:25.493858  2396 solver.cpp:245]     Train net output #0: loss = 1.32554 (* 1 = 1.32554 loss)
I0113 18:49:25.493863  2396 sgd_solver.cpp:106] Iteration 88000, lr = 1e-05
I0113 18:49:46.301393  2396 solver.cpp:229] Iteration 88200, loss = 1.28228
I0113 18:49:46.301447  2396 solver.cpp:245]     Train net output #0: loss = 1.28228 (* 1 = 1.28228 loss)
I0113 18:49:46.301453  2396 sgd_solver.cpp:106] Iteration 88200, lr = 1e-05
I0113 18:50:07.125850  2396 solver.cpp:229] Iteration 88400, loss = 1.30968
I0113 18:50:07.125892  2396 solver.cpp:245]     Train net output #0: loss = 1.30968 (* 1 = 1.30968 loss)
I0113 18:50:07.125897  2396 sgd_solver.cpp:106] Iteration 88400, lr = 1e-05
I0113 18:50:27.938588  2396 solver.cpp:229] Iteration 88600, loss = 1.24866
I0113 18:50:27.938675  2396 solver.cpp:245]     Train net output #0: loss = 1.24866 (* 1 = 1.24866 loss)
I0113 18:50:27.938681  2396 sgd_solver.cpp:106] Iteration 88600, lr = 1e-05
I0113 18:50:48.743791  2396 solver.cpp:229] Iteration 88800, loss = 1.22145
I0113 18:50:48.743834  2396 solver.cpp:245]     Train net output #0: loss = 1.22145 (* 1 = 1.22145 loss)
I0113 18:50:48.743839  2396 sgd_solver.cpp:106] Iteration 88800, lr = 1e-05
I0113 18:51:09.465889  2396 solver.cpp:338] Iteration 89000, Testing net (#0)
I0113 18:51:12.749145  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3857
I0113 18:51:12.749183  2396 solver.cpp:406]     Test net output #1: loss = 1.25814 (* 1 = 1.25814 loss)
I0113 18:51:12.804909  2396 solver.cpp:229] Iteration 89000, loss = 1.31219
I0113 18:51:12.804946  2396 solver.cpp:245]     Train net output #0: loss = 1.31219 (* 1 = 1.31219 loss)
I0113 18:51:12.804952  2396 sgd_solver.cpp:106] Iteration 89000, lr = 1e-05
I0113 18:51:33.616523  2396 solver.cpp:229] Iteration 89200, loss = 1.12196
I0113 18:51:33.616564  2396 solver.cpp:245]     Train net output #0: loss = 1.12196 (* 1 = 1.12196 loss)
I0113 18:51:33.616570  2396 sgd_solver.cpp:106] Iteration 89200, lr = 1e-05
I0113 18:51:54.423593  2396 solver.cpp:229] Iteration 89400, loss = 1.25419
I0113 18:51:54.423647  2396 solver.cpp:245]     Train net output #0: loss = 1.25419 (* 1 = 1.25419 loss)
I0113 18:51:54.423652  2396 sgd_solver.cpp:106] Iteration 89400, lr = 1e-05
I0113 18:52:15.235950  2396 solver.cpp:229] Iteration 89600, loss = 1.43071
I0113 18:52:15.235991  2396 solver.cpp:245]     Train net output #0: loss = 1.43071 (* 1 = 1.43071 loss)
I0113 18:52:15.235997  2396 sgd_solver.cpp:106] Iteration 89600, lr = 1e-05
I0113 18:52:36.043196  2396 solver.cpp:229] Iteration 89800, loss = 1.27277
I0113 18:52:36.043294  2396 solver.cpp:245]     Train net output #0: loss = 1.27277 (* 1 = 1.27277 loss)
I0113 18:52:36.043300  2396 sgd_solver.cpp:106] Iteration 89800, lr = 1e-05
I0113 18:52:56.762302  2396 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_90000.caffemodel.h5
I0113 18:52:56.811627  2396 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_90000.solverstate.h5
I0113 18:52:56.812360  2396 solver.cpp:338] Iteration 90000, Testing net (#0)
I0113 18:53:00.049491  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3915
I0113 18:53:00.049531  2396 solver.cpp:406]     Test net output #1: loss = 1.25316 (* 1 = 1.25316 loss)
I0113 18:53:00.105222  2396 solver.cpp:229] Iteration 90000, loss = 1.37392
I0113 18:53:00.105259  2396 solver.cpp:245]     Train net output #0: loss = 1.37392 (* 1 = 1.37392 loss)
I0113 18:53:00.105264  2396 sgd_solver.cpp:106] Iteration 90000, lr = 1e-05
I0113 18:53:20.922547  2396 solver.cpp:229] Iteration 90200, loss = 1.27968
I0113 18:53:20.922626  2396 solver.cpp:245]     Train net output #0: loss = 1.27968 (* 1 = 1.27968 loss)
I0113 18:53:20.922631  2396 sgd_solver.cpp:106] Iteration 90200, lr = 1e-05
I0113 18:53:41.729876  2396 solver.cpp:229] Iteration 90400, loss = 1.40688
I0113 18:53:41.729917  2396 solver.cpp:245]     Train net output #0: loss = 1.40688 (* 1 = 1.40688 loss)
I0113 18:53:41.729921  2396 sgd_solver.cpp:106] Iteration 90400, lr = 1e-05
I0113 18:54:02.556731  2396 solver.cpp:229] Iteration 90600, loss = 1.25876
I0113 18:54:02.556777  2396 solver.cpp:245]     Train net output #0: loss = 1.25876 (* 1 = 1.25876 loss)
I0113 18:54:02.556783  2396 sgd_solver.cpp:106] Iteration 90600, lr = 1e-05
I0113 18:54:23.371517  2396 solver.cpp:229] Iteration 90800, loss = 1.25028
I0113 18:54:23.371558  2396 solver.cpp:245]     Train net output #0: loss = 1.25028 (* 1 = 1.25028 loss)
I0113 18:54:23.371564  2396 sgd_solver.cpp:106] Iteration 90800, lr = 1e-05
I0113 18:54:44.078900  2396 solver.cpp:338] Iteration 91000, Testing net (#0)
I0113 18:54:47.361985  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3847
I0113 18:54:47.362021  2396 solver.cpp:406]     Test net output #1: loss = 1.25461 (* 1 = 1.25461 loss)
I0113 18:54:47.417750  2396 solver.cpp:229] Iteration 91000, loss = 1.22553
I0113 18:54:47.417784  2396 solver.cpp:245]     Train net output #0: loss = 1.22553 (* 1 = 1.22553 loss)
I0113 18:54:47.417788  2396 sgd_solver.cpp:106] Iteration 91000, lr = 1e-05
I0113 18:55:08.237941  2396 solver.cpp:229] Iteration 91200, loss = 1.25479
I0113 18:55:08.237980  2396 solver.cpp:245]     Train net output #0: loss = 1.25479 (* 1 = 1.25479 loss)
I0113 18:55:08.237987  2396 sgd_solver.cpp:106] Iteration 91200, lr = 1e-05
I0113 18:55:29.050287  2396 solver.cpp:229] Iteration 91400, loss = 1.59108
I0113 18:55:29.050362  2396 solver.cpp:245]     Train net output #0: loss = 1.59108 (* 1 = 1.59108 loss)
I0113 18:55:29.050367  2396 sgd_solver.cpp:106] Iteration 91400, lr = 1e-05
I0113 18:55:49.867288  2396 solver.cpp:229] Iteration 91600, loss = 1.49103
I0113 18:55:49.867331  2396 solver.cpp:245]     Train net output #0: loss = 1.49103 (* 1 = 1.49103 loss)
I0113 18:55:49.867336  2396 sgd_solver.cpp:106] Iteration 91600, lr = 1e-05
I0113 18:56:10.688704  2396 solver.cpp:229] Iteration 91800, loss = 1.15609
I0113 18:56:10.688756  2396 solver.cpp:245]     Train net output #0: loss = 1.15609 (* 1 = 1.15609 loss)
I0113 18:56:10.688761  2396 sgd_solver.cpp:106] Iteration 91800, lr = 1e-05
I0113 18:56:31.392587  2396 solver.cpp:338] Iteration 92000, Testing net (#0)
I0113 18:56:34.674401  2396 solver.cpp:406]     Test net output #0: accuracy = 0.391
I0113 18:56:34.674440  2396 solver.cpp:406]     Test net output #1: loss = 1.25232 (* 1 = 1.25232 loss)
I0113 18:56:34.730154  2396 solver.cpp:229] Iteration 92000, loss = 1.1362
I0113 18:56:34.730190  2396 solver.cpp:245]     Train net output #0: loss = 1.1362 (* 1 = 1.1362 loss)
I0113 18:56:34.730195  2396 sgd_solver.cpp:106] Iteration 92000, lr = 1e-05
I0113 18:56:55.552462  2396 solver.cpp:229] Iteration 92200, loss = 1.06332
I0113 18:56:55.552553  2396 solver.cpp:245]     Train net output #0: loss = 1.06332 (* 1 = 1.06332 loss)
I0113 18:56:55.552559  2396 sgd_solver.cpp:106] Iteration 92200, lr = 1e-05
I0113 18:57:16.372570  2396 solver.cpp:229] Iteration 92400, loss = 1.05945
I0113 18:57:16.372611  2396 solver.cpp:245]     Train net output #0: loss = 1.05945 (* 1 = 1.05945 loss)
I0113 18:57:16.372617  2396 sgd_solver.cpp:106] Iteration 92400, lr = 1e-05
I0113 18:57:37.180627  2396 solver.cpp:229] Iteration 92600, loss = 1.16762
I0113 18:57:37.180685  2396 solver.cpp:245]     Train net output #0: loss = 1.16762 (* 1 = 1.16762 loss)
I0113 18:57:37.180691  2396 sgd_solver.cpp:106] Iteration 92600, lr = 1e-05
I0113 18:57:57.999287  2396 solver.cpp:229] Iteration 92800, loss = 1.11571
I0113 18:57:57.999330  2396 solver.cpp:245]     Train net output #0: loss = 1.11571 (* 1 = 1.11571 loss)
I0113 18:57:57.999336  2396 sgd_solver.cpp:106] Iteration 92800, lr = 1e-05
I0113 18:58:18.707685  2396 solver.cpp:338] Iteration 93000, Testing net (#0)
I0113 18:58:21.990348  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3863
I0113 18:58:21.990387  2396 solver.cpp:406]     Test net output #1: loss = 1.25832 (* 1 = 1.25832 loss)
I0113 18:58:22.046118  2396 solver.cpp:229] Iteration 93000, loss = 1.24847
I0113 18:58:22.046154  2396 solver.cpp:245]     Train net output #0: loss = 1.24847 (* 1 = 1.24847 loss)
I0113 18:58:22.046159  2396 sgd_solver.cpp:106] Iteration 93000, lr = 1e-05
I0113 18:58:42.862594  2396 solver.cpp:229] Iteration 93200, loss = 1.13582
I0113 18:58:42.862635  2396 solver.cpp:245]     Train net output #0: loss = 1.13582 (* 1 = 1.13582 loss)
I0113 18:58:42.862640  2396 sgd_solver.cpp:106] Iteration 93200, lr = 1e-05
I0113 18:59:03.683329  2396 solver.cpp:229] Iteration 93400, loss = 1.36842
I0113 18:59:03.683382  2396 solver.cpp:245]     Train net output #0: loss = 1.36842 (* 1 = 1.36842 loss)
I0113 18:59:03.683393  2396 sgd_solver.cpp:106] Iteration 93400, lr = 1e-05
I0113 18:59:24.491139  2396 solver.cpp:229] Iteration 93600, loss = 1.17243
I0113 18:59:24.491180  2396 solver.cpp:245]     Train net output #0: loss = 1.17243 (* 1 = 1.17243 loss)
I0113 18:59:24.491185  2396 sgd_solver.cpp:106] Iteration 93600, lr = 1e-05
I0113 18:59:45.311251  2396 solver.cpp:229] Iteration 93800, loss = 1.05059
I0113 18:59:45.311324  2396 solver.cpp:245]     Train net output #0: loss = 1.05059 (* 1 = 1.05059 loss)
I0113 18:59:45.311331  2396 sgd_solver.cpp:106] Iteration 93800, lr = 1e-05
I0113 19:00:06.028687  2396 solver.cpp:338] Iteration 94000, Testing net (#0)
I0113 19:00:09.310801  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3911
I0113 19:00:09.310840  2396 solver.cpp:406]     Test net output #1: loss = 1.2536 (* 1 = 1.2536 loss)
I0113 19:00:09.366591  2396 solver.cpp:229] Iteration 94000, loss = 1.27085
I0113 19:00:09.366629  2396 solver.cpp:245]     Train net output #0: loss = 1.27085 (* 1 = 1.27085 loss)
I0113 19:00:09.366634  2396 sgd_solver.cpp:106] Iteration 94000, lr = 1e-05
I0113 19:00:30.185441  2396 solver.cpp:229] Iteration 94200, loss = 1.42955
I0113 19:00:30.185493  2396 solver.cpp:245]     Train net output #0: loss = 1.42955 (* 1 = 1.42955 loss)
I0113 19:00:30.185498  2396 sgd_solver.cpp:106] Iteration 94200, lr = 1e-05
I0113 19:00:51.016054  2396 solver.cpp:229] Iteration 94400, loss = 1.24907
I0113 19:00:51.016095  2396 solver.cpp:245]     Train net output #0: loss = 1.24907 (* 1 = 1.24907 loss)
I0113 19:00:51.016100  2396 sgd_solver.cpp:106] Iteration 94400, lr = 1e-05
I0113 19:01:11.838697  2396 solver.cpp:229] Iteration 94600, loss = 1.21451
I0113 19:01:11.838786  2396 solver.cpp:245]     Train net output #0: loss = 1.21451 (* 1 = 1.21451 loss)
I0113 19:01:11.838793  2396 sgd_solver.cpp:106] Iteration 94600, lr = 1e-05
I0113 19:01:32.661948  2396 solver.cpp:229] Iteration 94800, loss = 1.36982
I0113 19:01:32.661990  2396 solver.cpp:245]     Train net output #0: loss = 1.36982 (* 1 = 1.36982 loss)
I0113 19:01:32.661995  2396 sgd_solver.cpp:106] Iteration 94800, lr = 1e-05
I0113 19:01:53.386276  2396 solver.cpp:466] Snapshotting to HDF5 file krnet_full_iter_95000.caffemodel.h5
I0113 19:01:53.435479  2396 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file krnet_full_iter_95000.solverstate.h5
I0113 19:01:53.468444  2396 solver.cpp:318] Iteration 95000, loss = 1.40428
I0113 19:01:53.468479  2396 solver.cpp:338] Iteration 95000, Testing net (#0)
I0113 19:01:56.705405  2396 solver.cpp:406]     Test net output #0: accuracy = 0.3861
I0113 19:01:56.705445  2396 solver.cpp:406]     Test net output #1: loss = 1.25432 (* 1 = 1.25432 loss)
I0113 19:01:56.705449  2396 solver.cpp:323] Optimization Done.
I0113 19:01:56.705451  2396 caffe.cpp:216] Optimization Done.
